{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Data\n",
    "\n",
    "## Environment Settings\n",
    "\n",
    "An statistical Analysis of the data captured will be performed.\n",
    "\n",
    "The environment configuration is the following:\n",
    "\n",
    "- A rectangle area is used whose dimension is 2 x 1.5 meters. \n",
    "- A custom robot similar to an epuck was used.\n",
    "- The robot starts in the middle of the arena.\n",
    "- The robot moves in a random fashion way around the environment avoiding obstacles.\n",
    "- The robot has 8 sensors that measure the distance between the robot and the walls.\n",
    "- Some noise was introduced in the sensors measurements of the robot using the concept of [lookup tables](https://cyberbotics.com/doc/reference/distancesensor) in the Webots simulator which according to Webots documentation \"The first column of the table specifies the input distances, the second column specifies the corresponding desired response values, and the third column indicates the desired standard deviation of the noise. The noise on the return value is computed according to a gaussian random number distribution whose range is calculated as a percent of the response value (two times the standard deviation is often referred to as the signal quality)\". The following values were taken:\n",
    "\n",
    "    -First experiment:\n",
    "        - (0, 0, 0.01)\n",
    "        - (10, 10, 0.01)\n",
    "    -Second experiment:\n",
    "    \n",
    "        - (0, 0, 0.2)\n",
    "        - (10, 10, 0.2)\n",
    "- The simulator runs during 10 minutes in fast mode which is translated into 12 hours of collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from keras) (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install keras\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.988880</td>\n",
       "      <td>0.75</td>\n",
       "      <td>179.999914</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-3.434233e-08</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>1.016671</td>\n",
       "      <td>0.772257</td>\n",
       "      <td>0.758362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776327</td>\n",
       "      <td>1.036414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986479</td>\n",
       "      <td>0.75</td>\n",
       "      <td>179.999700</td>\n",
       "      <td>-0.002402</td>\n",
       "      <td>-4.404136e-08</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>1.023977</td>\n",
       "      <td>0.769891</td>\n",
       "      <td>0.776911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772796</td>\n",
       "      <td>1.021728</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>-0.002366</td>\n",
       "      <td>0.018549</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.014686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.984077</td>\n",
       "      <td>0.75</td>\n",
       "      <td>179.999550</td>\n",
       "      <td>-0.002402</td>\n",
       "      <td>-4.461517e-08</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>1.025475</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.755931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763096</td>\n",
       "      <td>1.011234</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>-0.020980</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>-0.001140</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.010494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>0.75</td>\n",
       "      <td>179.999646</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>1.811730e-09</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.002404</td>\n",
       "      <td>0.765992</td>\n",
       "      <td>0.761169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768402</td>\n",
       "      <td>1.027048</td>\n",
       "      <td>-0.023071</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>-0.014810</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.015814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.979275</td>\n",
       "      <td>0.75</td>\n",
       "      <td>179.999719</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>-3.172477e-08</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.031322</td>\n",
       "      <td>0.770209</td>\n",
       "      <td>0.758279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784118</td>\n",
       "      <td>1.007218</td>\n",
       "      <td>0.028918</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.001779</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.015716</td>\n",
       "      <td>-0.019830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         x     y       theta        dx            dy    dtheta  \\\n",
       "0           0  0.988880  0.75  179.999914 -0.002403 -3.434233e-08 -0.000307   \n",
       "1           1  0.986479  0.75  179.999700 -0.002402 -4.404136e-08 -0.000214   \n",
       "2           2  0.984077  0.75  179.999550 -0.002402 -4.461517e-08 -0.000150   \n",
       "3           3  0.981675  0.75  179.999646 -0.002401  1.811730e-09  0.000096   \n",
       "4           4  0.979275  0.75  179.999719 -0.002401 -3.172477e-08  0.000073   \n",
       "\n",
       "   sensor_1  sensor_2  sensor_3    ...      sensor_7  sensor_8  dsensor_1  \\\n",
       "0  1.016671  0.772257  0.758362    ...      0.776327  1.036414        NaN   \n",
       "1  1.023977  0.769891  0.776911    ...      0.772796  1.021728   0.007307   \n",
       "2  1.025475  0.764957  0.755931    ...      0.763096  1.011234   0.001498   \n",
       "3  1.002404  0.765992  0.761169    ...      0.768402  1.027048  -0.023071   \n",
       "4  1.031322  0.770209  0.758279    ...      0.784118  1.007218   0.028918   \n",
       "\n",
       "   dsensor_2  dsensor_3  dsensor_4  dsensor_5  dsensor_6  dsensor_7  dsensor_8  \n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "1  -0.002366   0.018549   0.010704   0.016474   0.008077  -0.003531  -0.014686  \n",
       "2  -0.004934  -0.020980  -0.005215   0.014775  -0.001140  -0.009700  -0.010494  \n",
       "3   0.001035   0.005239   0.002830  -0.010190  -0.014810   0.005306   0.015814  \n",
       "4   0.004218  -0.002891  -0.001779   0.007880   0.001911   0.015716  -0.019830  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'robot_info_dataset-small.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected 1384848 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1384848, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains some null values so they should be deleted from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data will be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "      <td>1.384847e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.043103e-01</td>\n",
       "      <td>5.022442e-01</td>\n",
       "      <td>5.066361e-01</td>\n",
       "      <td>4.986988e-01</td>\n",
       "      <td>4.977974e-01</td>\n",
       "      <td>4.999973e-01</td>\n",
       "      <td>3.271090e-01</td>\n",
       "      <td>3.311406e-01</td>\n",
       "      <td>3.325766e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401064e-01</td>\n",
       "      <td>3.362420e-01</td>\n",
       "      <td>4.531070e-01</td>\n",
       "      <td>4.571082e-01</td>\n",
       "      <td>4.921013e-01</td>\n",
       "      <td>5.345466e-01</td>\n",
       "      <td>5.522644e-01</td>\n",
       "      <td>5.323369e-01</td>\n",
       "      <td>4.278540e-01</td>\n",
       "      <td>4.592014e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.886754e-01</td>\n",
       "      <td>2.954846e-01</td>\n",
       "      <td>2.963533e-01</td>\n",
       "      <td>2.937289e-01</td>\n",
       "      <td>3.235386e-01</td>\n",
       "      <td>3.064571e-01</td>\n",
       "      <td>3.355993e-02</td>\n",
       "      <td>2.032944e-01</td>\n",
       "      <td>2.329466e-01</td>\n",
       "      <td>2.384979e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328287e-01</td>\n",
       "      <td>2.009473e-01</td>\n",
       "      <td>1.981138e-02</td>\n",
       "      <td>2.099583e-02</td>\n",
       "      <td>2.021053e-02</td>\n",
       "      <td>2.187133e-02</td>\n",
       "      <td>2.111011e-02</td>\n",
       "      <td>2.118726e-02</td>\n",
       "      <td>2.121420e-02</td>\n",
       "      <td>2.087997e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.407805e-01</td>\n",
       "      <td>2.343989e-01</td>\n",
       "      <td>2.521449e-01</td>\n",
       "      <td>1.653955e-01</td>\n",
       "      <td>1.998177e-01</td>\n",
       "      <td>4.999971e-01</td>\n",
       "      <td>1.606788e-01</td>\n",
       "      <td>1.164520e-01</td>\n",
       "      <td>1.224339e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.173001e-01</td>\n",
       "      <td>1.721422e-01</td>\n",
       "      <td>4.479947e-01</td>\n",
       "      <td>4.523809e-01</td>\n",
       "      <td>4.884411e-01</td>\n",
       "      <td>5.308855e-01</td>\n",
       "      <td>5.487057e-01</td>\n",
       "      <td>5.285259e-01</td>\n",
       "      <td>4.230109e-01</td>\n",
       "      <td>4.539795e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.046786e-01</td>\n",
       "      <td>5.057731e-01</td>\n",
       "      <td>5.030852e-01</td>\n",
       "      <td>4.975412e-01</td>\n",
       "      <td>4.939680e-01</td>\n",
       "      <td>4.999974e-01</td>\n",
       "      <td>2.913437e-01</td>\n",
       "      <td>3.099246e-01</td>\n",
       "      <td>3.020417e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.181929e-01</td>\n",
       "      <td>3.031704e-01</td>\n",
       "      <td>4.521192e-01</td>\n",
       "      <td>4.568127e-01</td>\n",
       "      <td>4.924489e-01</td>\n",
       "      <td>5.355157e-01</td>\n",
       "      <td>5.531776e-01</td>\n",
       "      <td>5.327067e-01</td>\n",
       "      <td>4.275885e-01</td>\n",
       "      <td>4.581827e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>7.702018e-01</td>\n",
       "      <td>7.750610e-01</td>\n",
       "      <td>7.517734e-01</td>\n",
       "      <td>8.246082e-01</td>\n",
       "      <td>8.018908e-01</td>\n",
       "      <td>4.999977e-01</td>\n",
       "      <td>4.689142e-01</td>\n",
       "      <td>5.248440e-01</td>\n",
       "      <td>5.246918e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.340601e-01</td>\n",
       "      <td>4.775811e-01</td>\n",
       "      <td>4.566103e-01</td>\n",
       "      <td>4.608929e-01</td>\n",
       "      <td>4.965942e-01</td>\n",
       "      <td>5.399879e-01</td>\n",
       "      <td>5.575024e-01</td>\n",
       "      <td>5.370229e-01</td>\n",
       "      <td>4.317304e-01</td>\n",
       "      <td>4.627662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             x             y         theta            dx  \\\n",
       "count  1.384847e+06  1.384847e+06  1.384847e+06  1.384847e+06  1.384847e+06   \n",
       "mean   5.000000e-01  5.043103e-01  5.022442e-01  5.066361e-01  4.986988e-01   \n",
       "std    2.886754e-01  2.954846e-01  2.963533e-01  2.937289e-01  3.235386e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.500000e-01  2.407805e-01  2.343989e-01  2.521449e-01  1.653955e-01   \n",
       "50%    5.000000e-01  5.046786e-01  5.057731e-01  5.030852e-01  4.975412e-01   \n",
       "75%    7.500000e-01  7.702018e-01  7.750610e-01  7.517734e-01  8.246082e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 dy        dtheta      sensor_1      sensor_2      sensor_3  \\\n",
       "count  1.384847e+06  1.384847e+06  1.384847e+06  1.384847e+06  1.384847e+06   \n",
       "mean   4.977974e-01  4.999973e-01  3.271090e-01  3.311406e-01  3.325766e-01   \n",
       "std    3.064571e-01  3.355993e-02  2.032944e-01  2.329466e-01  2.384979e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.998177e-01  4.999971e-01  1.606788e-01  1.164520e-01  1.224339e-01   \n",
       "50%    4.939680e-01  4.999974e-01  2.913437e-01  3.099246e-01  3.020417e-01   \n",
       "75%    8.018908e-01  4.999977e-01  4.689142e-01  5.248440e-01  5.246918e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           ...           sensor_7      sensor_8     dsensor_1     dsensor_2  \\\n",
       "count      ...       1.384847e+06  1.384847e+06  1.384847e+06  1.384847e+06   \n",
       "mean       ...       3.401064e-01  3.362420e-01  4.531070e-01  4.571082e-01   \n",
       "std        ...       2.328287e-01  2.009473e-01  1.981138e-02  2.099583e-02   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       1.173001e-01  1.721422e-01  4.479947e-01  4.523809e-01   \n",
       "50%        ...       3.181929e-01  3.031704e-01  4.521192e-01  4.568127e-01   \n",
       "75%        ...       5.340601e-01  4.775811e-01  4.566103e-01  4.608929e-01   \n",
       "max        ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          dsensor_3     dsensor_4     dsensor_5     dsensor_6     dsensor_7  \\\n",
       "count  1.384847e+06  1.384847e+06  1.384847e+06  1.384847e+06  1.384847e+06   \n",
       "mean   4.921013e-01  5.345466e-01  5.522644e-01  5.323369e-01  4.278540e-01   \n",
       "std    2.021053e-02  2.187133e-02  2.111011e-02  2.118726e-02  2.121420e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    4.884411e-01  5.308855e-01  5.487057e-01  5.285259e-01  4.230109e-01   \n",
       "50%    4.924489e-01  5.355157e-01  5.531776e-01  5.327067e-01  4.275885e-01   \n",
       "75%    4.965942e-01  5.399879e-01  5.575024e-01  5.370229e-01  4.317304e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          dsensor_8  \n",
       "count  1.384847e+06  \n",
       "mean   4.592014e-01  \n",
       "std    2.087997e-02  \n",
       "min    0.000000e+00  \n",
       "25%    4.539795e-01  \n",
       "50%    4.581827e-01  \n",
       "75%    4.627662e-01  \n",
       "max    1.000000e+00  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "normalized_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into training, testing and validation sets. 60% of the data will be used for training, 20% for training and 20% of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train size\n",
    "test_size_percentage = .2\n",
    "train_size_percentage = .6\n",
    "ds_size = normalized_df.shape[0]\n",
    "train_size = int(train_size_percentage * ds_size)\n",
    "test_size = int(test_size_percentage * ds_size)\n",
    "\n",
    "# shuffle dataset\n",
    "normalized_df = normalized_df.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs = normalized_df[['x', 'y', 'theta']]\n",
    "targets = normalized_df[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "# test\n",
    "test_inputs = inputs[train_size:(train_size + test_size)]\n",
    "test_targets = targets[train_size:(train_size + test_size)]\n",
    "\n",
    "# validation\n",
    "validation_inputs = inputs[(train_size + test_size):]\n",
    "validation_targets = targets[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forsest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fit a random forest tree with 5 trees and each tree will handle $\\sqrt n$ number of variables available for splitting at each tree node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=5, n_jobs=1, oob_score=False,\n",
       "                      random_state=None, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 8;\n",
    "max_features = round(math.sqrt(n_features))\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=5, max_features=max_features, criterion='mse', verbose=False, n_jobs=1)\n",
    "reg.fit(train_inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importances x: 0.278818, y: 0.267225, theta: 0.453957\n",
      "\n",
      "R^2 score: 0.999047 \n",
      "\n",
      "Mean Absolute Error:\n",
      "0.00448776\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "98.1 %.\n",
      "\n",
      "NMSE\n",
      "0.0009723349374928195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features importances x: %f, y: %f, theta: %f\" %(reg.feature_importances_[0], reg.feature_importances_[1], reg.feature_importances_[2]))\n",
    "print()\n",
    "predictions_targets = reg.predict(test_inputs)\n",
    "\n",
    "print(\"R^2 score: %f \\n\" % reg.score(test_inputs, test_targets))\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions_targets - test_targets)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:')\n",
    "print(round(np.mean(np.mean(errors)), 8))\n",
    "print()\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_targets)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print()\n",
    "print('Accuracy:')\n",
    "print(round(np.mean(accuracy), 2), '%.')\n",
    "print()\n",
    "\n",
    "nmse = np.mean((predictions_targets - test_targets)**2/np.var(test_targets))\n",
    "print(\"NMSE\")\n",
    "print(np.mean(nmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input the neural network receives the x, y coordinates and rotation angle $\\theta$. The output are the sensor measurements. The hidden layer uses relu as activation function. The loss function is MSE and it serves as a metric\n",
    "to minimize the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NN Architecture](nn_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(train_data):\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(8))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 664727 samples, validate on 166181 samples\n",
      "Epoch 1/50\n",
      "664727/664727 [==============================] - 729s 1ms/step - loss: 0.0193 - mae: 0.1078 - val_loss: 0.0167 - val_mae: 0.1005\n",
      "Epoch 2/50\n",
      "664727/664727 [==============================] - 717s 1ms/step - loss: 0.0179 - mae: 0.1042 - val_loss: 0.0189 - val_mae: 0.1060\n",
      "Epoch 3/50\n",
      "664727/664727 [==============================] - 732s 1ms/step - loss: 0.0195 - mae: 0.1095 - val_loss: 0.0207 - val_mae: 0.1133\n",
      "Epoch 4/50\n",
      "664727/664727 [==============================] - 713s 1ms/step - loss: 0.0205 - mae: 0.1122 - val_loss: 0.0247 - val_mae: 0.1248\n",
      "Epoch 5/50\n",
      "664727/664727 [==============================] - 743s 1ms/step - loss: 0.0197 - mae: 0.1100 - val_loss: 0.0170 - val_mae: 0.1018\n",
      "Epoch 6/50\n",
      "664727/664727 [==============================] - 742s 1ms/step - loss: 0.0200 - mae: 0.1111 - val_loss: 0.0190 - val_mae: 0.1072\n",
      "Epoch 7/50\n",
      "664727/664727 [==============================] - 667s 1ms/step - loss: 0.0208 - mae: 0.1130 - val_loss: 0.0191 - val_mae: 0.1088\n",
      "Epoch 8/50\n",
      "664727/664727 [==============================] - 718s 1ms/step - loss: 0.0219 - mae: 0.1160 - val_loss: 0.0221 - val_mae: 0.1151\n",
      "Epoch 9/50\n",
      "664727/664727 [==============================] - 948s 1ms/step - loss: 0.0238 - mae: 0.1205 - val_loss: 0.0269 - val_mae: 0.1297\n",
      "Epoch 10/50\n",
      "664727/664727 [==============================] - 834s 1ms/step - loss: 0.0252 - mae: 0.1256 - val_loss: 0.0232 - val_mae: 0.1207\n",
      "Epoch 11/50\n",
      "664727/664727 [==============================] - 659s 991us/step - loss: 0.0235 - mae: 0.1213 - val_loss: 0.0219 - val_mae: 0.1166\n",
      "Epoch 12/50\n",
      "664727/664727 [==============================] - 607s 913us/step - loss: 0.0212 - mae: 0.1136 - val_loss: 0.0237 - val_mae: 0.1196\n",
      "Epoch 13/50\n",
      "664727/664727 [==============================] - 583s 877us/step - loss: 0.0223 - mae: 0.1166 - val_loss: 0.0261 - val_mae: 0.1270\n",
      "Epoch 14/50\n",
      "664727/664727 [==============================] - 618s 929us/step - loss: 0.0255 - mae: 0.1250 - val_loss: 0.0287 - val_mae: 0.1321\n",
      "Epoch 15/50\n",
      "664727/664727 [==============================] - 718s 1ms/step - loss: 0.0250 - mae: 0.1236 - val_loss: 0.0261 - val_mae: 0.1284\n",
      "Epoch 16/50\n",
      "664727/664727 [==============================] - 694s 1ms/step - loss: 0.0254 - mae: 0.1245 - val_loss: 0.0226 - val_mae: 0.1182\n",
      "Epoch 17/50\n",
      "664727/664727 [==============================] - 689s 1ms/step - loss: 0.0254 - mae: 0.1244 - val_loss: 0.0324 - val_mae: 0.1432\n",
      "Epoch 18/50\n",
      "664727/664727 [==============================] - 647s 974us/step - loss: 0.0278 - mae: 0.1300 - val_loss: 0.0238 - val_mae: 0.1209\n",
      "Epoch 19/50\n",
      "664727/664727 [==============================] - 688s 1ms/step - loss: 0.0276 - mae: 0.1303 - val_loss: 0.0305 - val_mae: 0.1393\n",
      "Epoch 20/50\n",
      "664727/664727 [==============================] - 605s 910us/step - loss: 0.0269 - mae: 0.1288 - val_loss: 0.0260 - val_mae: 0.1283\n",
      "Epoch 21/50\n",
      "664727/664727 [==============================] - 634s 954us/step - loss: 0.0282 - mae: 0.1323 - val_loss: 0.0300 - val_mae: 0.1360\n",
      "Epoch 22/50\n",
      "664727/664727 [==============================] - 732s 1ms/step - loss: 0.0294 - mae: 0.1354 - val_loss: 0.0298 - val_mae: 0.1366\n",
      "Epoch 23/50\n",
      "664727/664727 [==============================] - 749s 1ms/step - loss: 0.0301 - mae: 0.1369 - val_loss: 0.0323 - val_mae: 0.1415\n",
      "Epoch 24/50\n",
      "664727/664727 [==============================] - 612s 921us/step - loss: 0.0334 - mae: 0.1441 - val_loss: 0.0339 - val_mae: 0.1467\n",
      "Epoch 25/50\n",
      "664727/664727 [==============================] - 601s 904us/step - loss: 0.0351 - mae: 0.1483 - val_loss: 0.0309 - val_mae: 0.1408\n",
      "Epoch 26/50\n",
      "664727/664727 [==============================] - 703s 1ms/step - loss: 0.0367 - mae: 0.1523 - val_loss: 0.0386 - val_mae: 0.1590\n",
      "Epoch 27/50\n",
      "664727/664727 [==============================] - 578s 869us/step - loss: 0.0370 - mae: 0.1528 - val_loss: 0.0310 - val_mae: 0.1394\n",
      "Epoch 28/50\n",
      "664727/664727 [==============================] - 621s 935us/step - loss: 0.0371 - mae: 0.1530 - val_loss: 0.0370 - val_mae: 0.1534\n",
      "Epoch 29/50\n",
      "664727/664727 [==============================] - 698s 1ms/step - loss: 0.0373 - mae: 0.1534 - val_loss: 0.0414 - val_mae: 0.1608\n",
      "Epoch 30/50\n",
      "664727/664727 [==============================] - 669s 1ms/step - loss: 0.0370 - mae: 0.1529 - val_loss: 0.0390 - val_mae: 0.1572\n",
      "Epoch 31/50\n",
      "664727/664727 [==============================] - 584s 878us/step - loss: 0.0372 - mae: 0.1530 - val_loss: 0.0360 - val_mae: 0.1507\n",
      "Epoch 32/50\n",
      "664727/664727 [==============================] - 594s 893us/step - loss: 0.0373 - mae: 0.1530 - val_loss: 0.0353 - val_mae: 0.1488\n",
      "Epoch 33/50\n",
      "664727/664727 [==============================] - 589s 886us/step - loss: 0.0375 - mae: 0.1530 - val_loss: 0.0427 - val_mae: 0.1620\n",
      "Epoch 34/50\n",
      "664727/664727 [==============================] - 562s 845us/step - loss: 0.0366 - mae: 0.1522 - val_loss: 0.0359 - val_mae: 0.1501\n",
      "Epoch 35/50\n",
      "664727/664727 [==============================] - 571s 859us/step - loss: 0.0357 - mae: 0.1505 - val_loss: 0.0319 - val_mae: 0.1399\n",
      "Epoch 36/50\n",
      "664727/664727 [==============================] - 574s 864us/step - loss: 0.0327 - mae: 0.1437 - val_loss: 0.0343 - val_mae: 0.1475\n",
      "Epoch 37/50\n",
      "664727/664727 [==============================] - 585s 880us/step - loss: 0.0309 - mae: 0.1389 - val_loss: 0.0257 - val_mae: 0.1268\n",
      "Epoch 38/50\n",
      "664727/664727 [==============================] - 580s 873us/step - loss: 0.0294 - mae: 0.1359 - val_loss: 0.0292 - val_mae: 0.1338\n",
      "Epoch 39/50\n",
      "664727/664727 [==============================] - 570s 857us/step - loss: 0.0306 - mae: 0.1379 - val_loss: 0.0287 - val_mae: 0.1325\n",
      "Epoch 40/50\n",
      "664727/664727 [==============================] - 578s 870us/step - loss: 0.0320 - mae: 0.1406 - val_loss: 0.0290 - val_mae: 0.1344\n",
      "Epoch 41/50\n",
      "664727/664727 [==============================] - 585s 880us/step - loss: 0.0298 - mae: 0.1358 - val_loss: 0.0301 - val_mae: 0.1376\n",
      "Epoch 42/50\n",
      "664727/664727 [==============================] - 569s 856us/step - loss: 0.0310 - mae: 0.1386 - val_loss: 0.0282 - val_mae: 0.1336\n",
      "Epoch 43/50\n",
      "664727/664727 [==============================] - 580s 872us/step - loss: 0.0309 - mae: 0.1396 - val_loss: 0.0295 - val_mae: 0.1348\n",
      "Epoch 44/50\n",
      "664727/664727 [==============================] - 592s 890us/step - loss: 0.0286 - mae: 0.1326 - val_loss: 0.0320 - val_mae: 0.1392\n",
      "Epoch 45/50\n",
      "664727/664727 [==============================] - 593s 893us/step - loss: 0.0294 - mae: 0.1353 - val_loss: 0.0334 - val_mae: 0.1458\n",
      "Epoch 46/50\n",
      "664727/664727 [==============================] - 566s 852us/step - loss: 0.0310 - mae: 0.1386 - val_loss: 0.0330 - val_mae: 0.1423\n",
      "Epoch 47/50\n",
      "664727/664727 [==============================] - 585s 881us/step - loss: 0.0301 - mae: 0.1367 - val_loss: 0.0296 - val_mae: 0.1362\n",
      "Epoch 48/50\n",
      "664727/664727 [==============================] - 596s 897us/step - loss: 0.0289 - mae: 0.1340 - val_loss: 0.0282 - val_mae: 0.1311\n",
      "Epoch 49/50\n",
      "664727/664727 [==============================] - 582s 875us/step - loss: 0.0302 - mae: 0.1364 - val_loss: 0.0536 - val_mae: 0.1840\n",
      "Epoch 50/50\n",
      "664727/664727 [==============================] - 589s 887us/step - loss: 0.0308 - mae: 0.1375 - val_loss: 0.0273 - val_mae: 0.1298\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 1\n",
      "Train on 664727 samples, validate on 166181 samples\n",
      "Epoch 1/50\n",
      "664727/664727 [==============================] - 577s 868us/step - loss: 0.0186 - mae: 0.1055 - val_loss: 0.0171 - val_mae: 0.1015\n",
      "Epoch 2/50\n",
      "664727/664727 [==============================] - 576s 866us/step - loss: 0.0176 - mae: 0.1030 - val_loss: 0.0191 - val_mae: 0.1082\n",
      "Epoch 3/50\n",
      "664727/664727 [==============================] - 587s 884us/step - loss: 0.0177 - mae: 0.1033 - val_loss: 0.0166 - val_mae: 0.0996\n",
      "Epoch 4/50\n",
      "664727/664727 [==============================] - 595s 895us/step - loss: 0.0178 - mae: 0.1035 - val_loss: 0.0179 - val_mae: 0.1048\n",
      "Epoch 5/50\n",
      "664727/664727 [==============================] - 582s 875us/step - loss: 0.0182 - mae: 0.1046 - val_loss: 0.0176 - val_mae: 0.1044\n",
      "Epoch 6/50\n",
      "664727/664727 [==============================] - 576s 867us/step - loss: 0.0185 - mae: 0.1058 - val_loss: 0.0179 - val_mae: 0.1045\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664727/664727 [==============================] - 569s 856us/step - loss: 0.0187 - mae: 0.1067 - val_loss: 0.0210 - val_mae: 0.1147\n",
      "Epoch 8/50\n",
      "664727/664727 [==============================] - 591s 889us/step - loss: 0.0186 - mae: 0.1066 - val_loss: 0.0198 - val_mae: 0.1101\n",
      "Epoch 9/50\n",
      "664727/664727 [==============================] - 573s 862us/step - loss: 0.0186 - mae: 0.1065 - val_loss: 0.0189 - val_mae: 0.1065\n",
      "Epoch 10/50\n",
      "664727/664727 [==============================] - 577s 868us/step - loss: 0.0186 - mae: 0.1064 - val_loss: 0.0171 - val_mae: 0.1001\n",
      "Epoch 11/50\n",
      "664727/664727 [==============================] - 585s 880us/step - loss: 0.0185 - mae: 0.1063 - val_loss: 0.0212 - val_mae: 0.1144\n",
      "Epoch 12/50\n",
      "664727/664727 [==============================] - 599s 902us/step - loss: 0.0185 - mae: 0.1063 - val_loss: 0.0170 - val_mae: 0.1007\n",
      "Epoch 13/50\n",
      "664727/664727 [==============================] - 576s 867us/step - loss: 0.0184 - mae: 0.1061 - val_loss: 0.0190 - val_mae: 0.1075\n",
      "Epoch 14/50\n",
      "664727/664727 [==============================] - 576s 867us/step - loss: 0.0184 - mae: 0.1060 - val_loss: 0.0198 - val_mae: 0.1097\n",
      "Epoch 15/50\n",
      "664727/664727 [==============================] - 576s 866us/step - loss: 0.0184 - mae: 0.1061 - val_loss: 0.0196 - val_mae: 0.1096\n",
      "Epoch 16/50\n",
      "664727/664727 [==============================] - 588s 885us/step - loss: 0.0182 - mae: 0.1053 - val_loss: 0.0177 - val_mae: 0.1053\n",
      "Epoch 17/50\n",
      "664727/664727 [==============================] - 591s 889us/step - loss: 0.0181 - mae: 0.1046 - val_loss: 0.0191 - val_mae: 0.1080\n",
      "Epoch 18/50\n",
      "664727/664727 [==============================] - 581s 874us/step - loss: 0.0185 - mae: 0.1054 - val_loss: 0.0199 - val_mae: 0.1100\n",
      "Epoch 19/50\n",
      "664727/664727 [==============================] - 606s 912us/step - loss: 0.0192 - mae: 0.1079 - val_loss: 0.0194 - val_mae: 0.1082\n",
      "Epoch 20/50\n",
      "664727/664727 [==============================] - 572s 860us/step - loss: 0.0205 - mae: 0.1114 - val_loss: 0.0205 - val_mae: 0.1117\n",
      "Epoch 21/50\n",
      "664727/664727 [==============================] - 597s 899us/step - loss: 0.0223 - mae: 0.1159 - val_loss: 0.0233 - val_mae: 0.1171\n",
      "Epoch 22/50\n",
      "664727/664727 [==============================] - 572s 860us/step - loss: 0.0236 - mae: 0.1197 - val_loss: 0.0232 - val_mae: 0.1176\n",
      "Epoch 23/50\n",
      "664727/664727 [==============================] - 582s 876us/step - loss: 0.0256 - mae: 0.1247 - val_loss: 0.0265 - val_mae: 0.1265\n",
      "Epoch 24/50\n",
      "664727/664727 [==============================] - 582s 875us/step - loss: 0.0276 - mae: 0.1302 - val_loss: 0.0258 - val_mae: 0.1253\n",
      "Epoch 25/50\n",
      "664727/664727 [==============================] - 594s 894us/step - loss: 0.0281 - mae: 0.1312 - val_loss: 0.0254 - val_mae: 0.1236\n",
      "Epoch 26/50\n",
      "664727/664727 [==============================] - 596s 896us/step - loss: 0.0286 - mae: 0.1322 - val_loss: 0.0243 - val_mae: 0.1215\n",
      "Epoch 27/50\n",
      "664727/664727 [==============================] - 577s 868us/step - loss: 0.0294 - mae: 0.1343 - val_loss: 0.0368 - val_mae: 0.1485\n",
      "Epoch 28/50\n",
      "664727/664727 [==============================] - 591s 889us/step - loss: 0.0313 - mae: 0.1384 - val_loss: 0.0278 - val_mae: 0.1303\n",
      "Epoch 29/50\n",
      "664727/664727 [==============================] - 577s 868us/step - loss: 0.0305 - mae: 0.1369 - val_loss: 0.0313 - val_mae: 0.1380\n",
      "Epoch 30/50\n",
      "664727/664727 [==============================] - 588s 884us/step - loss: 0.0329 - mae: 0.1423 - val_loss: 0.0338 - val_mae: 0.1421\n",
      "Epoch 31/50\n",
      "664727/664727 [==============================] - 581s 874us/step - loss: 0.0335 - mae: 0.1440 - val_loss: 0.0322 - val_mae: 0.1419\n",
      "Epoch 32/50\n",
      "664727/664727 [==============================] - 576s 867us/step - loss: 0.0337 - mae: 0.1447 - val_loss: 0.0364 - val_mae: 0.1526\n",
      "Epoch 33/50\n",
      "664727/664727 [==============================] - 577s 869us/step - loss: 0.0335 - mae: 0.1442 - val_loss: 0.0310 - val_mae: 0.1406\n",
      "Epoch 34/50\n",
      "664727/664727 [==============================] - 596s 896us/step - loss: 0.0335 - mae: 0.1444 - val_loss: 0.0440 - val_mae: 0.1651\n",
      "Epoch 35/50\n",
      "664727/664727 [==============================] - 609s 916us/step - loss: 0.0334 - mae: 0.1445 - val_loss: 0.0323 - val_mae: 0.1426\n",
      "Epoch 36/50\n",
      "664727/664727 [==============================] - 645s 971us/step - loss: 0.0336 - mae: 0.1451 - val_loss: 0.0308 - val_mae: 0.1404\n",
      "Epoch 37/50\n",
      "664727/664727 [==============================] - 667s 1ms/step - loss: 0.0338 - mae: 0.1456 - val_loss: 0.0302 - val_mae: 0.1379\n",
      "Epoch 38/50\n",
      "664727/664727 [==============================] - 673s 1ms/step - loss: 0.0340 - mae: 0.1460 - val_loss: 0.0321 - val_mae: 0.1416\n",
      "Epoch 39/50\n",
      "664727/664727 [==============================] - 619s 931us/step - loss: 0.0342 - mae: 0.1464 - val_loss: 0.0356 - val_mae: 0.1513\n",
      "Epoch 40/50\n",
      "664727/664727 [==============================] - 657s 988us/step - loss: 0.0327 - mae: 0.1434 - val_loss: 0.0347 - val_mae: 0.1460\n",
      "Epoch 41/50\n",
      "664727/664727 [==============================] - 673s 1ms/step - loss: 0.0324 - mae: 0.1423 - val_loss: 0.0336 - val_mae: 0.1444\n",
      "Epoch 42/50\n",
      "664727/664727 [==============================] - 651s 979us/step - loss: 0.0337 - mae: 0.1436 - val_loss: 0.0367 - val_mae: 0.1442\n",
      "Epoch 43/50\n",
      "664727/664727 [==============================] - 586s 882us/step - loss: 0.0349 - mae: 0.1466 - val_loss: 0.0371 - val_mae: 0.1555\n",
      "Epoch 44/50\n",
      "664727/664727 [==============================] - 665s 1000us/step - loss: 0.0318 - mae: 0.1405 - val_loss: 0.0282 - val_mae: 0.1319\n",
      "Epoch 45/50\n",
      "664727/664727 [==============================] - 591s 890us/step - loss: 0.0284 - mae: 0.1329 - val_loss: 0.0279 - val_mae: 0.1305\n",
      "Epoch 46/50\n",
      "664727/664727 [==============================] - 646s 972us/step - loss: 0.0277 - mae: 0.1309 - val_loss: 0.0269 - val_mae: 0.1271\n",
      "Epoch 47/50\n",
      "664727/664727 [==============================] - 781s 1ms/step - loss: 0.0306 - mae: 0.1379 - val_loss: 0.0280 - val_mae: 0.1328\n",
      "Epoch 48/50\n",
      "664727/664727 [==============================] - 693s 1ms/step - loss: 0.0288 - mae: 0.1331 - val_loss: 0.0267 - val_mae: 0.1278\n",
      "Epoch 49/50\n",
      "664727/664727 [==============================] - 576s 866us/step - loss: 0.0272 - mae: 0.1297 - val_loss: 0.0276 - val_mae: 0.1317\n",
      "Epoch 50/50\n",
      "664727/664727 [==============================] - 601s 904us/step - loss: 0.0277 - mae: 0.1314 - val_loss: 0.0274 - val_mae: 0.1314\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 2\n",
      "Train on 664727 samples, validate on 166181 samples\n",
      "Epoch 1/50\n",
      "664727/664727 [==============================] - 619s 932us/step - loss: 0.0209 - mae: 0.1127 - val_loss: 0.0178 - val_mae: 0.1034\n",
      "Epoch 2/50\n",
      "664727/664727 [==============================] - 753s 1ms/step - loss: 0.0204 - mae: 0.1118 - val_loss: 0.0204 - val_mae: 0.1121\n",
      "Epoch 3/50\n",
      "664727/664727 [==============================] - 646s 972us/step - loss: 0.0207 - mae: 0.1122 - val_loss: 0.0226 - val_mae: 0.1197\n",
      "Epoch 4/50\n",
      "664727/664727 [==============================] - 591s 889us/step - loss: 0.0216 - mae: 0.1147 - val_loss: 0.0199 - val_mae: 0.1101\n",
      "Epoch 5/50\n",
      "664727/664727 [==============================] - 591s 889us/step - loss: 0.0224 - mae: 0.1171 - val_loss: 0.0229 - val_mae: 0.1181\n",
      "Epoch 6/50\n",
      "664727/664727 [==============================] - 569s 855us/step - loss: 0.0232 - mae: 0.1192 - val_loss: 0.0219 - val_mae: 0.1160\n",
      "Epoch 7/50\n",
      "664727/664727 [==============================] - 588s 885us/step - loss: 0.0238 - mae: 0.1209 - val_loss: 0.0300 - val_mae: 0.1394\n",
      "Epoch 8/50\n",
      "664727/664727 [==============================] - 575s 864us/step - loss: 0.0244 - mae: 0.1225 - val_loss: 0.0249 - val_mae: 0.1254\n",
      "Epoch 9/50\n",
      "664727/664727 [==============================] - 583s 877us/step - loss: 0.0248 - mae: 0.1234 - val_loss: 0.0213 - val_mae: 0.1137\n",
      "Epoch 10/50\n",
      "664727/664727 [==============================] - 565s 850us/step - loss: 0.0248 - mae: 0.1235 - val_loss: 0.0215 - val_mae: 0.1158\n",
      "Epoch 11/50\n",
      "664727/664727 [==============================] - 10566s 16ms/step - loss: 0.0241 - mae: 0.1219 - val_loss: 0.0227 - val_mae: 0.1188\n",
      "Epoch 12/50\n",
      "664727/664727 [==============================] - 872s 1ms/step - loss: 0.0234 - mae: 0.1201 - val_loss: 0.0192 - val_mae: 0.1089\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664727/664727 [==============================] - 725s 1ms/step - loss: 0.0228 - mae: 0.1187 - val_loss: 0.0179 - val_mae: 0.1052\n",
      "Epoch 14/50\n",
      "664727/664727 [==============================] - 718s 1ms/step - loss: 0.0225 - mae: 0.1180 - val_loss: 0.0185 - val_mae: 0.1066\n",
      "Epoch 15/50\n",
      "664727/664727 [==============================] - 660s 994us/step - loss: 0.0224 - mae: 0.1178 - val_loss: 0.0207 - val_mae: 0.1138\n",
      "Epoch 16/50\n",
      "664727/664727 [==============================] - 641s 964us/step - loss: 0.0225 - mae: 0.1178 - val_loss: 0.0232 - val_mae: 0.1201\n",
      "Epoch 17/50\n",
      "664727/664727 [==============================] - 652s 982us/step - loss: 0.0225 - mae: 0.1180 - val_loss: 0.0198 - val_mae: 0.1123\n",
      "Epoch 18/50\n",
      "664727/664727 [==============================] - 610s 918us/step - loss: 0.0226 - mae: 0.1182 - val_loss: 0.0198 - val_mae: 0.1102\n",
      "Epoch 19/50\n",
      "664727/664727 [==============================] - 606s 912us/step - loss: 0.0226 - mae: 0.1183 - val_loss: 0.0213 - val_mae: 0.1165\n",
      "Epoch 20/50\n",
      "664727/664727 [==============================] - 612s 920us/step - loss: 0.0226 - mae: 0.1184 - val_loss: 0.0203 - val_mae: 0.1110\n",
      "Epoch 21/50\n",
      "664727/664727 [==============================] - 604s 908us/step - loss: 0.0227 - mae: 0.1184 - val_loss: 0.0203 - val_mae: 0.1118\n",
      "Epoch 22/50\n",
      "664727/664727 [==============================] - 578s 870us/step - loss: 0.0227 - mae: 0.1185 - val_loss: 0.0190 - val_mae: 0.1081\n",
      "Epoch 23/50\n",
      "664727/664727 [==============================] - 658s 990us/step - loss: 0.0228 - mae: 0.1188 - val_loss: 0.0222 - val_mae: 0.1169\n",
      "Epoch 24/50\n",
      "664727/664727 [==============================] - 618s 930us/step - loss: 0.0228 - mae: 0.1188 - val_loss: 0.0195 - val_mae: 0.1096\n",
      "Epoch 25/50\n",
      "664727/664727 [==============================] - 605s 910us/step - loss: 0.0228 - mae: 0.1188 - val_loss: 0.0273 - val_mae: 0.1317\n",
      "Epoch 26/50\n",
      "664727/664727 [==============================] - 640s 963us/step - loss: 0.0229 - mae: 0.1190 - val_loss: 0.0202 - val_mae: 0.1117\n",
      "Epoch 27/50\n",
      "664727/664727 [==============================] - 647s 974us/step - loss: 0.0229 - mae: 0.1193 - val_loss: 0.0231 - val_mae: 0.1193\n",
      "Epoch 28/50\n",
      "664727/664727 [==============================] - 584s 879us/step - loss: 0.0231 - mae: 0.1197 - val_loss: 0.0213 - val_mae: 0.1168\n",
      "Epoch 29/50\n",
      "664727/664727 [==============================] - 583s 877us/step - loss: 0.0233 - mae: 0.1203 - val_loss: 0.0260 - val_mae: 0.1265\n",
      "Epoch 30/50\n",
      "664727/664727 [==============================] - 638s 960us/step - loss: 0.0235 - mae: 0.1206 - val_loss: 0.0430 - val_mae: 0.1658\n",
      "Epoch 31/50\n",
      "664727/664727 [==============================] - 700s 1ms/step - loss: 0.0237 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1183\n",
      "Epoch 32/50\n",
      "664727/664727 [==============================] - 661s 995us/step - loss: 0.0238 - mae: 0.1215 - val_loss: 0.0234 - val_mae: 0.1211\n",
      "Epoch 33/50\n",
      "664727/664727 [==============================] - 717s 1ms/step - loss: 0.0239 - mae: 0.1216 - val_loss: 0.0205 - val_mae: 0.1133\n",
      "Epoch 34/50\n",
      "664727/664727 [==============================] - 690s 1ms/step - loss: 0.0237 - mae: 0.1212 - val_loss: 0.0184 - val_mae: 0.1057\n",
      "Epoch 35/50\n",
      "664727/664727 [==============================] - 689s 1ms/step - loss: 0.0234 - mae: 0.1204 - val_loss: 0.0279 - val_mae: 0.1315\n",
      "Epoch 36/50\n",
      "664727/664727 [==============================] - 615s 926us/step - loss: 0.0232 - mae: 0.1198 - val_loss: 0.0275 - val_mae: 0.1343\n",
      "Epoch 37/50\n",
      "664727/664727 [==============================] - 583s 877us/step - loss: 0.0231 - mae: 0.1196 - val_loss: 0.0220 - val_mae: 0.1163\n",
      "Epoch 38/50\n",
      "664727/664727 [==============================] - 637s 959us/step - loss: 0.0231 - mae: 0.1197 - val_loss: 0.0211 - val_mae: 0.1137\n",
      "Epoch 39/50\n",
      "664727/664727 [==============================] - 660s 993us/step - loss: 0.0231 - mae: 0.1198 - val_loss: 0.0335 - val_mae: 0.1477\n",
      "Epoch 40/50\n",
      "664727/664727 [==============================] - 734s 1ms/step - loss: 0.0231 - mae: 0.1199 - val_loss: 0.0199 - val_mae: 0.1116\n",
      "Epoch 41/50\n",
      "664727/664727 [==============================] - 660s 993us/step - loss: 0.0232 - mae: 0.1200 - val_loss: 0.0263 - val_mae: 0.1294\n",
      "Epoch 42/50\n",
      "664727/664727 [==============================] - 639s 962us/step - loss: 0.0232 - mae: 0.1201 - val_loss: 0.0190 - val_mae: 0.1082\n",
      "Epoch 43/50\n",
      "664727/664727 [==============================] - 622s 936us/step - loss: 0.0232 - mae: 0.1201 - val_loss: 0.0201 - val_mae: 0.1107\n",
      "Epoch 44/50\n",
      "664727/664727 [==============================] - 595s 895us/step - loss: 0.0233 - mae: 0.1202 - val_loss: 0.0290 - val_mae: 0.1373\n",
      "Epoch 45/50\n",
      "664727/664727 [==============================] - 590s 887us/step - loss: 0.0233 - mae: 0.1203 - val_loss: 0.0202 - val_mae: 0.1117\n",
      "Epoch 46/50\n",
      "664727/664727 [==============================] - 603s 907us/step - loss: 0.0233 - mae: 0.1203 - val_loss: 0.0201 - val_mae: 0.1098\n",
      "Epoch 47/50\n",
      "664727/664727 [==============================] - 606s 912us/step - loss: 0.0233 - mae: 0.1203 - val_loss: 0.0214 - val_mae: 0.1150\n",
      "Epoch 48/50\n",
      "664727/664727 [==============================] - 603s 907us/step - loss: 0.0233 - mae: 0.1204 - val_loss: 0.0290 - val_mae: 0.1366\n",
      "Epoch 49/50\n",
      "664727/664727 [==============================] - 670s 1ms/step - loss: 0.0233 - mae: 0.1204 - val_loss: 0.0198 - val_mae: 0.1113\n",
      "Epoch 50/50\n",
      "664727/664727 [==============================] - 629s 947us/step - loss: 0.0233 - mae: 0.1204 - val_loss: 0.0214 - val_mae: 0.1161\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 3\n",
      "Train on 664727 samples, validate on 166181 samples\n",
      "Epoch 1/50\n",
      "664727/664727 [==============================] - 620s 932us/step - loss: 0.0268 - mae: 0.1291 - val_loss: 0.0252 - val_mae: 0.1253\n",
      "Epoch 2/50\n",
      "664727/664727 [==============================] - 643s 967us/step - loss: 0.0227 - mae: 0.1187 - val_loss: 0.0218 - val_mae: 0.1162\n",
      "Epoch 3/50\n",
      "664727/664727 [==============================] - 604s 909us/step - loss: 0.0224 - mae: 0.1178 - val_loss: 0.0221 - val_mae: 0.1164\n",
      "Epoch 4/50\n",
      "664727/664727 [==============================] - 592s 890us/step - loss: 0.0233 - mae: 0.1190 - val_loss: 0.0219 - val_mae: 0.1132\n",
      "Epoch 5/50\n",
      "664727/664727 [==============================] - 610s 918us/step - loss: 0.0258 - mae: 0.1251 - val_loss: 0.0234 - val_mae: 0.1189\n",
      "Epoch 6/50\n",
      "664727/664727 [==============================] - 598s 900us/step - loss: 0.0246 - mae: 0.1222 - val_loss: 0.0200 - val_mae: 0.1103\n",
      "Epoch 7/50\n",
      "664727/664727 [==============================] - 612s 920us/step - loss: 0.0231 - mae: 0.1183 - val_loss: 0.0241 - val_mae: 0.1223\n",
      "Epoch 8/50\n",
      "664727/664727 [==============================] - 610s 918us/step - loss: 0.0215 - mae: 0.1143 - val_loss: 0.0263 - val_mae: 0.1283\n",
      "Epoch 9/50\n",
      "664727/664727 [==============================] - 604s 908us/step - loss: 0.0213 - mae: 0.1140 - val_loss: 0.0215 - val_mae: 0.1154\n",
      "Epoch 10/50\n",
      "664727/664727 [==============================] - 614s 923us/step - loss: 0.0243 - mae: 0.1217 - val_loss: 0.0224 - val_mae: 0.1171\n",
      "Epoch 11/50\n",
      "664727/664727 [==============================] - 618s 930us/step - loss: 0.0264 - mae: 0.1267 - val_loss: 0.0257 - val_mae: 0.1269\n",
      "Epoch 12/50\n",
      "664727/664727 [==============================] - 616s 926us/step - loss: 0.0297 - mae: 0.1357 - val_loss: 0.0317 - val_mae: 0.1411\n",
      "Epoch 13/50\n",
      "664727/664727 [==============================] - 606s 911us/step - loss: 0.0323 - mae: 0.1412 - val_loss: 0.0351 - val_mae: 0.1485\n",
      "Epoch 14/50\n",
      "664727/664727 [==============================] - 609s 917us/step - loss: 0.0324 - mae: 0.1410 - val_loss: 0.0294 - val_mae: 0.1332\n",
      "Epoch 15/50\n",
      "664727/664727 [==============================] - 607s 913us/step - loss: 0.0322 - mae: 0.1408 - val_loss: 0.0332 - val_mae: 0.1385\n",
      "Epoch 16/50\n",
      "664727/664727 [==============================] - 619s 931us/step - loss: 0.0325 - mae: 0.1418 - val_loss: 0.0343 - val_mae: 0.1461\n",
      "Epoch 17/50\n",
      "664727/664727 [==============================] - 610s 918us/step - loss: 0.0328 - mae: 0.1426 - val_loss: 0.0395 - val_mae: 0.1558\n",
      "Epoch 18/50\n",
      "664727/664727 [==============================] - 618s 929us/step - loss: 0.0335 - mae: 0.1441 - val_loss: 0.0369 - val_mae: 0.1511\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664727/664727 [==============================] - 576s 867us/step - loss: 0.0344 - mae: 0.1460 - val_loss: 0.0422 - val_mae: 0.1650\n",
      "Epoch 20/50\n",
      "664727/664727 [==============================] - 594s 894us/step - loss: 0.0346 - mae: 0.1467 - val_loss: 0.0377 - val_mae: 0.1490\n",
      "Epoch 21/50\n",
      "664727/664727 [==============================] - 585s 881us/step - loss: 0.0347 - mae: 0.1469 - val_loss: 0.0378 - val_mae: 0.1548\n",
      "Epoch 22/50\n",
      "664727/664727 [==============================] - 596s 897us/step - loss: 0.0348 - mae: 0.1473 - val_loss: 0.0296 - val_mae: 0.1358\n",
      "Epoch 23/50\n",
      "664727/664727 [==============================] - 584s 878us/step - loss: 0.0349 - mae: 0.1474 - val_loss: 0.0467 - val_mae: 0.1707\n",
      "Epoch 24/50\n",
      "664727/664727 [==============================] - 584s 879us/step - loss: 0.0351 - mae: 0.1476 - val_loss: 0.0331 - val_mae: 0.1453\n",
      "Epoch 25/50\n",
      "664727/664727 [==============================] - 588s 884us/step - loss: 0.0352 - mae: 0.1477 - val_loss: 0.0445 - val_mae: 0.1670\n",
      "Epoch 26/50\n",
      "664727/664727 [==============================] - 598s 900us/step - loss: 0.0353 - mae: 0.1479 - val_loss: 0.0296 - val_mae: 0.1357\n",
      "Epoch 27/50\n",
      "664727/664727 [==============================] - 582s 875us/step - loss: 0.0354 - mae: 0.1480 - val_loss: 0.0300 - val_mae: 0.1330\n",
      "Epoch 28/50\n",
      "664727/664727 [==============================] - 590s 888us/step - loss: 0.0355 - mae: 0.1483 - val_loss: 0.0325 - val_mae: 0.1446\n",
      "Epoch 29/50\n",
      "664727/664727 [==============================] - 591s 888us/step - loss: 0.0355 - mae: 0.1481 - val_loss: 0.0337 - val_mae: 0.1471\n",
      "Epoch 30/50\n",
      "664727/664727 [==============================] - 601s 905us/step - loss: 0.0355 - mae: 0.1483 - val_loss: 0.0325 - val_mae: 0.1405\n",
      "Epoch 31/50\n",
      "664727/664727 [==============================] - 585s 879us/step - loss: 0.0357 - mae: 0.1487 - val_loss: 0.0294 - val_mae: 0.1349\n",
      "Epoch 32/50\n",
      "664727/664727 [==============================] - 601s 904us/step - loss: 0.0357 - mae: 0.1490 - val_loss: 0.0364 - val_mae: 0.1532\n",
      "Epoch 33/50\n",
      "664727/664727 [==============================] - 588s 884us/step - loss: 0.0360 - mae: 0.1497 - val_loss: 0.0440 - val_mae: 0.1660\n",
      "Epoch 34/50\n",
      "664727/664727 [==============================] - 605s 911us/step - loss: 0.0360 - mae: 0.1499 - val_loss: 0.0448 - val_mae: 0.1675\n",
      "Epoch 35/50\n",
      "664727/664727 [==============================] - 594s 894us/step - loss: 0.0362 - mae: 0.1505 - val_loss: 0.0330 - val_mae: 0.1444\n",
      "Epoch 36/50\n",
      "664727/664727 [==============================] - 602s 906us/step - loss: 0.0363 - mae: 0.1508 - val_loss: 0.0425 - val_mae: 0.1627\n",
      "Epoch 37/50\n",
      "664727/664727 [==============================] - 582s 875us/step - loss: 0.0363 - mae: 0.1511 - val_loss: 0.0342 - val_mae: 0.1488\n",
      "Epoch 38/50\n",
      "664727/664727 [==============================] - 603s 907us/step - loss: 0.0359 - mae: 0.1505 - val_loss: 0.0356 - val_mae: 0.1497\n",
      "Epoch 39/50\n",
      "664727/664727 [==============================] - 606s 912us/step - loss: 0.0353 - mae: 0.1490 - val_loss: 0.0350 - val_mae: 0.1493\n",
      "Epoch 40/50\n",
      "664727/664727 [==============================] - 587s 882us/step - loss: 0.0330 - mae: 0.1433 - val_loss: 0.0302 - val_mae: 0.1369\n",
      "Epoch 41/50\n",
      "664727/664727 [==============================] - 585s 881us/step - loss: 0.0303 - mae: 0.1368 - val_loss: 0.0311 - val_mae: 0.1396\n",
      "Epoch 42/50\n",
      "664727/664727 [==============================] - 577s 869us/step - loss: 0.0297 - mae: 0.1351 - val_loss: 0.0269 - val_mae: 0.1290\n",
      "Epoch 43/50\n",
      "664727/664727 [==============================] - 598s 900us/step - loss: 0.0302 - mae: 0.1361 - val_loss: 0.0321 - val_mae: 0.1377\n",
      "Epoch 44/50\n",
      "664727/664727 [==============================] - 619s 931us/step - loss: 0.0308 - mae: 0.1377 - val_loss: 0.0312 - val_mae: 0.1364\n",
      "Epoch 45/50\n",
      "664727/664727 [==============================] - 586s 881us/step - loss: 0.0314 - mae: 0.1390 - val_loss: 0.0294 - val_mae: 0.1337\n",
      "Epoch 46/50\n",
      "664727/664727 [==============================] - 595s 896us/step - loss: 0.0318 - mae: 0.1391 - val_loss: 0.0297 - val_mae: 0.1322\n",
      "Epoch 47/50\n",
      "664727/664727 [==============================] - 587s 884us/step - loss: 0.0325 - mae: 0.1406 - val_loss: 0.0339 - val_mae: 0.1447\n",
      "Epoch 48/50\n",
      "664727/664727 [==============================] - 603s 907us/step - loss: 0.0331 - mae: 0.1422 - val_loss: 0.0330 - val_mae: 0.1434\n",
      "Epoch 49/50\n",
      "664727/664727 [==============================] - 613s 922us/step - loss: 0.0336 - mae: 0.1434 - val_loss: 0.0394 - val_mae: 0.1577\n",
      "Epoch 50/50\n",
      "664727/664727 [==============================] - 581s 874us/step - loss: 0.0338 - mae: 0.1439 - val_loss: 0.0348 - val_mae: 0.1482\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 4\n",
      "Train on 664727 samples, validate on 166181 samples\n",
      "Epoch 1/50\n",
      "664727/664727 [==============================] - 605s 910us/step - loss: 0.0249 - mae: 0.1227 - val_loss: 0.0221 - val_mae: 0.1157\n",
      "Epoch 2/50\n",
      "664727/664727 [==============================] - 600s 903us/step - loss: 0.0211 - mae: 0.1129 - val_loss: 0.0196 - val_mae: 0.1088\n",
      "Epoch 3/50\n",
      "664727/664727 [==============================] - 585s 879us/step - loss: 0.0205 - mae: 0.1120 - val_loss: 0.0230 - val_mae: 0.1167\n",
      "Epoch 4/50\n",
      "664727/664727 [==============================] - 615s 926us/step - loss: 0.0196 - mae: 0.1092 - val_loss: 0.0186 - val_mae: 0.1072\n",
      "Epoch 5/50\n",
      "664727/664727 [==============================] - 600s 903us/step - loss: 0.0196 - mae: 0.1096 - val_loss: 0.0191 - val_mae: 0.1064\n",
      "Epoch 6/50\n",
      "664727/664727 [==============================] - 590s 887us/step - loss: 0.0196 - mae: 0.1099 - val_loss: 0.0197 - val_mae: 0.1112\n",
      "Epoch 7/50\n",
      "664727/664727 [==============================] - 618s 930us/step - loss: 0.0193 - mae: 0.1091 - val_loss: 0.0195 - val_mae: 0.1101\n",
      "Epoch 8/50\n",
      "664727/664727 [==============================] - 590s 887us/step - loss: 0.0189 - mae: 0.1079 - val_loss: 0.0171 - val_mae: 0.1026\n",
      "Epoch 9/50\n",
      "664727/664727 [==============================] - 577s 867us/step - loss: 0.0189 - mae: 0.1079 - val_loss: 0.0186 - val_mae: 0.1081\n",
      "Epoch 10/50\n",
      "664727/664727 [==============================] - 633s 953us/step - loss: 0.0191 - mae: 0.1085 - val_loss: 0.0176 - val_mae: 0.1049\n",
      "Epoch 11/50\n",
      "664727/664727 [==============================] - 668s 1ms/step - loss: 0.0198 - mae: 0.1104 - val_loss: 0.0177 - val_mae: 0.1051\n",
      "Epoch 12/50\n",
      "664727/664727 [==============================] - 587s 884us/step - loss: 0.0208 - mae: 0.1129 - val_loss: 0.0201 - val_mae: 0.1103\n",
      "Epoch 13/50\n",
      "664727/664727 [==============================] - 602s 906us/step - loss: 0.0212 - mae: 0.1143 - val_loss: 0.0192 - val_mae: 0.1077\n",
      "Epoch 14/50\n",
      "664727/664727 [==============================] - 611s 919us/step - loss: 0.0215 - mae: 0.1149 - val_loss: 0.0183 - val_mae: 0.1053\n",
      "Epoch 15/50\n",
      "664727/664727 [==============================] - 603s 908us/step - loss: 0.0215 - mae: 0.1150 - val_loss: 0.0214 - val_mae: 0.1156\n",
      "Epoch 16/50\n",
      "664727/664727 [==============================] - 583s 877us/step - loss: 0.0216 - mae: 0.1152 - val_loss: 0.0220 - val_mae: 0.1166\n",
      "Epoch 17/50\n",
      "664727/664727 [==============================] - 604s 909us/step - loss: 0.0216 - mae: 0.1152 - val_loss: 0.0197 - val_mae: 0.1096\n",
      "Epoch 18/50\n",
      "664727/664727 [==============================] - 592s 891us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0265 - val_mae: 0.1303\n",
      "Epoch 19/50\n",
      "664727/664727 [==============================] - 617s 928us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0237 - val_mae: 0.1229\n",
      "Epoch 20/50\n",
      "664727/664727 [==============================] - 590s 887us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0217 - val_mae: 0.1153\n",
      "Epoch 21/50\n",
      "664727/664727 [==============================] - 589s 887us/step - loss: 0.0218 - mae: 0.1158 - val_loss: 0.0188 - val_mae: 0.1066\n",
      "Epoch 22/50\n",
      "664727/664727 [==============================] - 593s 892us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0180 - val_mae: 0.1050\n",
      "Epoch 23/50\n",
      "664727/664727 [==============================] - 579s 871us/step - loss: 0.0217 - mae: 0.1155 - val_loss: 0.0182 - val_mae: 0.1037\n",
      "Epoch 24/50\n",
      "664727/664727 [==============================] - 598s 900us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0210 - val_mae: 0.1140\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664727/664727 [==============================] - 605s 910us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0247 - val_mae: 0.1251\n",
      "Epoch 26/50\n",
      "664727/664727 [==============================] - 582s 876us/step - loss: 0.0218 - mae: 0.1158 - val_loss: 0.0196 - val_mae: 0.1103\n",
      "Epoch 27/50\n",
      "664727/664727 [==============================] - 603s 907us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0211 - val_mae: 0.1145\n",
      "Epoch 28/50\n",
      "664727/664727 [==============================] - 612s 921us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0194 - val_mae: 0.1084\n",
      "Epoch 29/50\n",
      "664727/664727 [==============================] - 627s 944us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0215 - val_mae: 0.1165\n",
      "Epoch 30/50\n",
      "664727/664727 [==============================] - 618s 929us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0210 - val_mae: 0.1127\n",
      "Epoch 31/50\n",
      "664727/664727 [==============================] - 609s 916us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0215 - val_mae: 0.1158\n",
      "Epoch 32/50\n",
      "664727/664727 [==============================] - 618s 930us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0177 - val_mae: 0.1040\n",
      "Epoch 33/50\n",
      "664727/664727 [==============================] - 622s 936us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0284 - val_mae: 0.1336\n",
      "Epoch 34/50\n",
      "664727/664727 [==============================] - 613s 923us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0196 - val_mae: 0.1105\n",
      "Epoch 35/50\n",
      "664727/664727 [==============================] - 610s 917us/step - loss: 0.0217 - mae: 0.1155 - val_loss: 0.0294 - val_mae: 0.1354\n",
      "Epoch 36/50\n",
      "664727/664727 [==============================] - 609s 916us/step - loss: 0.0216 - mae: 0.1154 - val_loss: 0.0210 - val_mae: 0.1152\n",
      "Epoch 37/50\n",
      "664727/664727 [==============================] - 599s 901us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0255 - val_mae: 0.1273\n",
      "Epoch 38/50\n",
      "664727/664727 [==============================] - 601s 904us/step - loss: 0.0217 - mae: 0.1156 - val_loss: 0.0220 - val_mae: 0.1161\n",
      "Epoch 39/50\n",
      "664727/664727 [==============================] - 616s 927us/step - loss: 0.0217 - mae: 0.1157 - val_loss: 0.0266 - val_mae: 0.1278\n",
      "Epoch 40/50\n",
      "664727/664727 [==============================] - 646s 971us/step - loss: 0.0217 - mae: 0.1155 - val_loss: 0.0179 - val_mae: 0.1055\n",
      "Epoch 41/50\n",
      "664727/664727 [==============================] - 645s 970us/step - loss: 0.0216 - mae: 0.1153 - val_loss: 0.0198 - val_mae: 0.1084\n",
      "Epoch 42/50\n",
      "664727/664727 [==============================] - 629s 946us/step - loss: 0.0216 - mae: 0.1154 - val_loss: 0.0198 - val_mae: 0.1111\n",
      "Epoch 43/50\n",
      "664727/664727 [==============================] - 645s 970us/step - loss: 0.0216 - mae: 0.1154 - val_loss: 0.0221 - val_mae: 0.1171\n",
      "Epoch 44/50\n",
      "664727/664727 [==============================] - 631s 949us/step - loss: 0.0216 - mae: 0.1154 - val_loss: 0.0179 - val_mae: 0.1053\n",
      "Epoch 45/50\n",
      "664727/664727 [==============================] - 649s 977us/step - loss: 0.0216 - mae: 0.1153 - val_loss: 0.0201 - val_mae: 0.1107\n",
      "Epoch 46/50\n",
      "664727/664727 [==============================] - 659s 991us/step - loss: 0.0217 - mae: 0.1155 - val_loss: 0.0312 - val_mae: 0.1411\n",
      "Epoch 47/50\n",
      "664727/664727 [==============================] - 658s 989us/step - loss: 0.0217 - mae: 0.1155 - val_loss: 0.0231 - val_mae: 0.1183\n",
      "Epoch 48/50\n",
      "664727/664727 [==============================] - 592s 890us/step - loss: 0.0216 - mae: 0.1155 - val_loss: 0.0197 - val_mae: 0.1106\n",
      "Epoch 49/50\n",
      "664727/664727 [==============================] - 741s 1ms/step - loss: 0.0216 - mae: 0.1153 - val_loss: 0.0252 - val_mae: 0.1248\n",
      "Epoch 50/50\n",
      "664727/664727 [==============================] - 805s 1ms/step - loss: 0.0216 - mae: 0.1154 - val_loss: 0.0216 - val_mae: 0.1156\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "num_val_samples = len(train_inputs) // k\n",
    "validation_scores = []\n",
    "num_epochs = 50\n",
    "all_mae_histories = []\n",
    "nmse = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples] \n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_inputs[:i * num_val_samples],\n",
    "         train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "    \n",
    " \n",
    "    model = get_model(train_inputs)\n",
    "    \n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    print(history.history.keys())\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    \n",
    "    predictions_targets = model.predict(val_data)\n",
    "    nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.5607586855711927\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse))\n",
    "\n",
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1110001, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "      <td>1.110001e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.025081e-01</td>\n",
       "      <td>5.137311e-01</td>\n",
       "      <td>5.029814e-01</td>\n",
       "      <td>4.994705e-01</td>\n",
       "      <td>4.991581e-01</td>\n",
       "      <td>4.999980e-01</td>\n",
       "      <td>2.491424e-01</td>\n",
       "      <td>2.369523e-01</td>\n",
       "      <td>2.351461e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.566096e-01</td>\n",
       "      <td>2.289987e-01</td>\n",
       "      <td>5.045379e-01</td>\n",
       "      <td>5.023748e-01</td>\n",
       "      <td>4.896848e-01</td>\n",
       "      <td>4.906998e-01</td>\n",
       "      <td>5.382509e-01</td>\n",
       "      <td>4.871383e-01</td>\n",
       "      <td>4.883274e-01</td>\n",
       "      <td>4.827896e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.886755e-01</td>\n",
       "      <td>2.726448e-01</td>\n",
       "      <td>2.641271e-01</td>\n",
       "      <td>2.900229e-01</td>\n",
       "      <td>3.232297e-01</td>\n",
       "      <td>3.089054e-01</td>\n",
       "      <td>2.584209e-02</td>\n",
       "      <td>1.373419e-01</td>\n",
       "      <td>1.473428e-01</td>\n",
       "      <td>1.447032e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.474400e-01</td>\n",
       "      <td>1.330272e-01</td>\n",
       "      <td>6.525044e-02</td>\n",
       "      <td>6.475618e-02</td>\n",
       "      <td>6.054986e-02</td>\n",
       "      <td>6.117374e-02</td>\n",
       "      <td>5.648393e-02</td>\n",
       "      <td>5.592453e-02</td>\n",
       "      <td>6.472175e-02</td>\n",
       "      <td>6.201368e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.579933e-01</td>\n",
       "      <td>2.790194e-01</td>\n",
       "      <td>2.534673e-01</td>\n",
       "      <td>1.670239e-01</td>\n",
       "      <td>1.958396e-01</td>\n",
       "      <td>4.999977e-01</td>\n",
       "      <td>1.389283e-01</td>\n",
       "      <td>1.105549e-01</td>\n",
       "      <td>1.135286e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.301613e-01</td>\n",
       "      <td>1.216215e-01</td>\n",
       "      <td>4.728892e-01</td>\n",
       "      <td>4.729581e-01</td>\n",
       "      <td>4.624096e-01</td>\n",
       "      <td>4.609610e-01</td>\n",
       "      <td>5.114513e-01</td>\n",
       "      <td>4.631514e-01</td>\n",
       "      <td>4.599116e-01</td>\n",
       "      <td>4.527951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.109220e-01</td>\n",
       "      <td>5.199541e-01</td>\n",
       "      <td>4.987691e-01</td>\n",
       "      <td>5.005303e-01</td>\n",
       "      <td>5.005646e-01</td>\n",
       "      <td>4.999981e-01</td>\n",
       "      <td>2.249761e-01</td>\n",
       "      <td>2.159326e-01</td>\n",
       "      <td>2.137655e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.295932e-01</td>\n",
       "      <td>2.074250e-01</td>\n",
       "      <td>5.045079e-01</td>\n",
       "      <td>5.023648e-01</td>\n",
       "      <td>4.896769e-01</td>\n",
       "      <td>4.907026e-01</td>\n",
       "      <td>5.382418e-01</td>\n",
       "      <td>4.871612e-01</td>\n",
       "      <td>4.882619e-01</td>\n",
       "      <td>4.827387e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>7.450964e-01</td>\n",
       "      <td>7.527783e-01</td>\n",
       "      <td>7.537631e-01</td>\n",
       "      <td>8.264685e-01</td>\n",
       "      <td>8.020884e-01</td>\n",
       "      <td>4.999986e-01</td>\n",
       "      <td>3.356570e-01</td>\n",
       "      <td>3.384592e-01</td>\n",
       "      <td>3.331201e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.573809e-01</td>\n",
       "      <td>3.134715e-01</td>\n",
       "      <td>5.361424e-01</td>\n",
       "      <td>5.317868e-01</td>\n",
       "      <td>5.170093e-01</td>\n",
       "      <td>5.204661e-01</td>\n",
       "      <td>5.651213e-01</td>\n",
       "      <td>5.111268e-01</td>\n",
       "      <td>5.167584e-01</td>\n",
       "      <td>5.127842e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             x             y         theta            dx  \\\n",
       "count  1.110001e+06  1.110001e+06  1.110001e+06  1.110001e+06  1.110001e+06   \n",
       "mean   5.000000e-01  5.025081e-01  5.137311e-01  5.029814e-01  4.994705e-01   \n",
       "std    2.886755e-01  2.726448e-01  2.641271e-01  2.900229e-01  3.232297e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.500000e-01  2.579933e-01  2.790194e-01  2.534673e-01  1.670239e-01   \n",
       "50%    5.000000e-01  5.109220e-01  5.199541e-01  4.987691e-01  5.005303e-01   \n",
       "75%    7.500000e-01  7.450964e-01  7.527783e-01  7.537631e-01  8.264685e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                 dy        dtheta      sensor_1      sensor_2      sensor_3  \\\n",
       "count  1.110001e+06  1.110001e+06  1.110001e+06  1.110001e+06  1.110001e+06   \n",
       "mean   4.991581e-01  4.999980e-01  2.491424e-01  2.369523e-01  2.351461e-01   \n",
       "std    3.089054e-01  2.584209e-02  1.373419e-01  1.473428e-01  1.447032e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.958396e-01  4.999977e-01  1.389283e-01  1.105549e-01  1.135286e-01   \n",
       "50%    5.005646e-01  4.999981e-01  2.249761e-01  2.159326e-01  2.137655e-01   \n",
       "75%    8.020884e-01  4.999986e-01  3.356570e-01  3.384592e-01  3.331201e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           ...           sensor_7      sensor_8     dsensor_1     dsensor_2  \\\n",
       "count      ...       1.110001e+06  1.110001e+06  1.110001e+06  1.110001e+06   \n",
       "mean       ...       2.566096e-01  2.289987e-01  5.045379e-01  5.023748e-01   \n",
       "std        ...       1.474400e-01  1.330272e-01  6.525044e-02  6.475618e-02   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       1.301613e-01  1.216215e-01  4.728892e-01  4.729581e-01   \n",
       "50%        ...       2.295932e-01  2.074250e-01  5.045079e-01  5.023648e-01   \n",
       "75%        ...       3.573809e-01  3.134715e-01  5.361424e-01  5.317868e-01   \n",
       "max        ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          dsensor_3     dsensor_4     dsensor_5     dsensor_6     dsensor_7  \\\n",
       "count  1.110001e+06  1.110001e+06  1.110001e+06  1.110001e+06  1.110001e+06   \n",
       "mean   4.896848e-01  4.906998e-01  5.382509e-01  4.871383e-01  4.883274e-01   \n",
       "std    6.054986e-02  6.117374e-02  5.648393e-02  5.592453e-02  6.472175e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    4.624096e-01  4.609610e-01  5.114513e-01  4.631514e-01  4.599116e-01   \n",
       "50%    4.896769e-01  4.907026e-01  5.382418e-01  4.871612e-01  4.882619e-01   \n",
       "75%    5.170093e-01  5.204661e-01  5.651213e-01  5.111268e-01  5.167584e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          dsensor_8  \n",
       "count  1.110001e+06  \n",
       "mean   4.827896e-01  \n",
       "std    6.201368e-02  \n",
       "min    0.000000e+00  \n",
       "25%    4.527951e-01  \n",
       "50%    4.827387e-01  \n",
       "75%    5.127842e-01  \n",
       "max    1.000000e+00  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_big = 'robot_info_dataset-big.csv'\n",
    "df_big = pd.read_csv(csv_file_big)\n",
    "df_big = df_big.dropna()\n",
    "print(\"Shape: \", df_big.shape)\n",
    "\n",
    "# data normalization\n",
    "normalized_df_big=(df_big-df_big.min())/(df_big.max()-df_big.min())\n",
    "normalized_df_big.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train size\n",
    "ds_size_big = normalized_df_big.shape[0]\n",
    "\n",
    "# take 40% of the data for trainning only cause NN takes too much time with 60%\n",
    "train_size_big = int(0.4 * ds_size_big)\n",
    "test_size_big = int(0.2 * ds_size_big)\n",
    "\n",
    "# shuffle dataset\n",
    "normalized_df_big = normalized_df_big.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs_big = normalized_df_big[['x', 'y', 'theta']]\n",
    "targets_big = normalized_df_big[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs_big = inputs_big[:train_size_big]\n",
    "train_targets_big = targets_big[:train_size_big]\n",
    "\n",
    "# test\n",
    "test_inputs_big = inputs_big[train_size_big:(train_size_big + test_size_big)]\n",
    "test_targets_big = targets_big[train_size_big:(train_size_big + test_size_big)]\n",
    "\n",
    "# validation\n",
    "validation_inputs_big = inputs_big[(train_size_big + test_size_big):]\n",
    "validation_targets_big = targets_big[(train_size_big + test_size_big):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forsest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=5, n_jobs=1, oob_score=False,\n",
       "                      random_state=None, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2 = RandomForestRegressor(n_estimators=5, max_features=max_features, criterion='mse', verbose=False, n_jobs=1)\n",
    "reg2.fit(train_inputs_big, train_targets_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importances x: 0.294433, y: 0.231119, theta: 0.474448\n",
      "\n",
      "R^2 score: 0.795388 \n",
      "\n",
      "Mean Absolute Error:\n",
      "0.04404581\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "sensor_1         -inf\n",
      "sensor_2    78.180000\n",
      "sensor_3    79.400000\n",
      "sensor_4    80.850000\n",
      "sensor_5    79.450000\n",
      "sensor_6    78.710000\n",
      "sensor_7    82.540000\n",
      "sensor_8         -inf\n",
      "dtype: float64 %.\n",
      "\n",
      "NMSE\n",
      "0.20584814916063043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features importances x: %f, y: %f, theta: %f\" %(reg2.feature_importances_[0], reg2.feature_importances_[1], reg2.feature_importances_[2]))\n",
    "print()\n",
    "predictions_targets2 = reg2.predict(test_inputs_big)\n",
    "\n",
    "print(\"R^2 score: %f \\n\" % reg2.score(test_inputs_big, test_targets_big))\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors2 = abs(predictions_targets2 - test_targets_big)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:')\n",
    "print(round(np.mean(np.mean(errors2)), 8))\n",
    "print()\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape2 = 100 * (errors2 / test_targets_big)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy2 = 100 - np.mean(mape2)\n",
    "\n",
    "print()\n",
    "print('Accuracy:')\n",
    "print(round(accuracy2, 2), '%.')\n",
    "print()\n",
    "\n",
    "nmse2 = np.mean((predictions_targets2 - test_targets_big)**2/np.var(test_targets_big))\n",
    "print(\"NMSE\")\n",
    "print(np.mean(nmse2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 355200 samples, validate on 88800 samples\n",
      "Epoch 1/50\n",
      "355200/355200 [==============================] - 367s 1ms/step - loss: 0.0113 - mae: 0.0825 - val_loss: 0.0111 - val_mae: 0.0815\n",
      "Epoch 2/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0114 - mae: 0.0826 - val_loss: 0.0108 - val_mae: 0.0802\n",
      "Epoch 3/50\n",
      "355200/355200 [==============================] - 389s 1ms/step - loss: 0.0114 - mae: 0.0828 - val_loss: 0.0111 - val_mae: 0.0813\n",
      "Epoch 4/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0114 - mae: 0.0829 - val_loss: 0.0114 - val_mae: 0.0835\n",
      "Epoch 5/50\n",
      "355200/355200 [==============================] - 403s 1ms/step - loss: 0.0115 - mae: 0.0831 - val_loss: 0.0111 - val_mae: 0.0815\n",
      "Epoch 6/50\n",
      "355200/355200 [==============================] - 387s 1ms/step - loss: 0.0113 - mae: 0.0824 - val_loss: 0.0106 - val_mae: 0.0797\n",
      "Epoch 7/50\n",
      "355200/355200 [==============================] - 378s 1ms/step - loss: 0.0104 - mae: 0.0789 - val_loss: 0.0097 - val_mae: 0.0761\n",
      "Epoch 8/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0093 - mae: 0.0737 - val_loss: 0.0086 - val_mae: 0.0709\n",
      "Epoch 9/50\n",
      "355200/355200 [==============================] - 385s 1ms/step - loss: 0.0096 - mae: 0.0753 - val_loss: 0.0100 - val_mae: 0.0773\n",
      "Epoch 10/50\n",
      "355200/355200 [==============================] - 353s 995us/step - loss: 0.0107 - mae: 0.0799 - val_loss: 0.0103 - val_mae: 0.0785\n",
      "Epoch 11/50\n",
      "355200/355200 [==============================] - 382s 1ms/step - loss: 0.0109 - mae: 0.0809 - val_loss: 0.0115 - val_mae: 0.0833\n",
      "Epoch 12/50\n",
      "355200/355200 [==============================] - 339s 955us/step - loss: 0.0107 - mae: 0.0801 - val_loss: 0.0095 - val_mae: 0.0743\n",
      "Epoch 13/50\n",
      "355200/355200 [==============================] - 345s 970us/step - loss: 0.0103 - mae: 0.0789 - val_loss: 0.0095 - val_mae: 0.0756\n",
      "Epoch 14/50\n",
      "355200/355200 [==============================] - 347s 977us/step - loss: 0.0109 - mae: 0.0813 - val_loss: 0.0100 - val_mae: 0.0776\n",
      "Epoch 15/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0114 - mae: 0.0832 - val_loss: 0.0109 - val_mae: 0.0805\n",
      "Epoch 16/50\n",
      "355200/355200 [==============================] - 353s 994us/step - loss: 0.0112 - mae: 0.0823 - val_loss: 0.0127 - val_mae: 0.0883\n",
      "Epoch 17/50\n",
      "355200/355200 [==============================] - 345s 972us/step - loss: 0.0108 - mae: 0.0810 - val_loss: 0.0100 - val_mae: 0.0779\n",
      "Epoch 18/50\n",
      "355200/355200 [==============================] - 352s 990us/step - loss: 0.0112 - mae: 0.0827 - val_loss: 0.0108 - val_mae: 0.0811\n",
      "Epoch 19/50\n",
      "355200/355200 [==============================] - 345s 973us/step - loss: 0.0116 - mae: 0.0842 - val_loss: 0.0134 - val_mae: 0.0916\n",
      "Epoch 20/50\n",
      "355200/355200 [==============================] - 359s 1ms/step - loss: 0.0119 - mae: 0.0851 - val_loss: 0.0142 - val_mae: 0.0934\n",
      "Epoch 21/50\n",
      "355200/355200 [==============================] - 349s 981us/step - loss: 0.0122 - mae: 0.0859 - val_loss: 0.0123 - val_mae: 0.0865\n",
      "Epoch 22/50\n",
      "355200/355200 [==============================] - 381s 1ms/step - loss: 0.0121 - mae: 0.0852 - val_loss: 0.0136 - val_mae: 0.0905\n",
      "Epoch 23/50\n",
      "355200/355200 [==============================] - 346s 975us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "Epoch 24/50\n",
      "355200/355200 [==============================] - 349s 982us/step - loss: 0.0116 - mae: 0.0837 - val_loss: 0.0116 - val_mae: 0.0833\n",
      "Epoch 25/50\n",
      "355200/355200 [==============================] - 350s 985us/step - loss: 0.0131 - mae: 0.0886 - val_loss: 0.0137 - val_mae: 0.0918\n",
      "Epoch 26/50\n",
      "355200/355200 [==============================] - 347s 976us/step - loss: 0.0149 - mae: 0.0954 - val_loss: 0.0146 - val_mae: 0.0951\n",
      "Epoch 27/50\n",
      "355200/355200 [==============================] - 345s 972us/step - loss: 0.0150 - mae: 0.0959 - val_loss: 0.0155 - val_mae: 0.0975\n",
      "Epoch 28/50\n",
      "355200/355200 [==============================] - 339s 954us/step - loss: 0.0137 - mae: 0.0910 - val_loss: 0.0119 - val_mae: 0.0837\n",
      "Epoch 29/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0142 - val_mae: 0.0920\n",
      "Epoch 30/50\n",
      "355200/355200 [==============================] - 366s 1ms/step - loss: 0.0148 - mae: 0.0950 - val_loss: 0.0146 - val_mae: 0.0936\n",
      "Epoch 31/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0144 - mae: 0.0938 - val_loss: 0.0135 - val_mae: 0.0914\n",
      "Epoch 32/50\n",
      "355200/355200 [==============================] - 339s 954us/step - loss: 0.0127 - mae: 0.0871 - val_loss: 0.0129 - val_mae: 0.0886\n",
      "Epoch 33/50\n",
      "355200/355200 [==============================] - 343s 964us/step - loss: 0.0134 - mae: 0.0898 - val_loss: 0.0132 - val_mae: 0.0884\n",
      "Epoch 34/50\n",
      "355200/355200 [==============================] - 359s 1ms/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0132 - val_mae: 0.0887\n",
      "Epoch 35/50\n",
      "355200/355200 [==============================] - 350s 985us/step - loss: 0.0134 - mae: 0.0900 - val_loss: 0.0125 - val_mae: 0.0860\n",
      "Epoch 36/50\n",
      "355200/355200 [==============================] - 345s 971us/step - loss: 0.0130 - mae: 0.0886 - val_loss: 0.0130 - val_mae: 0.0877\n",
      "Epoch 37/50\n",
      "355200/355200 [==============================] - 352s 991us/step - loss: 0.0130 - mae: 0.0885 - val_loss: 0.0159 - val_mae: 0.0990\n",
      "Epoch 38/50\n",
      "355200/355200 [==============================] - 349s 983us/step - loss: 0.0131 - mae: 0.0888 - val_loss: 0.0129 - val_mae: 0.0877\n",
      "Epoch 39/50\n",
      "355200/355200 [==============================] - 349s 981us/step - loss: 0.0133 - mae: 0.0890 - val_loss: 0.0136 - val_mae: 0.0896\n",
      "Epoch 40/50\n",
      "355200/355200 [==============================] - 348s 979us/step - loss: 0.0132 - mae: 0.0888 - val_loss: 0.0125 - val_mae: 0.0869\n",
      "Epoch 41/50\n",
      "355200/355200 [==============================] - 339s 953us/step - loss: 0.0132 - mae: 0.0890 - val_loss: 0.0122 - val_mae: 0.0855\n",
      "Epoch 42/50\n",
      "355200/355200 [==============================] - 355s 999us/step - loss: 0.0126 - mae: 0.0871 - val_loss: 0.0138 - val_mae: 0.0919\n",
      "Epoch 43/50\n",
      "355200/355200 [==============================] - 343s 967us/step - loss: 0.0125 - mae: 0.0867 - val_loss: 0.0123 - val_mae: 0.0857\n",
      "Epoch 44/50\n",
      "355200/355200 [==============================] - 352s 991us/step - loss: 0.0130 - mae: 0.0887 - val_loss: 0.0128 - val_mae: 0.0878\n",
      "Epoch 45/50\n",
      "355200/355200 [==============================] - 384s 1ms/step - loss: 0.0131 - mae: 0.0889 - val_loss: 0.0139 - val_mae: 0.0921\n",
      "Epoch 46/50\n",
      "355200/355200 [==============================] - 363s 1ms/step - loss: 0.0134 - mae: 0.0898 - val_loss: 0.0128 - val_mae: 0.0874\n",
      "Epoch 47/50\n",
      "355200/355200 [==============================] - 348s 978us/step - loss: 0.0128 - mae: 0.0876 - val_loss: 0.0117 - val_mae: 0.0835\n",
      "Epoch 48/50\n",
      "355200/355200 [==============================] - 347s 977us/step - loss: 0.0125 - mae: 0.0864 - val_loss: 0.0119 - val_mae: 0.0844\n",
      "Epoch 49/50\n",
      "355200/355200 [==============================] - 367s 1ms/step - loss: 0.0123 - mae: 0.0858 - val_loss: 0.0126 - val_mae: 0.0867\n",
      "Epoch 50/50\n",
      "355200/355200 [==============================] - 350s 986us/step - loss: 0.0122 - mae: 0.0857 - val_loss: 0.0118 - val_mae: 0.0841\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 1\n",
      "Train on 355200 samples, validate on 88800 samples\n",
      "Epoch 1/50\n",
      "355200/355200 [==============================] - 343s 966us/step - loss: 0.0114 - mae: 0.0819 - val_loss: 0.0112 - val_mae: 0.0810\n",
      "Epoch 2/50\n",
      "355200/355200 [==============================] - 344s 968us/step - loss: 0.0114 - mae: 0.0821 - val_loss: 0.0099 - val_mae: 0.0772\n",
      "Epoch 3/50\n",
      "355200/355200 [==============================] - 366s 1ms/step - loss: 0.0104 - mae: 0.0786 - val_loss: 0.0121 - val_mae: 0.0856\n",
      "Epoch 4/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0113 - mae: 0.0821 - val_loss: 0.0113 - val_mae: 0.0821\n",
      "Epoch 5/50\n",
      "355200/355200 [==============================] - 355s 999us/step - loss: 0.0119 - mae: 0.0846 - val_loss: 0.0116 - val_mae: 0.0833\n",
      "Epoch 6/50\n",
      "355200/355200 [==============================] - 343s 965us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355200/355200 [==============================] - 348s 979us/step - loss: 0.0135 - mae: 0.0899 - val_loss: 0.0126 - val_mae: 0.0866\n",
      "Epoch 8/50\n",
      "355200/355200 [==============================] - 343s 966us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0124 - val_mae: 0.0874\n",
      "Epoch 9/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0122 - mae: 0.0858 - val_loss: 0.0118 - val_mae: 0.0845\n",
      "Epoch 10/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0126 - mae: 0.0874 - val_loss: 0.0124 - val_mae: 0.0855\n",
      "Epoch 11/50\n",
      "355200/355200 [==============================] - 351s 988us/step - loss: 0.0129 - mae: 0.0886 - val_loss: 0.0125 - val_mae: 0.0869\n",
      "Epoch 12/50\n",
      "355200/355200 [==============================] - 350s 984us/step - loss: 0.0131 - mae: 0.0889 - val_loss: 0.0126 - val_mae: 0.0868\n",
      "Epoch 13/50\n",
      "355200/355200 [==============================] - 355s 999us/step - loss: 0.0129 - mae: 0.0880 - val_loss: 0.0126 - val_mae: 0.0873\n",
      "Epoch 14/50\n",
      "355200/355200 [==============================] - 372s 1ms/step - loss: 0.0127 - mae: 0.0875 - val_loss: 0.0127 - val_mae: 0.0878\n",
      "Epoch 15/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0126 - val_mae: 0.0878\n",
      "Epoch 16/50\n",
      "355200/355200 [==============================] - 369s 1ms/step - loss: 0.0126 - mae: 0.0870 - val_loss: 0.0123 - val_mae: 0.0859\n",
      "Epoch 17/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0130 - val_mae: 0.0885\n",
      "Epoch 18/50\n",
      "355200/355200 [==============================] - 357s 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0122 - val_mae: 0.0862\n",
      "Epoch 19/50\n",
      "355200/355200 [==============================] - 375s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0122 - val_mae: 0.0853\n",
      "Epoch 20/50\n",
      "355200/355200 [==============================] - 350s 986us/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0125 - val_mae: 0.0861\n",
      "Epoch 21/50\n",
      "355200/355200 [==============================] - 350s 984us/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0121 - val_mae: 0.0860\n",
      "Epoch 22/50\n",
      "355200/355200 [==============================] - 367s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0127 - val_mae: 0.0877\n",
      "Epoch 23/50\n",
      "355200/355200 [==============================] - 366s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0122 - val_mae: 0.0863\n",
      "Epoch 24/50\n",
      "355200/355200 [==============================] - 352s 991us/step - loss: 0.0125 - mae: 0.0868 - val_loss: 0.0120 - val_mae: 0.0843\n",
      "Epoch 25/50\n",
      "355200/355200 [==============================] - 381s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0128 - val_mae: 0.0883\n",
      "Epoch 26/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0137 - val_mae: 0.0912\n",
      "Epoch 27/50\n",
      "355200/355200 [==============================] - 357s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0133 - val_mae: 0.0895\n",
      "Epoch 28/50\n",
      "355200/355200 [==============================] - 357s 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0130 - val_mae: 0.0888\n",
      "Epoch 29/50\n",
      "355200/355200 [==============================] - 363s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0124 - val_mae: 0.0863\n",
      "Epoch 30/50\n",
      "355200/355200 [==============================] - 367s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0120 - val_mae: 0.0851\n",
      "Epoch 31/50\n",
      "355200/355200 [==============================] - 363s 1ms/step - loss: 0.0125 - mae: 0.0869 - val_loss: 0.0123 - val_mae: 0.0858\n",
      "Epoch 32/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0130 - val_mae: 0.0892\n",
      "Epoch 33/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0127 - val_mae: 0.0878\n",
      "Epoch 34/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0120 - val_mae: 0.0853\n",
      "Epoch 35/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 0.0137 - val_mae: 0.0912\n",
      "Epoch 36/50\n",
      "355200/355200 [==============================] - 370s 1ms/step - loss: 0.0126 - mae: 0.0870 - val_loss: 0.0126 - val_mae: 0.0862\n",
      "Epoch 37/50\n",
      "355200/355200 [==============================] - 369s 1ms/step - loss: 0.0126 - mae: 0.0870 - val_loss: 0.0130 - val_mae: 0.0887\n",
      "Epoch 38/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0126 - mae: 0.0870 - val_loss: 0.0122 - val_mae: 0.0860\n",
      "Epoch 39/50\n",
      "355200/355200 [==============================] - 377s 1ms/step - loss: 0.0126 - mae: 0.0871 - val_loss: 0.0125 - val_mae: 0.0867\n",
      "Epoch 40/50\n",
      "355200/355200 [==============================] - 386s 1ms/step - loss: 0.0126 - mae: 0.0872 - val_loss: 0.0136 - val_mae: 0.0915\n",
      "Epoch 41/50\n",
      "355200/355200 [==============================] - 351s 988us/step - loss: 0.0126 - mae: 0.0871 - val_loss: 0.0132 - val_mae: 0.0888\n",
      "Epoch 42/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0126 - mae: 0.0872 - val_loss: 0.0131 - val_mae: 0.0897\n",
      "Epoch 43/50\n",
      "355200/355200 [==============================] - 374s 1ms/step - loss: 0.0126 - mae: 0.0872 - val_loss: 0.0122 - val_mae: 0.0865\n",
      "Epoch 44/50\n",
      "355200/355200 [==============================] - 365s 1ms/step - loss: 0.0126 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0863\n",
      "Epoch 45/50\n",
      "355200/355200 [==============================] - 370s 1ms/step - loss: 0.0126 - mae: 0.0873 - val_loss: 0.0126 - val_mae: 0.0872\n",
      "Epoch 46/50\n",
      "355200/355200 [==============================] - 351s 989us/step - loss: 0.0126 - mae: 0.0873 - val_loss: 0.0124 - val_mae: 0.0867\n",
      "Epoch 47/50\n",
      "355200/355200 [==============================] - 360s 1ms/step - loss: 0.0126 - mae: 0.0873 - val_loss: 0.0127 - val_mae: 0.0886\n",
      "Epoch 48/50\n",
      "355200/355200 [==============================] - 372s 1ms/step - loss: 0.0126 - mae: 0.0873 - val_loss: 0.0125 - val_mae: 0.0867\n",
      "Epoch 49/50\n",
      "355200/355200 [==============================] - 351s 988us/step - loss: 0.0127 - mae: 0.0874 - val_loss: 0.0131 - val_mae: 0.0877\n",
      "Epoch 50/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0127 - mae: 0.0874 - val_loss: 0.0130 - val_mae: 0.0891\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 2\n",
      "Train on 355200 samples, validate on 88800 samples\n",
      "Epoch 1/50\n",
      "355200/355200 [==============================] - 373s 1ms/step - loss: 0.0134 - mae: 0.0902 - val_loss: 0.0144 - val_mae: 0.0929\n",
      "Epoch 2/50\n",
      "355200/355200 [==============================] - 387s 1ms/step - loss: 0.0131 - mae: 0.0891 - val_loss: 0.0120 - val_mae: 0.0835\n",
      "Epoch 3/50\n",
      "355200/355200 [==============================] - 365s 1ms/step - loss: 0.0125 - mae: 0.0867 - val_loss: 0.0107 - val_mae: 0.0804\n",
      "Epoch 4/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0113 - mae: 0.0824 - val_loss: 0.0108 - val_mae: 0.0805\n",
      "Epoch 5/50\n",
      "355200/355200 [==============================] - 380s 1ms/step - loss: 0.0113 - mae: 0.0823 - val_loss: 0.0106 - val_mae: 0.0801\n",
      "Epoch 6/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0112 - mae: 0.0822 - val_loss: 0.0109 - val_mae: 0.0812\n",
      "Epoch 7/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0113 - mae: 0.0823 - val_loss: 0.0106 - val_mae: 0.0796\n",
      "Epoch 8/50\n",
      "355200/355200 [==============================] - 374s 1ms/step - loss: 0.0114 - mae: 0.0830 - val_loss: 0.0110 - val_mae: 0.0812\n",
      "Epoch 9/50\n",
      "355200/355200 [==============================] - 386s 1ms/step - loss: 0.0117 - mae: 0.0842 - val_loss: 0.0117 - val_mae: 0.0838\n",
      "Epoch 10/50\n",
      "355200/355200 [==============================] - 366s 1ms/step - loss: 0.0117 - mae: 0.0842 - val_loss: 0.0117 - val_mae: 0.0843\n",
      "Epoch 11/50\n",
      "355200/355200 [==============================] - 375s 1ms/step - loss: 0.0117 - mae: 0.0841 - val_loss: 0.0118 - val_mae: 0.0839\n",
      "Epoch 12/50\n",
      "355200/355200 [==============================] - 373s 1ms/step - loss: 0.0120 - mae: 0.0850 - val_loss: 0.0127 - val_mae: 0.0878\n",
      "Epoch 13/50\n",
      "355200/355200 [==============================] - 375s 1ms/step - loss: 0.0119 - mae: 0.0847 - val_loss: 0.0110 - val_mae: 0.0814\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355200/355200 [==============================] - 376s 1ms/step - loss: 0.0119 - mae: 0.0850 - val_loss: 0.0111 - val_mae: 0.0825\n",
      "Epoch 15/50\n",
      "355200/355200 [==============================] - 357s 1ms/step - loss: 0.0120 - mae: 0.0852 - val_loss: 0.0122 - val_mae: 0.0865\n",
      "Epoch 16/50\n",
      "355200/355200 [==============================] - 370s 1ms/step - loss: 0.0121 - mae: 0.0856 - val_loss: 0.0109 - val_mae: 0.0811\n",
      "Epoch 17/50\n",
      "355200/355200 [==============================] - 377s 1ms/step - loss: 0.0121 - mae: 0.0856 - val_loss: 0.0115 - val_mae: 0.0837\n",
      "Epoch 18/50\n",
      "355200/355200 [==============================] - 365s 1ms/step - loss: 0.0121 - mae: 0.0857 - val_loss: 0.0109 - val_mae: 0.0808\n",
      "Epoch 19/50\n",
      "355200/355200 [==============================] - 383s 1ms/step - loss: 0.0119 - mae: 0.0849 - val_loss: 0.0123 - val_mae: 0.0868\n",
      "Epoch 20/50\n",
      "355200/355200 [==============================] - 389s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0104 - val_mae: 0.0795\n",
      "Epoch 21/50\n",
      "355200/355200 [==============================] - 370s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0120 - val_mae: 0.0856\n",
      "Epoch 22/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0110 - val_mae: 0.0815\n",
      "Epoch 23/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0132 - val_mae: 0.0902\n",
      "Epoch 24/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0112 - val_mae: 0.0816\n",
      "Epoch 25/50\n",
      "355200/355200 [==============================] - 369s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0103 - val_mae: 0.0787\n",
      "Epoch 26/50\n",
      "355200/355200 [==============================] - 373s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0118 - val_mae: 0.0844\n",
      "Epoch 27/50\n",
      "355200/355200 [==============================] - 389s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0163 - val_mae: 0.1025\n",
      "Epoch 28/50\n",
      "355200/355200 [==============================] - 385s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0110 - val_mae: 0.0811\n",
      "Epoch 29/50\n",
      "355200/355200 [==============================] - 389s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0116 - val_mae: 0.0841\n",
      "Epoch 30/50\n",
      "355200/355200 [==============================] - 366s 1ms/step - loss: 0.0118 - mae: 0.0848 - val_loss: 0.0153 - val_mae: 0.0992\n",
      "Epoch 31/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0172 - val_mae: 0.1054\n",
      "Epoch 32/50\n",
      "355200/355200 [==============================] - 391s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0102 - val_mae: 0.0785\n",
      "Epoch 33/50\n",
      "355200/355200 [==============================] - 366s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0116 - val_mae: 0.0841\n",
      "Epoch 34/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0106 - val_mae: 0.0798\n",
      "Epoch 35/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0145 - val_mae: 0.0945\n",
      "Epoch 36/50\n",
      "355200/355200 [==============================] - 398s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0124 - val_mae: 0.0876\n",
      "Epoch 37/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0137 - val_mae: 0.0915\n",
      "Epoch 38/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0111 - val_mae: 0.0818\n",
      "Epoch 39/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0109 - val_mae: 0.0806\n",
      "Epoch 40/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0105 - val_mae: 0.0793\n",
      "Epoch 41/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0127 - val_mae: 0.0873\n",
      "Epoch 42/50\n",
      "355200/355200 [==============================] - 373s 1ms/step - loss: 0.0119 - mae: 0.0848 - val_loss: 0.0105 - val_mae: 0.0792\n",
      "Epoch 43/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0107 - val_mae: 0.0807\n",
      "Epoch 44/50\n",
      "355200/355200 [==============================] - 381s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0108 - val_mae: 0.0810\n",
      "Epoch 45/50\n",
      "355200/355200 [==============================] - 356s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0165 - val_mae: 0.1028\n",
      "Epoch 46/50\n",
      "355200/355200 [==============================] - 377s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0103 - val_mae: 0.0792\n",
      "Epoch 47/50\n",
      "355200/355200 [==============================] - 366s 1ms/step - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0115 - val_mae: 0.0833\n",
      "Epoch 48/50\n",
      "355200/355200 [==============================] - 360s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0118 - val_mae: 0.0850\n",
      "Epoch 49/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0110 - val_mae: 0.0815\n",
      "Epoch 50/50\n",
      "355200/355200 [==============================] - 389s 1ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0115 - val_mae: 0.0834\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 3\n",
      "Train on 355200 samples, validate on 88800 samples\n",
      "Epoch 1/50\n",
      "355200/355200 [==============================] - 460s 1ms/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0114 - val_mae: 0.0818\n",
      "Epoch 2/50\n",
      "355200/355200 [==============================] - 416s 1ms/step - loss: 0.0097 - mae: 0.0758 - val_loss: 0.0089 - val_mae: 0.0716\n",
      "Epoch 3/50\n",
      "355200/355200 [==============================] - 388s 1ms/step - loss: 0.0096 - mae: 0.0753 - val_loss: 0.0090 - val_mae: 0.0733\n",
      "Epoch 4/50\n",
      "355200/355200 [==============================] - 403s 1ms/step - loss: 0.0093 - mae: 0.0743 - val_loss: 0.0088 - val_mae: 0.0718\n",
      "Epoch 5/50\n",
      "355200/355200 [==============================] - 399s 1ms/step - loss: 0.0090 - mae: 0.0729 - val_loss: 0.0083 - val_mae: 0.0704\n",
      "Epoch 6/50\n",
      "355200/355200 [==============================] - 403s 1ms/step - loss: 0.0088 - mae: 0.0723 - val_loss: 0.0088 - val_mae: 0.0721\n",
      "Epoch 7/50\n",
      "355200/355200 [==============================] - 394s 1ms/step - loss: 0.0091 - mae: 0.0733 - val_loss: 0.0101 - val_mae: 0.0783s\n",
      "Epoch 8/50\n",
      "355200/355200 [==============================] - 359s 1ms/step - loss: 0.0093 - mae: 0.0742 - val_loss: 0.0089 - val_mae: 0.0724\n",
      "Epoch 9/50\n",
      "355200/355200 [==============================] - 348s 981us/step - loss: 0.0094 - mae: 0.0747 - val_loss: 0.0089 - val_mae: 0.0731\n",
      "Epoch 10/50\n",
      "355200/355200 [==============================] - 380s 1ms/step - loss: 0.0095 - mae: 0.0750 - val_loss: 0.0117 - val_mae: 0.0853\n",
      "Epoch 11/50\n",
      "355200/355200 [==============================] - 376s 1ms/step - loss: 0.0095 - mae: 0.0753 - val_loss: 0.0099 - val_mae: 0.0768\n",
      "Epoch 12/50\n",
      "355200/355200 [==============================] - 428s 1ms/step - loss: 0.0096 - mae: 0.0757 - val_loss: 0.0101 - val_mae: 0.0776\n",
      "Epoch 13/50\n",
      "355200/355200 [==============================] - 433s 1ms/step - loss: 0.0096 - mae: 0.0757 - val_loss: 0.0090 - val_mae: 0.0727\n",
      "Epoch 14/50\n",
      "355200/355200 [==============================] - 403s 1ms/step - loss: 0.0096 - mae: 0.0757 - val_loss: 0.0089 - val_mae: 0.0725\n",
      "Epoch 15/50\n",
      "355200/355200 [==============================] - 373s 1ms/step - loss: 0.0096 - mae: 0.0758 - val_loss: 0.0085 - val_mae: 0.0712\n",
      "Epoch 16/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0096 - mae: 0.0758 - val_loss: 0.0090 - val_mae: 0.0731\n",
      "Epoch 17/50\n",
      "355200/355200 [==============================] - 378s 1ms/step - loss: 0.0096 - mae: 0.0759 - val_loss: 0.0096 - val_mae: 0.0764\n",
      "Epoch 18/50\n",
      "355200/355200 [==============================] - 373s 1ms/step - loss: 0.0096 - mae: 0.0759 - val_loss: 0.0100 - val_mae: 0.0783\n",
      "Epoch 19/50\n",
      "355200/355200 [==============================] - 361s 1ms/step - loss: 0.0096 - mae: 0.0759 - val_loss: 0.0088 - val_mae: 0.0731\n",
      "Epoch 20/50\n",
      "355200/355200 [==============================] - 357s 1ms/step - loss: 0.0096 - mae: 0.0759 - val_loss: 0.0097 - val_mae: 0.0755\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355200/355200 [==============================] - 363s 1ms/step - loss: 0.0096 - mae: 0.0760 - val_loss: 0.0096 - val_mae: 0.0761\n",
      "Epoch 22/50\n",
      "355200/355200 [==============================] - 352s 992us/step - loss: 0.0096 - mae: 0.0760 - val_loss: 0.0094 - val_mae: 0.0752\n",
      "Epoch 23/50\n",
      "355200/355200 [==============================] - 383s 1ms/step - loss: 0.0096 - mae: 0.0760 - val_loss: 0.0092 - val_mae: 0.0738\n",
      "Epoch 24/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0096 - mae: 0.0760 - val_loss: 0.0092 - val_mae: 0.0740\n",
      "Epoch 25/50\n",
      "355200/355200 [==============================] - 347s 977us/step - loss: 0.0096 - mae: 0.0760 - val_loss: 0.0102 - val_mae: 0.0794\n",
      "Epoch 26/50\n",
      "355200/355200 [==============================] - 370s 1ms/step - loss: 0.0096 - mae: 0.0760 - val_loss: 0.0096 - val_mae: 0.0751\n",
      "Epoch 27/50\n",
      "355200/355200 [==============================] - 342s 962us/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0089 - val_mae: 0.0721\n",
      "Epoch 28/50\n",
      "355200/355200 [==============================] - 353s 993us/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0091 - val_mae: 0.0745\n",
      "Epoch 29/50\n",
      "355200/355200 [==============================] - 370s 1ms/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0085 - val_mae: 0.0710\n",
      "Epoch 30/50\n",
      "355200/355200 [==============================] - 355s 998us/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0099 - val_mae: 0.0767\n",
      "Epoch 31/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0118 - val_mae: 0.0849\n",
      "Epoch 32/50\n",
      "355200/355200 [==============================] - 364s 1ms/step - loss: 0.0097 - mae: 0.0763 - val_loss: 0.0089 - val_mae: 0.0729\n",
      "Epoch 33/50\n",
      "355200/355200 [==============================] - 353s 995us/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0093 - val_mae: 0.0741\n",
      "Epoch 34/50\n",
      "355200/355200 [==============================] - 356s 1ms/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0096 - val_mae: 0.0756\n",
      "Epoch 35/50\n",
      "355200/355200 [==============================] - 357s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0091 - val_mae: 0.0738\n",
      "Epoch 36/50\n",
      "355200/355200 [==============================] - 357s 1ms/step - loss: 0.0097 - mae: 0.0763 - val_loss: 0.0095 - val_mae: 0.0748\n",
      "Epoch 37/50\n",
      "355200/355200 [==============================] - 372s 1ms/step - loss: 0.0097 - mae: 0.0763 - val_loss: 0.0102 - val_mae: 0.0781\n",
      "Epoch 38/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0088 - val_mae: 0.0722\n",
      "Epoch 39/50\n",
      "355200/355200 [==============================] - 352s 990us/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0094 - val_mae: 0.0749\n",
      "Epoch 40/50\n",
      "355200/355200 [==============================] - 365s 1ms/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0086 - val_mae: 0.0710\n",
      "Epoch 41/50\n",
      "355200/355200 [==============================] - 376s 1ms/step - loss: 0.0097 - mae: 0.0761 - val_loss: 0.0093 - val_mae: 0.0755\n",
      "Epoch 42/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0091 - val_mae: 0.0734\n",
      "Epoch 43/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0102 - val_mae: 0.0786\n",
      "Epoch 44/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0091 - val_mae: 0.0738\n",
      "Epoch 45/50\n",
      "355200/355200 [==============================] - 354s 997us/step - loss: 0.0097 - mae: 0.0763 - val_loss: 0.0091 - val_mae: 0.0744\n",
      "Epoch 46/50\n",
      "355200/355200 [==============================] - 354s 998us/step - loss: 0.0097 - mae: 0.0763 - val_loss: 0.0094 - val_mae: 0.0749\n",
      "Epoch 47/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0097 - mae: 0.0763 - val_loss: 0.0087 - val_mae: 0.0711\n",
      "Epoch 48/50\n",
      "355200/355200 [==============================] - 367s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0096 - val_mae: 0.0758\n",
      "Epoch 49/50\n",
      "355200/355200 [==============================] - 358s 1ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 0.0090 - val_mae: 0.0728\n",
      "Epoch 50/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0097 - mae: 0.0763 - val_loss: 0.0100 - val_mae: 0.0772\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n",
      "processing fold # 4\n",
      "Train on 355200 samples, validate on 88800 samples\n",
      "Epoch 1/50\n",
      "355200/355200 [==============================] - 355s 1000us/step - loss: 0.0094 - mae: 0.0742 - val_loss: 0.0083 - val_mae: 0.0694\n",
      "Epoch 2/50\n",
      "355200/355200 [==============================] - 368s 1ms/step - loss: 0.0084 - mae: 0.0702 - val_loss: 0.0082 - val_mae: 0.0693\n",
      "Epoch 3/50\n",
      "355200/355200 [==============================] - 362s 1ms/step - loss: 0.0084 - mae: 0.0701 - val_loss: 0.0082 - val_mae: 0.0687\n",
      "Epoch 4/50\n",
      "355200/355200 [==============================] - 354s 996us/step - loss: 0.0087 - mae: 0.0713 - val_loss: 0.0087 - val_mae: 0.0713\n",
      "Epoch 5/50\n",
      "355200/355200 [==============================] - 355s 998us/step - loss: 0.0089 - mae: 0.0722 - val_loss: 0.0092 - val_mae: 0.0738\n",
      "Epoch 6/50\n",
      "355200/355200 [==============================] - 392s 1ms/step - loss: 0.0091 - mae: 0.0731 - val_loss: 0.0092 - val_mae: 0.0739\n",
      "Epoch 7/50\n",
      "355200/355200 [==============================] - 478s 1ms/step - loss: 0.0092 - mae: 0.0734 - val_loss: 0.0092 - val_mae: 0.0738\n",
      "Epoch 8/50\n",
      "355200/355200 [==============================] - 458s 1ms/step - loss: 0.0091 - mae: 0.0733 - val_loss: 0.0088 - val_mae: 0.0719\n",
      "Epoch 9/50\n",
      "355200/355200 [==============================] - 458s 1ms/step - loss: 0.0092 - mae: 0.0738 - val_loss: 0.0091 - val_mae: 0.0738\n",
      "Epoch 10/50\n",
      "355200/355200 [==============================] - 454s 1ms/step - loss: 0.0091 - mae: 0.0736 - val_loss: 0.0089 - val_mae: 0.0723\n",
      "Epoch 11/50\n",
      "355200/355200 [==============================] - 463s 1ms/step - loss: 0.0091 - mae: 0.0734 - val_loss: 0.0097 - val_mae: 0.0763\n",
      "Epoch 12/50\n",
      "355200/355200 [==============================] - 449s 1ms/step - loss: 0.0091 - mae: 0.0734 - val_loss: 0.0095 - val_mae: 0.0758\n",
      "Epoch 13/50\n",
      "355200/355200 [==============================] - 446s 1ms/step - loss: 0.0091 - mae: 0.0733 - val_loss: 0.0085 - val_mae: 0.0710\n",
      "Epoch 14/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0091 - mae: 0.0733 - val_loss: 0.0092 - val_mae: 0.0742\n",
      "Epoch 15/50\n",
      "355200/355200 [==============================] - 359s 1ms/step - loss: 0.0090 - mae: 0.0732 - val_loss: 0.0096 - val_mae: 0.0762\n",
      "Epoch 16/50\n",
      "355200/355200 [==============================] - 371s 1ms/step - loss: 0.0090 - mae: 0.0732 - val_loss: 0.0105 - val_mae: 0.0801\n",
      "Epoch 17/50\n",
      "355200/355200 [==============================] - 421s 1ms/step - loss: 0.0090 - mae: 0.0733 - val_loss: 0.0089 - val_mae: 0.0732\n",
      "Epoch 18/50\n",
      "355200/355200 [==============================] - 370s 1ms/step - loss: 0.0090 - mae: 0.0733 - val_loss: 0.0087 - val_mae: 0.0719\n",
      "Epoch 19/50\n",
      "355200/355200 [==============================] - 412s 1ms/step - loss: 0.0091 - mae: 0.0735 - val_loss: 0.0104 - val_mae: 0.0794\n",
      "Epoch 20/50\n",
      "355200/355200 [==============================] - 447s 1ms/step - loss: 0.0091 - mae: 0.0735 - val_loss: 0.0085 - val_mae: 0.0713\n",
      "Epoch 21/50\n",
      "355200/355200 [==============================] - 470s 1ms/step - loss: 0.0091 - mae: 0.0736 - val_loss: 0.0089 - val_mae: 0.0735\n",
      "Epoch 22/50\n",
      "355200/355200 [==============================] - 429s 1ms/step - loss: 0.0091 - mae: 0.0737 - val_loss: 0.0087 - val_mae: 0.0720\n",
      "Epoch 23/50\n",
      "355200/355200 [==============================] - 457s 1ms/step - loss: 0.0091 - mae: 0.0738 - val_loss: 0.0102 - val_mae: 0.0785\n",
      "Epoch 24/50\n",
      "355200/355200 [==============================] - 436s 1ms/step - loss: 0.0092 - mae: 0.0739 - val_loss: 0.0086 - val_mae: 0.0717\n",
      "Epoch 25/50\n",
      "355200/355200 [==============================] - 453s 1ms/step - loss: 0.0092 - mae: 0.0739 - val_loss: 0.0088 - val_mae: 0.0724\n",
      "Epoch 26/50\n",
      "355200/355200 [==============================] - 433s 1ms/step - loss: 0.0092 - mae: 0.0740 - val_loss: 0.0094 - val_mae: 0.0742\n",
      "Epoch 27/50\n",
      "355200/355200 [==============================] - 435s 1ms/step - loss: 0.0092 - mae: 0.0741 - val_loss: 0.0083 - val_mae: 0.0707\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355200/355200 [==============================] - 395s 1ms/step - loss: 0.0092 - mae: 0.0742 - val_loss: 0.0088 - val_mae: 0.0724\n",
      "Epoch 29/50\n",
      "355200/355200 [==============================] - 405s 1ms/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0088 - val_mae: 0.0728\n",
      "Epoch 30/50\n",
      "355200/355200 [==============================] - 419s 1ms/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0092 - val_mae: 0.0738\n",
      "Epoch 31/50\n",
      "355200/355200 [==============================] - 396s 1ms/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0087 - val_mae: 0.0724\n",
      "Epoch 32/50\n",
      "355200/355200 [==============================] - 402s 1ms/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0090 - val_mae: 0.0730\n",
      "Epoch 33/50\n",
      "355200/355200 [==============================] - 445s 1ms/step - loss: 0.0093 - mae: 0.0744 - val_loss: 0.0085 - val_mae: 0.0710\n",
      "Epoch 34/50\n",
      "355200/355200 [==============================] - 473s 1ms/step - loss: 0.0093 - mae: 0.0744 - val_loss: 0.0121 - val_mae: 0.0874\n",
      "Epoch 35/50\n",
      "355200/355200 [==============================] - 438s 1ms/step - loss: 0.0093 - mae: 0.0744 - val_loss: 0.0085 - val_mae: 0.0710\n",
      "Epoch 36/50\n",
      "355200/355200 [==============================] - 436s 1ms/step - loss: 0.0092 - mae: 0.0744 - val_loss: 0.0088 - val_mae: 0.0721\n",
      "Epoch 37/50\n",
      "355200/355200 [==============================] - 433s 1ms/step - loss: 0.0092 - mae: 0.0744 - val_loss: 0.0085 - val_mae: 0.0708\n",
      "Epoch 38/50\n",
      "355200/355200 [==============================] - 416s 1ms/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0088 - val_mae: 0.0725\n",
      "Epoch 39/50\n",
      "355200/355200 [==============================] - 417s 1ms/step - loss: 0.0093 - mae: 0.0744 - val_loss: 0.0091 - val_mae: 0.0739\n",
      "Epoch 40/50\n",
      "355200/355200 [==============================] - 414s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0087 - val_mae: 0.0720\n",
      "Epoch 41/50\n",
      "355200/355200 [==============================] - 410s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0102 - val_mae: 0.0783\n",
      "Epoch 42/50\n",
      "355200/355200 [==============================] - 426s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0086 - val_mae: 0.0720\n",
      "Epoch 43/50\n",
      "355200/355200 [==============================] - 405s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0089 - val_mae: 0.0726\n",
      "Epoch 44/50\n",
      "355200/355200 [==============================] - 400s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0086 - val_mae: 0.0720\n",
      "Epoch 45/50\n",
      "355200/355200 [==============================] - 411s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0085 - val_mae: 0.0711\n",
      "Epoch 46/50\n",
      "355200/355200 [==============================] - 416s 1ms/step - loss: 0.0093 - mae: 0.0744 - val_loss: 0.0102 - val_mae: 0.0785\n",
      "Epoch 47/50\n",
      "355200/355200 [==============================] - 403s 1ms/step - loss: 0.0093 - mae: 0.0744 - val_loss: 0.0092 - val_mae: 0.0737\n",
      "Epoch 48/50\n",
      "355200/355200 [==============================] - 421s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0104 - val_mae: 0.0788\n",
      "Epoch 49/50\n",
      "355200/355200 [==============================] - 406s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0085 - val_mae: 0.0712\n",
      "Epoch 50/50\n",
      "355200/355200 [==============================] - 420s 1ms/step - loss: 0.0093 - mae: 0.0745 - val_loss: 0.0084 - val_mae: 0.0703\n",
      "dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "num_val_samples_2 = len(train_inputs_big) // k\n",
    "validation_scores_2 = []\n",
    "num_epochs = 50\n",
    "all_mae_histories_2 = []\n",
    "all_loss_histories_2 = []\n",
    "nmse_2 = []\n",
    "histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_inputs_big[i * num_val_samples_2: (i + 1) * num_val_samples_2] \n",
    "    val_targets = train_targets_big[i * num_val_samples_2: (i + 1) * num_val_samples_2]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_inputs_big[:i * num_val_samples_2],\n",
    "         train_inputs_big[(i + 1) * num_val_samples_2:]], axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets_big[:i * num_val_samples_2],\n",
    "         train_targets_big[(i + 1) * num_val_samples_2:]], axis=0)\n",
    "    \n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',\n",
    "                           input_shape=(train_inputs_big.shape[1],)))\n",
    "    model.add(layers.Dense(8))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    print(history.history.keys())\n",
    "    histories.append(history.history)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories_2.append(mae_history)\n",
    "    all_loss_histories_2.append(history.history['val_loss'])\n",
    "    \n",
    "    predictions_targets = model.predict(val_data)\n",
    "    nmse_2.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.5661648773330599\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse_2))\n",
    "\n",
    "average_mae_history_2 = [np.mean([x[i] for x in all_mae_histories_2]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(average_mae_history_2) + 1), average_mae_history_2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()\n",
    "\n",
    "average_loss_history_2 = [np.mean([x[i] for x in all_loss_histories_2]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(average_loss_history_2) + 1), average_loss_history_2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation LOSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
