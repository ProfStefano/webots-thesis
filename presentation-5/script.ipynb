{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Data\n",
    "\n",
    "## Environment Settings\n",
    "\n",
    "An statistical Analysis of the data captured will be performed.\n",
    "\n",
    "The environment configuration is the following:\n",
    "\n",
    "- A rectangle area is used whose dimension is 2 x 1.5 meters. \n",
    "- A custom robot similar to an epuck was used.\n",
    "- The robot starts in the middle of the arena.\n",
    "- The robot moves in a random fashion way around the environment avoiding obstacles.\n",
    "- The robot has 8 sensors that measure the distance between the robot and the walls.\n",
    "- Some noise was introduced in the sensors measurements of the robot using the concept of [lookup tables](https://cyberbotics.com/doc/reference/distancesensor) in the Webots simulator which according to Webots documentation \"The first column of the table specifies the input distances, the second column specifies the corresponding desired response values, and the third column indicates the desired standard deviation of the noise. The noise on the return value is computed according to a gaussian random number distribution whose range is calculated as a percent of the response value (two times the standard deviation is often referred to as the signal quality)\". The following values were taken:\n",
    "\n",
    "    -First experiment:\n",
    "        - (0, 0, 0.01)\n",
    "        - (10, 10, 0.01)\n",
    "    -Second experiment:\n",
    "    \n",
    "        - (0, 0, 0.2)\n",
    "        - (10, 10, 0.2)\n",
    "- The simulator runs during 10 minutes in fast mode which is translated into 12 hours of collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install keras\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.920614</td>\n",
       "      <td>0.761198</td>\n",
       "      <td>168.209483</td>\n",
       "      <td>-0.070670</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>-11.790739</td>\n",
       "      <td>1.085179</td>\n",
       "      <td>0.790267</td>\n",
       "      <td>0.893342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139790</td>\n",
       "      <td>1.144901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.850135</td>\n",
       "      <td>0.775909</td>\n",
       "      <td>168.212418</td>\n",
       "      <td>-0.070479</td>\n",
       "      <td>0.014711</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.571635</td>\n",
       "      <td>0.596799</td>\n",
       "      <td>0.883340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830057</td>\n",
       "      <td>1.028332</td>\n",
       "      <td>-0.513544</td>\n",
       "      <td>-0.193468</td>\n",
       "      <td>-0.010002</td>\n",
       "      <td>-0.430864</td>\n",
       "      <td>-0.070277</td>\n",
       "      <td>-0.387726</td>\n",
       "      <td>-0.309733</td>\n",
       "      <td>-0.116568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.779657</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>168.209551</td>\n",
       "      <td>-0.070478</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>-0.002867</td>\n",
       "      <td>0.581452</td>\n",
       "      <td>0.904627</td>\n",
       "      <td>0.689004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491200</td>\n",
       "      <td>0.889130</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.307828</td>\n",
       "      <td>-0.194336</td>\n",
       "      <td>0.239518</td>\n",
       "      <td>0.206480</td>\n",
       "      <td>0.293382</td>\n",
       "      <td>-0.338857</td>\n",
       "      <td>-0.139203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.709174</td>\n",
       "      <td>0.805340</td>\n",
       "      <td>168.212871</td>\n",
       "      <td>-0.070483</td>\n",
       "      <td>0.014715</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.956302</td>\n",
       "      <td>0.842911</td>\n",
       "      <td>0.796714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246415</td>\n",
       "      <td>0.712158</td>\n",
       "      <td>0.374849</td>\n",
       "      <td>-0.061716</td>\n",
       "      <td>0.107710</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>-0.345782</td>\n",
       "      <td>-0.084918</td>\n",
       "      <td>0.755215</td>\n",
       "      <td>-0.176971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.638698</td>\n",
       "      <td>0.820056</td>\n",
       "      <td>168.208857</td>\n",
       "      <td>-0.070477</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>0.671731</td>\n",
       "      <td>0.779896</td>\n",
       "      <td>0.962191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>0.595164</td>\n",
       "      <td>-0.284570</td>\n",
       "      <td>-0.063014</td>\n",
       "      <td>0.165477</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.128150</td>\n",
       "      <td>-0.054777</td>\n",
       "      <td>-0.678608</td>\n",
       "      <td>-0.116994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         x         y       theta        dx        dy     dtheta  \\\n",
       "0           0  0.920614  0.761198  168.209483 -0.070670  0.011198 -11.790739   \n",
       "1           1  0.850135  0.775909  168.212418 -0.070479  0.014711   0.002935   \n",
       "2           2  0.779657  0.790625  168.209551 -0.070478  0.014716  -0.002867   \n",
       "3           3  0.709174  0.805340  168.212871 -0.070483  0.014715   0.003319   \n",
       "4           4  0.638698  0.820056  168.208857 -0.070477  0.014716  -0.004013   \n",
       "\n",
       "   sensor_1  sensor_2  sensor_3    ...      sensor_7  sensor_8  dsensor_1  \\\n",
       "0  1.085179  0.790267  0.893342    ...      1.139790  1.144901        NaN   \n",
       "1  0.571635  0.596799  0.883340    ...      0.830057  1.028332  -0.513544   \n",
       "2  0.581452  0.904627  0.689004    ...      0.491200  0.889130   0.009817   \n",
       "3  0.956302  0.842911  0.796714    ...      1.246415  0.712158   0.374849   \n",
       "4  0.671731  0.779896  0.962191    ...      0.567806  0.595164  -0.284570   \n",
       "\n",
       "   dsensor_2  dsensor_3  dsensor_4  dsensor_5  dsensor_6  dsensor_7  dsensor_8  \n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "1  -0.193468  -0.010002  -0.430864  -0.070277  -0.387726  -0.309733  -0.116568  \n",
       "2   0.307828  -0.194336   0.239518   0.206480   0.293382  -0.338857  -0.139203  \n",
       "3  -0.061716   0.107710   0.075412  -0.345782  -0.084918   0.755215  -0.176971  \n",
       "4  -0.063014   0.165477   0.005216   0.128150  -0.054777  -0.678608  -0.116994  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'robot_info_dataset-jumped.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected 1384848 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65342, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains some null values so they should be deleted from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data will be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>0.504753</td>\n",
       "      <td>0.502063</td>\n",
       "      <td>0.499785</td>\n",
       "      <td>0.500412</td>\n",
       "      <td>0.501624</td>\n",
       "      <td>0.239976</td>\n",
       "      <td>0.236145</td>\n",
       "      <td>0.261438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251293</td>\n",
       "      <td>0.242889</td>\n",
       "      <td>0.449485</td>\n",
       "      <td>0.468761</td>\n",
       "      <td>0.513828</td>\n",
       "      <td>0.507022</td>\n",
       "      <td>0.519272</td>\n",
       "      <td>0.531825</td>\n",
       "      <td>0.446832</td>\n",
       "      <td>0.426383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288682</td>\n",
       "      <td>0.272549</td>\n",
       "      <td>0.264025</td>\n",
       "      <td>0.290735</td>\n",
       "      <td>0.353425</td>\n",
       "      <td>0.335002</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.149030</td>\n",
       "      <td>0.169722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.143636</td>\n",
       "      <td>0.078247</td>\n",
       "      <td>0.073403</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.072415</td>\n",
       "      <td>0.077850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.255777</td>\n",
       "      <td>0.269104</td>\n",
       "      <td>0.251332</td>\n",
       "      <td>0.139102</td>\n",
       "      <td>0.181098</td>\n",
       "      <td>0.496242</td>\n",
       "      <td>0.127116</td>\n",
       "      <td>0.108774</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112714</td>\n",
       "      <td>0.127502</td>\n",
       "      <td>0.412053</td>\n",
       "      <td>0.436092</td>\n",
       "      <td>0.483323</td>\n",
       "      <td>0.477268</td>\n",
       "      <td>0.488782</td>\n",
       "      <td>0.501383</td>\n",
       "      <td>0.415117</td>\n",
       "      <td>0.388997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498537</td>\n",
       "      <td>0.503544</td>\n",
       "      <td>0.498631</td>\n",
       "      <td>0.500020</td>\n",
       "      <td>0.500797</td>\n",
       "      <td>0.501627</td>\n",
       "      <td>0.216759</td>\n",
       "      <td>0.215659</td>\n",
       "      <td>0.237666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224880</td>\n",
       "      <td>0.220298</td>\n",
       "      <td>0.442927</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>0.516314</td>\n",
       "      <td>0.512401</td>\n",
       "      <td>0.524693</td>\n",
       "      <td>0.534465</td>\n",
       "      <td>0.445713</td>\n",
       "      <td>0.419784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.735371</td>\n",
       "      <td>0.740156</td>\n",
       "      <td>0.752400</td>\n",
       "      <td>0.860369</td>\n",
       "      <td>0.821281</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>0.328127</td>\n",
       "      <td>0.337889</td>\n",
       "      <td>0.375692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360337</td>\n",
       "      <td>0.333973</td>\n",
       "      <td>0.479438</td>\n",
       "      <td>0.498031</td>\n",
       "      <td>0.547039</td>\n",
       "      <td>0.544322</td>\n",
       "      <td>0.557577</td>\n",
       "      <td>0.565527</td>\n",
       "      <td>0.475271</td>\n",
       "      <td>0.456114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             x             y         theta            dx  \\\n",
       "count  65341.000000  65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       0.500000      0.498321      0.504753      0.502063      0.499785   \n",
       "std        0.288682      0.272549      0.264025      0.290735      0.353425   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.250000      0.255777      0.269104      0.251332      0.139102   \n",
       "50%        0.500000      0.498537      0.503544      0.498631      0.500020   \n",
       "75%        0.750000      0.735371      0.740156      0.752400      0.860369   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 dy        dtheta      sensor_1      sensor_2      sensor_3  \\\n",
       "count  65341.000000  65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       0.500412      0.501624      0.239976      0.236145      0.261438   \n",
       "std        0.335002      0.114192      0.140647      0.149030      0.169722   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.181098      0.496242      0.127116      0.108774      0.119219   \n",
       "50%        0.500797      0.501627      0.216759      0.215659      0.237666   \n",
       "75%        0.821281      0.506991      0.328127      0.337889      0.375692   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...           sensor_7      sensor_8     dsensor_1     dsensor_2  \\\n",
       "count      ...       65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       ...           0.251293      0.242889      0.449485      0.468761   \n",
       "std        ...           0.160999      0.143636      0.078247      0.073403   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.112714      0.127502      0.412053      0.436092   \n",
       "50%        ...           0.224880      0.220298      0.442927      0.467409   \n",
       "75%        ...           0.360337      0.333973      0.479438      0.498031   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          dsensor_3     dsensor_4     dsensor_5     dsensor_6     dsensor_7  \\\n",
       "count  65341.000000  65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       0.513828      0.507022      0.519272      0.531825      0.446832   \n",
       "std        0.077416      0.078125      0.081846      0.080184      0.072415   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.483323      0.477268      0.488782      0.501383      0.415117   \n",
       "50%        0.516314      0.512401      0.524693      0.534465      0.445713   \n",
       "75%        0.547039      0.544322      0.557577      0.565527      0.475271   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          dsensor_8  \n",
       "count  65341.000000  \n",
       "mean       0.426383  \n",
       "std        0.077850  \n",
       "min        0.000000  \n",
       "25%        0.388997  \n",
       "50%        0.419784  \n",
       "75%        0.456114  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "normalized_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into training, testing and validation sets. 60% of the data will be used for training, 20% for training and 20% of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train size\n",
    "test_size_percentage = .2\n",
    "train_size_percentage = .6\n",
    "ds_size = normalized_df.shape[0]\n",
    "train_size = int(train_size_percentage * ds_size)\n",
    "test_size = int(test_size_percentage * ds_size)\n",
    "\n",
    "# shuffle dataset\n",
    "normalized_df = normalized_df.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs = normalized_df[['x', 'y', 'theta']]\n",
    "targets = normalized_df[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "# test\n",
    "test_inputs = inputs[train_size:(train_size + test_size)]\n",
    "test_targets = targets[train_size:(train_size + test_size)]\n",
    "\n",
    "# validation\n",
    "validation_inputs = inputs[(train_size + test_size):]\n",
    "validation_targets = targets[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input the neural network receives the x, y coordinates and rotation angle $\\theta$. The output are the sensor measurements. One model per sensor will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu', input_shape=(3,)))\n",
    "#     model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(6, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "#     rmsprop = optimizers.RMSprop(learning_rate=0.01)\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets[['sensor_1']][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(sensor_number, num_epochs=10, k=5):\n",
    "    num_val_samples = len(train_inputs) // k\n",
    "    validation_scores = []\n",
    "    histories = []\n",
    "    nmse = []\n",
    "\n",
    "    for i in range(k):\n",
    "        print('processing fold #', i)\n",
    "        val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = train_targets[[sensor_number]][i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [train_inputs[:i * num_val_samples],\n",
    "             train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [train_targets[[sensor_number]][:i * num_val_samples],\n",
    "             train_targets[[sensor_number]][(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "\n",
    "        model = get_model()\n",
    "\n",
    "        history = model.fit(partial_train_data, partial_train_targets,\n",
    "                            validation_data=(val_data, val_targets),\n",
    "                            epochs=num_epochs, batch_size=1, verbose=1)\n",
    "        histories.append(history.history)\n",
    "\n",
    "        predictions_targets = model.predict(val_data)\n",
    "        nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "        \n",
    "    return histories, nmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0116 - mae: 0.0814 - val_loss: 0.0067 - val_mae: 0.0624\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0069 - mae: 0.0615 - val_loss: 0.0058 - val_mae: 0.0576\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0065 - mae: 0.0602 - val_loss: 0.0058 - val_mae: 0.0556\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0064 - mae: 0.0598 - val_loss: 0.0076 - val_mae: 0.0702\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0064 - mae: 0.0594 - val_loss: 0.0059 - val_mae: 0.0583\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0064 - mae: 0.0593 - val_loss: 0.0068 - val_mae: 0.0641\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0060 - mae: 0.0578 - val_loss: 0.0054 - val_mae: 0.0524\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0059 - mae: 0.0571 - val_loss: 0.0050 - val_mae: 0.0516\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0057 - mae: 0.0561 - val_loss: 0.0057 - val_mae: 0.0560\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0056 - mae: 0.0555 - val_loss: 0.0053 - val_mae: 0.0538\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0056 - mae: 0.0554 - val_loss: 0.0053 - val_mae: 0.0526\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.0051 - val_mae: 0.0512\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 41s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0048 - val_mae: 0.0503\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0048 - val_mae: 0.0512\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 39s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0052 - val_mae: 0.0515\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0046 - val_mae: 0.0504\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 39s 1ms/step - loss: 0.0052 - mae: 0.0534 - val_loss: 0.0048 - val_mae: 0.0501\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 40s 1ms/step - loss: 0.0051 - mae: 0.0532 - val_loss: 0.0052 - val_mae: 0.0527\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 40s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0048 - val_mae: 0.0528\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 40s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0059 - val_mae: 0.0561\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 42s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0045 - val_mae: 0.0491\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0052 - mae: 0.0533 - val_loss: 0.0046 - val_mae: 0.0508\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0049 - val_mae: 0.0536\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0052 - mae: 0.0533 - val_loss: 0.0047 - val_mae: 0.0522\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0051 - mae: 0.0532 - val_loss: 0.0045 - val_mae: 0.0491\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0045 - val_mae: 0.0504\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0045 - val_mae: 0.0496\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0082 - val_mae: 0.0729\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0047 - val_mae: 0.0508\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0070 - val_mae: 0.0644\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0044 - val_mae: 0.0497\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0054 - val_mae: 0.0566\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 38s 1ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0050 - val_mae: 0.0526\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0042 - val_mae: 0.0478\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0072 - val_mae: 0.0679\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0042 - val_mae: 0.0481\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0042 - val_mae: 0.0478\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0052 - val_mae: 0.0566\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0045 - val_mae: 0.0506\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0050 - val_mae: 0.0530\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0043 - val_mae: 0.0495\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0519 - val_loss: 0.0043 - val_mae: 0.0481\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0056 - val_mae: 0.0587\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0045 - val_mae: 0.0499\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0041 - val_mae: 0.0461\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0065 - val_mae: 0.0616\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0048 - val_mae: 0.0515\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0043 - val_mae: 0.0494\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0048 - val_mae: 0.0517\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0047 - val_mae: 0.0508\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0514 - val_loss: 0.0044 - val_mae: 0.0486\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0056 - val_mae: 0.0583\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0047 - val_mae: 0.0514\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0041 - val_mae: 0.0466\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0510 - val_loss: 0.0049 - val_mae: 0.0531\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0510 - val_loss: 0.0045 - val_mae: 0.0509\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0043 - val_mae: 0.0488\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0047 - mae: 0.0510 - val_loss: 0.0058 - val_mae: 0.0607\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0042 - val_mae: 0.0480\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0048 - val_mae: 0.0527\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0042 - val_mae: 0.0473\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0040 - val_mae: 0.0462\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0054 - val_mae: 0.0556\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0056 - val_mae: 0.0567\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0044 - val_mae: 0.0493\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0045 - val_mae: 0.0491\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0045 - val_mae: 0.0497\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0042 - val_mae: 0.0474\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0045 - val_mae: 0.0491\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0043 - val_mae: 0.0483\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0065 - val_mae: 0.0639\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0042 - val_mae: 0.0477\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0050 - val_mae: 0.0544\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0506 - val_loss: 0.0047 - val_mae: 0.0500\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0044 - val_mae: 0.0485\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0503 - val_loss: 0.0044 - val_mae: 0.0500\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0046 - mae: 0.0502 - val_loss: 0.0053 - val_mae: 0.0568\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0046 - mae: 0.0502 - val_loss: 0.0046 - val_mae: 0.0506\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0046 - mae: 0.0501 - val_loss: 0.0046 - val_mae: 0.0493\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0046 - mae: 0.0502 - val_loss: 0.0043 - val_mae: 0.0472\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0046 - mae: 0.0501 - val_loss: 0.0044 - val_mae: 0.0490\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0046 - mae: 0.0503 - val_loss: 0.0054 - val_mae: 0.0554\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0504 - val_loss: 0.0046 - val_mae: 0.0504\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0504 - val_loss: 0.0041 - val_mae: 0.0468\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0506 - val_loss: 0.0043 - val_mae: 0.0479\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0053 - val_mae: 0.0541\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0506 - val_loss: 0.0067 - val_mae: 0.0661\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0044 - val_mae: 0.0497\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0053 - val_mae: 0.0561\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0488\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0061 - val_mae: 0.0595\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0472\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0045 - val_mae: 0.0490\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0064 - val_mae: 0.0629\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0045 - val_mae: 0.0503\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0051 - val_mae: 0.0546\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0041 - val_mae: 0.0463\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0056 - val_mae: 0.0575\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0485\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0510 - val_loss: 0.0043 - val_mae: 0.0484\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0056 - val_mae: 0.0590\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0044 - val_mae: 0.0486\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0057 - val_mae: 0.0587\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0512 - val_loss: 0.0044 - val_mae: 0.0500\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0050 - val_mae: 0.0537\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0047 - mae: 0.0512 - val_loss: 0.0040 - val_mae: 0.0458\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0046 - val_mae: 0.0506\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0512 - val_loss: 0.0045 - val_mae: 0.0492\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0511 - val_loss: 0.0046 - val_mae: 0.0507\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0511 - val_loss: 0.0064 - val_mae: 0.0624\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0064 - val_mae: 0.0640\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0512 - val_loss: 0.0046 - val_mae: 0.0510\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0042 - val_mae: 0.0476\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0041 - val_mae: 0.0464\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0043 - val_mae: 0.0489\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0043 - val_mae: 0.0475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0062 - val_mae: 0.0606\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0043 - val_mae: 0.0479\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0061 - val_mae: 0.0599\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0059 - val_mae: 0.0591\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0052 - val_mae: 0.0557\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0048 - mae: 0.0515 - val_loss: 0.0044 - val_mae: 0.0490\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0054 - val_mae: 0.0548\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0060 - val_mae: 0.0582\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0047 - val_mae: 0.0508\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0048 - val_mae: 0.0520\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0044 - val_mae: 0.0491\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0045 - val_mae: 0.0498\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0046 - val_mae: 0.0494\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0052 - val_mae: 0.0547\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0045 - val_mae: 0.0500\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0058 - val_mae: 0.0569\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0042 - val_mae: 0.0472\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0051 - val_mae: 0.0543\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0056 - val_mae: 0.0576\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0042 - val_mae: 0.0471\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0058 - val_mae: 0.0579\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0058 - val_mae: 0.0604\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0048 - val_mae: 0.0539\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0054 - val_mae: 0.0560\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0059 - val_mae: 0.0620\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0052 - val_mae: 0.0556\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0049 - val_mae: 0.0530\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0054 - val_mae: 0.0577\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0050 - mae: 0.0524 - val_loss: 0.0063 - val_mae: 0.0611\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0046 - val_mae: 0.0515\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0053 - val_mae: 0.0556\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0049 - mae: 0.0528 - val_loss: 0.0047 - val_mae: 0.0527\n",
      "processing fold # 1\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0125 - mae: 0.0845 - val_loss: 0.0097 - val_mae: 0.0732\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0090 - mae: 0.0712 - val_loss: 0.0079 - val_mae: 0.0680\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0079 - mae: 0.0666 - val_loss: 0.0069 - val_mae: 0.0609\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0072 - mae: 0.0635 - val_loss: 0.0066 - val_mae: 0.0617\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0065 - mae: 0.0607 - val_loss: 0.0058 - val_mae: 0.0582\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0584 - val_loss: 0.0069 - val_mae: 0.0651\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0577 - val_loss: 0.0057 - val_mae: 0.0552\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0573 - val_loss: 0.0050 - val_mae: 0.0524\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0568 - val_loss: 0.0059 - val_mae: 0.0563\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0067 - val_mae: 0.0631\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0554 - val_loss: 0.0056 - val_mae: 0.0549\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0047 - val_mae: 0.0499\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0053 - val_mae: 0.0520\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0541 - val_loss: 0.0054 - val_mae: 0.0549\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0051 - val_mae: 0.0518\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0051 - val_mae: 0.0525\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0052 - val_mae: 0.0540\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0051 - val_mae: 0.0518\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0053 - val_mae: 0.0537\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0052 - val_mae: 0.0538\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0049 - val_mae: 0.0523\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0048 - val_mae: 0.0523\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0059 - val_mae: 0.0573\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0047 - val_mae: 0.0512\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0049 - val_mae: 0.0519\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0054 - val_mae: 0.0562\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0055 - val_mae: 0.0534\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0049 - val_mae: 0.0506\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0048 - val_mae: 0.0522\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0057 - val_mae: 0.0555\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0070 - val_mae: 0.0595\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0052 - val_mae: 0.0525\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0046 - val_mae: 0.0503\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0074 - val_mae: 0.0677\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0061 - val_mae: 0.0581\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0046 - val_mae: 0.0499\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0538 - val_loss: 0.0053 - val_mae: 0.0537\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0047 - val_mae: 0.0496\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0049 - val_mae: 0.0529\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0051 - mae: 0.0532 - val_loss: 0.0055 - val_mae: 0.0542\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0538 - val_loss: 0.0058 - val_mae: 0.0566\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0048 - val_mae: 0.0515\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0538 - val_loss: 0.0057 - val_mae: 0.0572\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0059 - val_mae: 0.0568\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0055 - val_mae: 0.0568\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0053 - val_mae: 0.0551\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0050 - val_mae: 0.0512\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0066 - val_mae: 0.0610\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0057 - val_mae: 0.0581\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0050 - val_mae: 0.0504\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0046 - val_mae: 0.0502\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0080 - val_mae: 0.0724\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0540 - val_loss: 0.0048 - val_mae: 0.0510\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0077 - val_mae: 0.0662\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0048 - val_mae: 0.0523\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0046 - val_mae: 0.0498\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0059 - val_mae: 0.0570\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0055 - val_mae: 0.0563\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0045 - val_mae: 0.0494\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0048 - val_mae: 0.0515\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0049 - val_mae: 0.0522\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0540 - val_loss: 0.0061 - val_mae: 0.0607\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0057 - val_mae: 0.0552\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0061 - val_mae: 0.0608\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0055 - val_mae: 0.0543\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0061 - val_mae: 0.0580\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0055 - val_mae: 0.0549\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0045 - val_mae: 0.0496\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0059 - val_mae: 0.0583\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0063 - val_mae: 0.0613\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0061 - val_mae: 0.0572\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0546 - val_loss: 0.0071 - val_mae: 0.0625\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0049 - val_mae: 0.0517\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0057 - val_mae: 0.0578\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0051 - val_mae: 0.0528\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0047 - val_mae: 0.0507\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0045 - val_mae: 0.0495\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0538 - val_loss: 0.0045 - val_mae: 0.0498\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0054 - val_mae: 0.0555\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0049 - val_mae: 0.0510\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0051 - val_mae: 0.0523\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0057 - val_mae: 0.0576\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0048 - val_mae: 0.0503\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0071 - val_mae: 0.0618\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0059 - val_mae: 0.0593\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0052 - val_mae: 0.0517\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0069 - val_mae: 0.0649\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0050 - val_mae: 0.0533\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0048 - val_mae: 0.0511\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0047 - val_mae: 0.0496\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0048 - val_mae: 0.0508\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0094 - val_mae: 0.0787\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0061 - val_mae: 0.0600\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0081 - val_mae: 0.0660\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0053 - val_mae: 0.0553\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0053 - val_mae: 0.0539\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0049 - val_mae: 0.0517\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0051 - val_mae: 0.0532\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0056 - val_mae: 0.0576\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0060 - val_mae: 0.0581\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0071 - val_mae: 0.0620\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0057 - val_mae: 0.0577\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0546 - val_loss: 0.0050 - val_mae: 0.0525\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0067 - val_mae: 0.0640\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0056 - val_mae: 0.0559\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0045 - val_mae: 0.0497\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0556 - val_loss: 0.0052 - val_mae: 0.0552\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0562 - val_loss: 0.0052 - val_mae: 0.0533\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0055 - val_mae: 0.0555\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0566 - val_loss: 0.0057 - val_mae: 0.0565\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0570 - val_loss: 0.0051 - val_mae: 0.0536\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0572 - val_loss: 0.0053 - val_mae: 0.0554\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0571 - val_loss: 0.0056 - val_mae: 0.0565\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0570 - val_loss: 0.0048 - val_mae: 0.0519\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0568 - val_loss: 0.0047 - val_mae: 0.0510\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0570 - val_loss: 0.0051 - val_mae: 0.0527\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0567 - val_loss: 0.0063 - val_mae: 0.0610\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0570 - val_loss: 0.0054 - val_mae: 0.0545\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0567 - val_loss: 0.0064 - val_mae: 0.0593\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0051 - val_mae: 0.0532\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0568 - val_loss: 0.0047 - val_mae: 0.0511\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0568 - val_loss: 0.0047 - val_mae: 0.0506\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0567 - val_loss: 0.0049 - val_mae: 0.0518\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0570 - val_loss: 0.0055 - val_mae: 0.0550\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0572 - val_loss: 0.0078 - val_mae: 0.0718\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0574 - val_loss: 0.0072 - val_mae: 0.0651\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0572 - val_loss: 0.0053 - val_mae: 0.0540\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0571 - val_loss: 0.0049 - val_mae: 0.0523\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0055 - val_mae: 0.0538\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0052 - val_mae: 0.0522\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0048 - val_mae: 0.0520\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0565 - val_loss: 0.0050 - val_mae: 0.0529\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0068 - val_mae: 0.0587\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0567 - val_loss: 0.0050 - val_mae: 0.0513\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0071 - val_mae: 0.0645\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0048 - val_mae: 0.0502\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0563 - val_loss: 0.0047 - val_mae: 0.0507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0563 - val_loss: 0.0075 - val_mae: 0.0636\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0563 - val_loss: 0.0046 - val_mae: 0.0500\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0566 - val_loss: 0.0052 - val_mae: 0.0538\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0568 - val_loss: 0.0049 - val_mae: 0.0519\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0046 - val_mae: 0.0496\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0071 - val_mae: 0.0656\n",
      "processing fold # 2\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0826 - val_loss: 0.0081 - val_mae: 0.0709\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0073 - mae: 0.0645 - val_loss: 0.0067 - val_mae: 0.0623\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0069 - mae: 0.0623 - val_loss: 0.0066 - val_mae: 0.0616\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0066 - mae: 0.0607 - val_loss: 0.0061 - val_mae: 0.0597\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0063 - mae: 0.0596 - val_loss: 0.0059 - val_mae: 0.0592\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0062 - mae: 0.0594 - val_loss: 0.0083 - val_mae: 0.0654\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0589 - val_loss: 0.0056 - val_mae: 0.0553\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0061 - mae: 0.0584 - val_loss: 0.0056 - val_mae: 0.0545\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0579 - val_loss: 0.0066 - val_mae: 0.0625\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0580 - val_loss: 0.0051 - val_mae: 0.0533\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0052 - val_mae: 0.0534\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0577 - val_loss: 0.0068 - val_mae: 0.0618\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0059 - mae: 0.0578 - val_loss: 0.0055 - val_mae: 0.0554\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0575 - val_loss: 0.0066 - val_mae: 0.0592\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0579 - val_loss: 0.0063 - val_mae: 0.0613\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0580 - val_loss: 0.0054 - val_mae: 0.0552\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0582 - val_loss: 0.0053 - val_mae: 0.0538\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0060 - mae: 0.0585 - val_loss: 0.0060 - val_mae: 0.0568\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0584 - val_loss: 0.0057 - val_mae: 0.0548\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0585 - val_loss: 0.0055 - val_mae: 0.0565\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0585 - val_loss: 0.0060 - val_mae: 0.0607\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0585 - val_loss: 0.0078 - val_mae: 0.0701\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0061 - mae: 0.0588 - val_loss: 0.0059 - val_mae: 0.0570\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0060 - mae: 0.0584 - val_loss: 0.0053 - val_mae: 0.0551\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0582 - val_loss: 0.0056 - val_mae: 0.0552\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0581 - val_loss: 0.0052 - val_mae: 0.0545\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0060 - mae: 0.0578 - val_loss: 0.0053 - val_mae: 0.0537\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0061 - val_mae: 0.0607\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0058 - mae: 0.0572 - val_loss: 0.0053 - val_mae: 0.0545\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0573 - val_loss: 0.0056 - val_mae: 0.0556\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0058 - mae: 0.0569 - val_loss: 0.0052 - val_mae: 0.0541\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0058 - mae: 0.0570 - val_loss: 0.0053 - val_mae: 0.0545\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0052 - val_mae: 0.0532\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0566 - val_loss: 0.0051 - val_mae: 0.0530\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0568 - val_loss: 0.0051 - val_mae: 0.0527\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0564 - val_loss: 0.0055 - val_mae: 0.0561\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0563 - val_loss: 0.0051 - val_mae: 0.0536\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0077 - val_mae: 0.0657\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0055 - val_mae: 0.0558\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0563 - val_loss: 0.0054 - val_mae: 0.0546\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0560 - val_loss: 0.0052 - val_mae: 0.0531\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0559 - val_loss: 0.0054 - val_mae: 0.0560\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0054 - val_mae: 0.0551\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0556 - val_loss: 0.0062 - val_mae: 0.0581\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0051 - val_mae: 0.0535\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0054 - val_mae: 0.0556\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0050 - val_mae: 0.0518\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0054 - val_mae: 0.0546\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0052 - val_mae: 0.0531\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0071 - val_mae: 0.0645\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0055 - val_mae: 0.0573\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0555 - val_loss: 0.0065 - val_mae: 0.0590\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0553 - val_loss: 0.0052 - val_mae: 0.0545\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0553 - val_loss: 0.0053 - val_mae: 0.0546\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0555 - val_loss: 0.0063 - val_mae: 0.0588\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0058 - val_mae: 0.0575\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0051 - val_mae: 0.0530\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0049 - val_mae: 0.0520\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0062 - val_mae: 0.0625\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0050 - val_mae: 0.0516\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0053 - val_mae: 0.0558\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0057 - val_mae: 0.0558\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0049 - val_mae: 0.0514\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0051 - val_mae: 0.0527\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0049 - val_mae: 0.0520\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0053 - val_mae: 0.0565\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0052 - val_mae: 0.0531\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0060 - val_mae: 0.0605\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0063 - val_mae: 0.0603\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0054 - val_mae: 0.0549\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0052 - val_mae: 0.0534\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0063 - val_mae: 0.0631\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0054 - val_mae: 0.0571\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0532\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0524\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0550\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0050 - val_mae: 0.0528\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0050 - val_mae: 0.0525\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0060 - val_mae: 0.0625\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0546 - val_loss: 0.0051 - val_mae: 0.0525\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0069 - val_mae: 0.0608\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0049 - val_mae: 0.0512\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0052 - val_mae: 0.0526\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0086 - val_mae: 0.0760\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0047 - val_mae: 0.0509\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0048 - val_mae: 0.0517\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0545 - val_loss: 0.0048 - val_mae: 0.0512\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0055 - val_mae: 0.0566\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0055 - val_mae: 0.0570\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0056 - val_mae: 0.0572\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0049 - val_mae: 0.0527\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0049 - val_mae: 0.0522\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0058 - val_mae: 0.0557\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0047 - val_mae: 0.0499\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0055 - val_mae: 0.0538\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0052 - val_mae: 0.0526\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0536 - val_loss: 0.0051 - val_mae: 0.0538\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0067 - val_mae: 0.0664\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0051 - val_mae: 0.0537\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0051 - val_mae: 0.0528\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0062 - val_mae: 0.0618\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0050 - val_mae: 0.0530\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0058 - val_mae: 0.0567\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0047 - val_mae: 0.0494\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0049 - val_mae: 0.0500\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0048 - val_mae: 0.0504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0047 - val_mae: 0.0505\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0053 - val_mae: 0.0546\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0534 - val_loss: 0.0054 - val_mae: 0.0524\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0532 - val_loss: 0.0050 - val_mae: 0.0523\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0532 - val_loss: 0.0072 - val_mae: 0.0630\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0534 - val_loss: 0.0049 - val_mae: 0.0530\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0060 - val_mae: 0.0576\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0064 - val_mae: 0.0591\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0051 - val_mae: 0.0542\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0049 - val_mae: 0.0505\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0045 - val_mae: 0.0500\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0048 - val_mae: 0.0529\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0051 - val_mae: 0.0523\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0045 - val_mae: 0.0486\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0080 - val_mae: 0.0685\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0049 - val_mae: 0.0508\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 39s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0050 - val_mae: 0.0506\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 45s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0055 - val_mae: 0.0572\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 41s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0063 - val_mae: 0.0599\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0050 - val_mae: 0.0502\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0053 - val_mae: 0.0543\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0053 - val_mae: 0.0574\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0067 - val_mae: 0.0630\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0058 - val_mae: 0.0542\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0058 - val_mae: 0.0564\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0045 - val_mae: 0.0499\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0049 - val_mae: 0.0522\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0054 - val_mae: 0.0558\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0060 - val_mae: 0.0587\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0550 - val_loss: 0.0059 - val_mae: 0.0546\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0054 - val_mae: 0.0549\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0049 - val_mae: 0.0528\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0055 - val_mae: 0.0552\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0555 - val_loss: 0.0050 - val_mae: 0.0528\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0051 - val_mae: 0.0534\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0057 - val_mae: 0.0544\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0558 - val_loss: 0.0047 - val_mae: 0.0489\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0559 - val_loss: 0.0048 - val_mae: 0.0517\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0560 - val_loss: 0.0052 - val_mae: 0.0541\n",
      "processing fold # 3\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0129 - mae: 0.0868 - val_loss: 0.0113 - val_mae: 0.0824\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0799 - val_loss: 0.0095 - val_mae: 0.0735\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0091 - mae: 0.0726 - val_loss: 0.0085 - val_mae: 0.0658\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0081 - mae: 0.0689 - val_loss: 0.0073 - val_mae: 0.0645\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0078 - mae: 0.0673 - val_loss: 0.0070 - val_mae: 0.0626\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0076 - mae: 0.0666 - val_loss: 0.0066 - val_mae: 0.0602\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0070 - mae: 0.0636 - val_loss: 0.0069 - val_mae: 0.0648\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0067 - mae: 0.0617 - val_loss: 0.0064 - val_mae: 0.0603\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0065 - mae: 0.0608 - val_loss: 0.0065 - val_mae: 0.0576\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0064 - mae: 0.0604 - val_loss: 0.0063 - val_mae: 0.0578\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0063 - mae: 0.0596 - val_loss: 0.0056 - val_mae: 0.0562\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0108 - val_mae: 0.0805\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0061 - mae: 0.0588 - val_loss: 0.0056 - val_mae: 0.0542\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0061 - mae: 0.0588 - val_loss: 0.0059 - val_mae: 0.0579\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0061 - mae: 0.0588 - val_loss: 0.0080 - val_mae: 0.0668\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0062 - mae: 0.0592 - val_loss: 0.0062 - val_mae: 0.0573\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0063 - mae: 0.0595 - val_loss: 0.0062 - val_mae: 0.0605\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0061 - mae: 0.0590 - val_loss: 0.0079 - val_mae: 0.0673\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0058 - mae: 0.0577 - val_loss: 0.0053 - val_mae: 0.0548\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0562 - val_loss: 0.0048 - val_mae: 0.0513\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0554 - val_loss: 0.0050 - val_mae: 0.0515\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0551 - val_loss: 0.0048 - val_mae: 0.0517\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0549 - val_loss: 0.0057 - val_mae: 0.0587\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0053 - val_mae: 0.0559\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0552 - val_loss: 0.0051 - val_mae: 0.0531\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0559 - val_loss: 0.0058 - val_mae: 0.0591\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0564 - val_loss: 0.0053 - val_mae: 0.0545\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0055 - val_mae: 0.0553\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0568 - val_loss: 0.0056 - val_mae: 0.0570\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0058 - mae: 0.0571 - val_loss: 0.0050 - val_mae: 0.0520\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0564 - val_loss: 0.0052 - val_mae: 0.0535\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0560 - val_loss: 0.0049 - val_mae: 0.0518\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0556 - val_loss: 0.0054 - val_mae: 0.0549\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0557 - val_loss: 0.0056 - val_mae: 0.0558\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0557 - val_loss: 0.0049 - val_mae: 0.0512\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0066 - val_mae: 0.0591\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0547 - val_loss: 0.0054 - val_mae: 0.0565\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0089 - val_mae: 0.0711\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0545 - val_loss: 0.0054 - val_mae: 0.0534\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0545 - val_loss: 0.0048 - val_mae: 0.0501\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0080 - val_mae: 0.0685\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0547 - val_loss: 0.0051 - val_mae: 0.0535\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0065 - val_mae: 0.0587\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0049 - val_mae: 0.0519\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0053 - mae: 0.0545 - val_loss: 0.0054 - val_mae: 0.0536\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0053 - val_mae: 0.0543\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0049 - val_mae: 0.0512\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0069 - val_mae: 0.0631\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0546 - val_loss: 0.0058 - val_mae: 0.0584\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0050 - val_mae: 0.0514\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0050 - val_mae: 0.0513\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0055 - val_mae: 0.0557\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0057 - val_mae: 0.0554\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0055 - val_mae: 0.0544\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0053 - val_mae: 0.0544\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0052 - val_mae: 0.0526\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0049 - val_mae: 0.0517\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0051 - val_mae: 0.0526\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0055 - val_mae: 0.0554\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0077 - val_mae: 0.0657\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0060 - val_mae: 0.0566\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0053 - val_mae: 0.0554\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0061 - val_mae: 0.0606\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0052 - val_mae: 0.0527\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0538 - val_loss: 0.0051 - val_mae: 0.0534\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0069 - val_mae: 0.0645\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0056 - val_mae: 0.0571\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0538 - val_loss: 0.0056 - val_mae: 0.0547\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0058 - val_mae: 0.0581\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0055 - val_mae: 0.0540\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0054 - val_mae: 0.0552\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0048 - val_mae: 0.0507\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0050 - val_mae: 0.0516\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0048 - val_mae: 0.0503\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0057 - val_mae: 0.0579\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0054 - val_mae: 0.0549\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.0056 - val_mae: 0.0540\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0050 - val_mae: 0.0515\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.0054 - val_mae: 0.0532\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0055 - val_mae: 0.0531\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0061 - val_mae: 0.0568\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0053 - val_mae: 0.0536\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0557 - val_loss: 0.0054 - val_mae: 0.0533\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 47s 2ms/step - loss: 0.0056 - mae: 0.0560 - val_loss: 0.0054 - val_mae: 0.0548\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0056 - mae: 0.0557 - val_loss: 0.0068 - val_mae: 0.0642\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0560 - val_loss: 0.0075 - val_mae: 0.0646\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0559 - val_loss: 0.0056 - val_mae: 0.0562\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0560 - val_loss: 0.0057 - val_mae: 0.0570\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0560 - val_loss: 0.0059 - val_mae: 0.0584\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0561 - val_loss: 0.0055 - val_mae: 0.0543\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0562 - val_loss: 0.0055 - val_mae: 0.0547\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0564 - val_loss: 0.0056 - val_mae: 0.0555\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0566 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0056 - val_mae: 0.0560\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0054 - val_mae: 0.0538\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0566 - val_loss: 0.0079 - val_mae: 0.0676\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0563 - val_loss: 0.0061 - val_mae: 0.0595\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0055 - val_mae: 0.0542\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0554 - val_loss: 0.0058 - val_mae: 0.0552\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.0050 - val_mae: 0.0508\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0053 - val_mae: 0.0533\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0551 - val_loss: 0.0054 - val_mae: 0.0521\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.0060 - val_mae: 0.0594\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0553 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0066 - val_mae: 0.0620\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0557 - val_loss: 0.0055 - val_mae: 0.0548\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0557 - val_loss: 0.0052 - val_mae: 0.0529\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0057 - mae: 0.0560 - val_loss: 0.0061 - val_mae: 0.0598\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0562 - val_loss: 0.0053 - val_mae: 0.0526\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0566 - val_loss: 0.0060 - val_mae: 0.0594\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0568 - val_loss: 0.0064 - val_mae: 0.0587\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0570 - val_loss: 0.0056 - val_mae: 0.0549\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0569 - val_loss: 0.0064 - val_mae: 0.0588\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0571 - val_loss: 0.0053 - val_mae: 0.0510\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0575 - val_loss: 0.0066 - val_mae: 0.0573\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0576 - val_loss: 0.0061 - val_mae: 0.0595\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0062 - mae: 0.0579 - val_loss: 0.0062 - val_mae: 0.0583\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0579 - val_loss: 0.0056 - val_mae: 0.0542\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0071 - val_mae: 0.0603\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0062 - mae: 0.0582 - val_loss: 0.0063 - val_mae: 0.0557\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0063 - mae: 0.0585 - val_loss: 0.0100 - val_mae: 0.0817\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0063 - mae: 0.0587 - val_loss: 0.0064 - val_mae: 0.0578\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0063 - mae: 0.0582 - val_loss: 0.0058 - val_mae: 0.0534\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0063 - mae: 0.0586 - val_loss: 0.0067 - val_mae: 0.0613\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0062 - mae: 0.0585 - val_loss: 0.0059 - val_mae: 0.0577\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0062 - val_mae: 0.0589\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0581 - val_loss: 0.0063 - val_mae: 0.0597\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0061 - mae: 0.0579 - val_loss: 0.0064 - val_mae: 0.0595\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0576 - val_loss: 0.0068 - val_mae: 0.0619\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0060 - mae: 0.0576 - val_loss: 0.0055 - val_mae: 0.0540\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0060 - mae: 0.0577 - val_loss: 0.0056 - val_mae: 0.0554\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0577 - val_loss: 0.0060 - val_mae: 0.0580\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0087 - val_mae: 0.0726\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0575 - val_loss: 0.0058 - val_mae: 0.0558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0576 - val_loss: 0.0055 - val_mae: 0.0539\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0063 - val_mae: 0.0576\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0064 - val_mae: 0.0608\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0575 - val_loss: 0.0062 - val_mae: 0.0589\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0574 - val_loss: 0.0062 - val_mae: 0.0590\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0574 - val_loss: 0.0053 - val_mae: 0.0541\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0577 - val_loss: 0.0068 - val_mae: 0.0602\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0577 - val_loss: 0.0052 - val_mae: 0.0537\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0058 - mae: 0.0577 - val_loss: 0.0072 - val_mae: 0.0678\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0056 - val_mae: 0.0560\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0055 - val_mae: 0.0538\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0579 - val_loss: 0.0057 - val_mae: 0.0566\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0059 - mae: 0.0579 - val_loss: 0.0056 - val_mae: 0.0552\n",
      "processing fold # 4\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0784 - val_loss: 0.0061 - val_mae: 0.0576\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0067 - mae: 0.0612 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0063 - mae: 0.0594 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0061 - mae: 0.0587 - val_loss: 0.0087 - val_mae: 0.0695\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0060 - mae: 0.0580 - val_loss: 0.0054 - val_mae: 0.0551\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0056 - val_mae: 0.0562\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0058 - mae: 0.0568 - val_loss: 0.0056 - val_mae: 0.0555\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0057 - mae: 0.0562 - val_loss: 0.0066 - val_mae: 0.0614\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0559 - val_loss: 0.0060 - val_mae: 0.0606\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0056 - mae: 0.0555 - val_loss: 0.0050 - val_mae: 0.0518\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0050 - val_mae: 0.0517\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0550 - val_loss: 0.0047 - val_mae: 0.0500\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0062 - val_mae: 0.0588\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0049 - val_mae: 0.0528\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0055 - val_mae: 0.0551\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0047 - val_mae: 0.0510\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0071 - val_mae: 0.0664\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0050 - val_mae: 0.0517\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0051 - val_mae: 0.0532\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0048 - val_mae: 0.0502\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0547 - val_loss: 0.0050 - val_mae: 0.0527\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0049 - val_mae: 0.0516\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0048 - val_mae: 0.0510\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0066 - val_mae: 0.0642\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0054 - val_mae: 0.0552\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0052 - val_mae: 0.0542\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0532 - val_loss: 0.0046 - val_mae: 0.0494\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0046 - val_mae: 0.0494\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0524 - val_loss: 0.0047 - val_mae: 0.0500\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0052 - val_mae: 0.0533\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0524 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0046 - val_mae: 0.0497\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0524 - val_loss: 0.0049 - val_mae: 0.0523\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0520 - val_loss: 0.0046 - val_mae: 0.0505\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0520 - val_loss: 0.0044 - val_mae: 0.0483\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0518 - val_loss: 0.0054 - val_mae: 0.0538\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0065 - val_mae: 0.0638\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0519 - val_loss: 0.0044 - val_mae: 0.0482\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0045 - val_mae: 0.0490\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0046 - val_mae: 0.0497\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0521 - val_loss: 0.0043 - val_mae: 0.0480\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0521 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0069 - val_mae: 0.0651\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0527 - val_loss: 0.0045 - val_mae: 0.0490\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0046 - val_mae: 0.0505\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0044 - val_mae: 0.0488\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0052 - val_mae: 0.0524\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0531 - val_loss: 0.0053 - val_mae: 0.0538\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0052 - mae: 0.0531 - val_loss: 0.0049 - val_mae: 0.0512\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0047 - val_mae: 0.0510\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0043 - val_mae: 0.0483\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0516 - val_loss: 0.0049 - val_mae: 0.0528\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0057 - val_mae: 0.0564\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0046 - val_mae: 0.0508\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0517 - val_loss: 0.0045 - val_mae: 0.0491\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0519 - val_loss: 0.0053 - val_mae: 0.0539\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0052 - val_mae: 0.0534\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0043 - val_mae: 0.0481\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0043 - val_mae: 0.0475\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0049 - val_mae: 0.0531\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0047 - val_mae: 0.0508\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0048 - val_mae: 0.0510\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0048 - val_mae: 0.0511\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0043 - val_mae: 0.0485\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0050 - val_mae: 0.0529\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0049 - val_mae: 0.0515\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0042 - val_mae: 0.0476\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0043 - val_mae: 0.0488\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0510 - val_loss: 0.0045 - val_mae: 0.0493\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0509 - val_loss: 0.0042 - val_mae: 0.0471\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0056 - val_mae: 0.0544\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0054 - val_mae: 0.0541\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0048 - val_mae: 0.0518\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0047 - val_mae: 0.0506\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0515 - val_loss: 0.0042 - val_mae: 0.0481\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0047 - val_mae: 0.0504\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0046 - val_mae: 0.0494\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0046 - val_mae: 0.0510\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0052 - val_mae: 0.0546\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0043 - val_mae: 0.0486\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0062 - val_mae: 0.0604\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0049 - val_mae: 0.0541\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0050 - val_mae: 0.0517\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0050 - val_mae: 0.0544\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0045 - val_mae: 0.0500\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0048 - val_mae: 0.0503\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0043 - val_mae: 0.0485\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0048 - val_mae: 0.0522\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0065 - val_mae: 0.0599\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0524 - val_loss: 0.0057 - val_mae: 0.0564\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0060 - val_mae: 0.0559\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0045 - val_mae: 0.0498\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0531 - val_loss: 0.0056 - val_mae: 0.0565\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0044 - val_mae: 0.0489\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0055 - val_mae: 0.0559\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0531 - val_loss: 0.0048 - val_mae: 0.0524\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0532 - val_loss: 0.0045 - val_mae: 0.0486\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0044 - val_mae: 0.0491\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0047 - val_mae: 0.0497\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0534 - val_loss: 0.0044 - val_mae: 0.0493\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0534 - val_loss: 0.0052 - val_mae: 0.0525\n",
      "Epoch 104/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0058 - val_mae: 0.0596\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0531 - val_loss: 0.0051 - val_mae: 0.0548\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0051 - val_mae: 0.0536\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0535 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0531 - val_loss: 0.0046 - val_mae: 0.0499\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0056 - val_mae: 0.0561\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0049 - val_mae: 0.0536\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0059 - val_mae: 0.0575\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0054 - val_mae: 0.0571\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0047 - val_mae: 0.0523\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0045 - val_mae: 0.0495\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0043 - val_mae: 0.0484\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0048 - val_mae: 0.0504\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0046 - val_mae: 0.0512\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0045 - val_mae: 0.0505\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0042 - val_mae: 0.0476\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0050 - val_mae: 0.0523\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0051 - val_mae: 0.0544\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0046 - val_mae: 0.0510\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0066 - val_mae: 0.0648\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0045 - val_mae: 0.0500\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0047 - val_mae: 0.0496\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0044 - val_mae: 0.0492\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0047 - val_mae: 0.0505\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0532 - val_loss: 0.0047 - val_mae: 0.0515\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0533 - val_loss: 0.0062 - val_mae: 0.0596\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0046 - val_mae: 0.0507\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0070 - val_mae: 0.0641\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0045 - val_mae: 0.0502\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0050 - val_mae: 0.0529\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0531 - val_loss: 0.0044 - val_mae: 0.0491\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0053 - val_mae: 0.0541\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 37s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0043 - val_mae: 0.0488\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0051 - val_mae: 0.0555\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0532 - val_loss: 0.0049 - val_mae: 0.0516\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0531 - val_loss: 0.0054 - val_mae: 0.0546\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0043 - val_mae: 0.0480\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0055 - val_mae: 0.0543\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0532 - val_loss: 0.0052 - val_mae: 0.0528\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0041 - val_mae: 0.0469\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0045 - val_mae: 0.0485\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0528 - val_loss: 0.0058 - val_mae: 0.0559\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0051 - val_mae: 0.0553\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0050 - val_mae: 0.0538\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0047 - val_mae: 0.0500\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0051 - mae: 0.0529 - val_loss: 0.0043 - val_mae: 0.0478\n"
     ]
    }
   ],
   "source": [
    "histories, nmse = k_fold('sensor_1', 150, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.27307531306958077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse))\n",
    "\n",
    "num_epochs = 150\n",
    "val_mae_history = [np.mean([x['val_mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "mae_history = [np.mean([x['mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(3, len(val_mae_history) + 1), val_mae_history[2:], 'ro')\n",
    "plt.plot(range(3, len(mae_history) + 1), mae_history[2:], 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_history = [np.mean([x['val_loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "loss_history = [np.mean([x['loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, 'ro')\n",
    "plt.plot(range(1, len(loss_history) + 1), loss_history, 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_1']], epochs=75, batch_size=1, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15995104286519056116\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11722500253068193238\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow           2.1.0       /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages pip      \r\n",
      "tensorflow-estimator 2.1.0       /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages pip      \r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/35/55/a0dbd642e68e68f3e309d1413abdc0a7aa7e1534c79c0fc2501defb864ac/tensorflow-2.1.0-cp37-cp37m-macosx_10_11_x86_64.whl\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/85/7a/ae480be23b768910a9327c33517ced4623ba88dc035f9ce0206657c353a9/scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.33.1)\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.18.0)\n",
      "Collecting keras-applications>=1.0.8 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.7.0)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Collecting protobuf>=3.8.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/4c/25/c057a298635d08d087a20f51ff4287d821814208ebb045d84ea65535b3e3/protobuf-3.11.3-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.16.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/72/1c1498c1e908e0562b1e1cd30012580baa7d33b5b0ffdbeb5fde2462cc71/setuptools-45.2.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.1)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "\u001b[31mtensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.18.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, opt-einsum, scipy, wrapt, keras-applications, setuptools, protobuf, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, google-pasta, tensorflow-estimator, tensorflow\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/Users/sebastiangerard/Library/Python/3.7'\n",
      "Check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
