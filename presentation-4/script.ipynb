{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Data\n",
    "\n",
    "## Environment Settings\n",
    "\n",
    "An statistical Analysis of the data captured will be performed.\n",
    "\n",
    "The environment configuration is the following:\n",
    "\n",
    "- A rectangle area is used whose dimension is 2 x 1.5 meters. \n",
    "- A custom robot similar to an epuck was used.\n",
    "- The robot starts in the middle of the arena.\n",
    "- The robot moves in a random fashion way around the environment avoiding obstacles.\n",
    "- The robot has 8 sensors that measure the distance between the robot and the walls.\n",
    "- Some noise was introduced in the sensors measurements of the robot using the concept of [lookup tables](https://cyberbotics.com/doc/reference/distancesensor) in the Webots simulator which according to Webots documentation \"The first column of the table specifies the input distances, the second column specifies the corresponding desired response values, and the third column indicates the desired standard deviation of the noise. The noise on the return value is computed according to a gaussian random number distribution whose range is calculated as a percent of the response value (two times the standard deviation is often referred to as the signal quality)\". The following values were taken:\n",
    "\n",
    "    -First experiment:\n",
    "        - (0, 0, 0.01)\n",
    "        - (10, 10, 0.01)\n",
    "    -Second experiment:\n",
    "    \n",
    "        - (0, 0, 0.2)\n",
    "        - (10, 10, 0.2)\n",
    "- The simulator runs during 10 minutes in fast mode which is translated into 12 hours of collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install keras\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.920614</td>\n",
       "      <td>0.761198</td>\n",
       "      <td>168.209483</td>\n",
       "      <td>-0.070670</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>-11.790739</td>\n",
       "      <td>1.085179</td>\n",
       "      <td>0.790267</td>\n",
       "      <td>0.893342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139790</td>\n",
       "      <td>1.144901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.850135</td>\n",
       "      <td>0.775909</td>\n",
       "      <td>168.212418</td>\n",
       "      <td>-0.070479</td>\n",
       "      <td>0.014711</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.571635</td>\n",
       "      <td>0.596799</td>\n",
       "      <td>0.883340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830057</td>\n",
       "      <td>1.028332</td>\n",
       "      <td>-0.513544</td>\n",
       "      <td>-0.193468</td>\n",
       "      <td>-0.010002</td>\n",
       "      <td>-0.430864</td>\n",
       "      <td>-0.070277</td>\n",
       "      <td>-0.387726</td>\n",
       "      <td>-0.309733</td>\n",
       "      <td>-0.116568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.779657</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>168.209551</td>\n",
       "      <td>-0.070478</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>-0.002867</td>\n",
       "      <td>0.581452</td>\n",
       "      <td>0.904627</td>\n",
       "      <td>0.689004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491200</td>\n",
       "      <td>0.889130</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.307828</td>\n",
       "      <td>-0.194336</td>\n",
       "      <td>0.239518</td>\n",
       "      <td>0.206480</td>\n",
       "      <td>0.293382</td>\n",
       "      <td>-0.338857</td>\n",
       "      <td>-0.139203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.709174</td>\n",
       "      <td>0.805340</td>\n",
       "      <td>168.212871</td>\n",
       "      <td>-0.070483</td>\n",
       "      <td>0.014715</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.956302</td>\n",
       "      <td>0.842911</td>\n",
       "      <td>0.796714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246415</td>\n",
       "      <td>0.712158</td>\n",
       "      <td>0.374849</td>\n",
       "      <td>-0.061716</td>\n",
       "      <td>0.107710</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>-0.345782</td>\n",
       "      <td>-0.084918</td>\n",
       "      <td>0.755215</td>\n",
       "      <td>-0.176971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.638698</td>\n",
       "      <td>0.820056</td>\n",
       "      <td>168.208857</td>\n",
       "      <td>-0.070477</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>0.671731</td>\n",
       "      <td>0.779896</td>\n",
       "      <td>0.962191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>0.595164</td>\n",
       "      <td>-0.284570</td>\n",
       "      <td>-0.063014</td>\n",
       "      <td>0.165477</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.128150</td>\n",
       "      <td>-0.054777</td>\n",
       "      <td>-0.678608</td>\n",
       "      <td>-0.116994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         x         y       theta        dx        dy     dtheta  \\\n",
       "0           0  0.920614  0.761198  168.209483 -0.070670  0.011198 -11.790739   \n",
       "1           1  0.850135  0.775909  168.212418 -0.070479  0.014711   0.002935   \n",
       "2           2  0.779657  0.790625  168.209551 -0.070478  0.014716  -0.002867   \n",
       "3           3  0.709174  0.805340  168.212871 -0.070483  0.014715   0.003319   \n",
       "4           4  0.638698  0.820056  168.208857 -0.070477  0.014716  -0.004013   \n",
       "\n",
       "   sensor_1  sensor_2  sensor_3    ...      sensor_7  sensor_8  dsensor_1  \\\n",
       "0  1.085179  0.790267  0.893342    ...      1.139790  1.144901        NaN   \n",
       "1  0.571635  0.596799  0.883340    ...      0.830057  1.028332  -0.513544   \n",
       "2  0.581452  0.904627  0.689004    ...      0.491200  0.889130   0.009817   \n",
       "3  0.956302  0.842911  0.796714    ...      1.246415  0.712158   0.374849   \n",
       "4  0.671731  0.779896  0.962191    ...      0.567806  0.595164  -0.284570   \n",
       "\n",
       "   dsensor_2  dsensor_3  dsensor_4  dsensor_5  dsensor_6  dsensor_7  dsensor_8  \n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "1  -0.193468  -0.010002  -0.430864  -0.070277  -0.387726  -0.309733  -0.116568  \n",
       "2   0.307828  -0.194336   0.239518   0.206480   0.293382  -0.338857  -0.139203  \n",
       "3  -0.061716   0.107710   0.075412  -0.345782  -0.084918   0.755215  -0.176971  \n",
       "4  -0.063014   0.165477   0.005216   0.128150  -0.054777  -0.678608  -0.116994  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'robot_info_dataset-jumped.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected 1384848 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65342, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains some null values so they should be deleted from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data will be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "      <td>65341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>0.504753</td>\n",
       "      <td>0.502063</td>\n",
       "      <td>0.499785</td>\n",
       "      <td>0.500412</td>\n",
       "      <td>0.501624</td>\n",
       "      <td>0.239976</td>\n",
       "      <td>0.236145</td>\n",
       "      <td>0.261438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251293</td>\n",
       "      <td>0.242889</td>\n",
       "      <td>0.449485</td>\n",
       "      <td>0.468761</td>\n",
       "      <td>0.513828</td>\n",
       "      <td>0.507022</td>\n",
       "      <td>0.519272</td>\n",
       "      <td>0.531825</td>\n",
       "      <td>0.446832</td>\n",
       "      <td>0.426383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288682</td>\n",
       "      <td>0.272549</td>\n",
       "      <td>0.264025</td>\n",
       "      <td>0.290735</td>\n",
       "      <td>0.353425</td>\n",
       "      <td>0.335002</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.149030</td>\n",
       "      <td>0.169722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160999</td>\n",
       "      <td>0.143636</td>\n",
       "      <td>0.078247</td>\n",
       "      <td>0.073403</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.072415</td>\n",
       "      <td>0.077850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.255777</td>\n",
       "      <td>0.269104</td>\n",
       "      <td>0.251332</td>\n",
       "      <td>0.139102</td>\n",
       "      <td>0.181098</td>\n",
       "      <td>0.496242</td>\n",
       "      <td>0.127116</td>\n",
       "      <td>0.108774</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112714</td>\n",
       "      <td>0.127502</td>\n",
       "      <td>0.412053</td>\n",
       "      <td>0.436092</td>\n",
       "      <td>0.483323</td>\n",
       "      <td>0.477268</td>\n",
       "      <td>0.488782</td>\n",
       "      <td>0.501383</td>\n",
       "      <td>0.415117</td>\n",
       "      <td>0.388997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498537</td>\n",
       "      <td>0.503544</td>\n",
       "      <td>0.498631</td>\n",
       "      <td>0.500020</td>\n",
       "      <td>0.500797</td>\n",
       "      <td>0.501627</td>\n",
       "      <td>0.216759</td>\n",
       "      <td>0.215659</td>\n",
       "      <td>0.237666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224880</td>\n",
       "      <td>0.220298</td>\n",
       "      <td>0.442927</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>0.516314</td>\n",
       "      <td>0.512401</td>\n",
       "      <td>0.524693</td>\n",
       "      <td>0.534465</td>\n",
       "      <td>0.445713</td>\n",
       "      <td>0.419784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.735371</td>\n",
       "      <td>0.740156</td>\n",
       "      <td>0.752400</td>\n",
       "      <td>0.860369</td>\n",
       "      <td>0.821281</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>0.328127</td>\n",
       "      <td>0.337889</td>\n",
       "      <td>0.375692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360337</td>\n",
       "      <td>0.333973</td>\n",
       "      <td>0.479438</td>\n",
       "      <td>0.498031</td>\n",
       "      <td>0.547039</td>\n",
       "      <td>0.544322</td>\n",
       "      <td>0.557577</td>\n",
       "      <td>0.565527</td>\n",
       "      <td>0.475271</td>\n",
       "      <td>0.456114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             x             y         theta            dx  \\\n",
       "count  65341.000000  65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       0.500000      0.498321      0.504753      0.502063      0.499785   \n",
       "std        0.288682      0.272549      0.264025      0.290735      0.353425   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.250000      0.255777      0.269104      0.251332      0.139102   \n",
       "50%        0.500000      0.498537      0.503544      0.498631      0.500020   \n",
       "75%        0.750000      0.735371      0.740156      0.752400      0.860369   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 dy        dtheta      sensor_1      sensor_2      sensor_3  \\\n",
       "count  65341.000000  65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       0.500412      0.501624      0.239976      0.236145      0.261438   \n",
       "std        0.335002      0.114192      0.140647      0.149030      0.169722   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.181098      0.496242      0.127116      0.108774      0.119219   \n",
       "50%        0.500797      0.501627      0.216759      0.215659      0.237666   \n",
       "75%        0.821281      0.506991      0.328127      0.337889      0.375692   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...           sensor_7      sensor_8     dsensor_1     dsensor_2  \\\n",
       "count      ...       65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       ...           0.251293      0.242889      0.449485      0.468761   \n",
       "std        ...           0.160999      0.143636      0.078247      0.073403   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.112714      0.127502      0.412053      0.436092   \n",
       "50%        ...           0.224880      0.220298      0.442927      0.467409   \n",
       "75%        ...           0.360337      0.333973      0.479438      0.498031   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          dsensor_3     dsensor_4     dsensor_5     dsensor_6     dsensor_7  \\\n",
       "count  65341.000000  65341.000000  65341.000000  65341.000000  65341.000000   \n",
       "mean       0.513828      0.507022      0.519272      0.531825      0.446832   \n",
       "std        0.077416      0.078125      0.081846      0.080184      0.072415   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.483323      0.477268      0.488782      0.501383      0.415117   \n",
       "50%        0.516314      0.512401      0.524693      0.534465      0.445713   \n",
       "75%        0.547039      0.544322      0.557577      0.565527      0.475271   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          dsensor_8  \n",
       "count  65341.000000  \n",
       "mean       0.426383  \n",
       "std        0.077850  \n",
       "min        0.000000  \n",
       "25%        0.388997  \n",
       "50%        0.419784  \n",
       "75%        0.456114  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "normalized_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into training, testing and validation sets. 60% of the data will be used for training, 20% for training and 20% of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train size\n",
    "test_size_percentage = .2\n",
    "train_size_percentage = .6\n",
    "ds_size = normalized_df.shape[0]\n",
    "train_size = int(train_size_percentage * ds_size)\n",
    "test_size = int(test_size_percentage * ds_size)\n",
    "\n",
    "# shuffle dataset\n",
    "normalized_df = normalized_df.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs = normalized_df[['x', 'y', 'theta']]\n",
    "targets = normalized_df[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "# test\n",
    "test_inputs = inputs[train_size:(train_size + test_size)]\n",
    "test_targets = targets[train_size:(train_size + test_size)]\n",
    "\n",
    "# validation\n",
    "validation_inputs = inputs[(train_size + test_size):]\n",
    "validation_targets = targets[(train_size + test_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forsest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fit a random forest tree with 5 trees and each tree will handle $\\sqrt n$ number of variables available for splitting at each tree node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=5, n_jobs=1, oob_score=False,\n",
       "                      random_state=None, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 8;\n",
    "max_features = round(math.sqrt(n_features))\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=5, max_features=max_features, criterion='mse', verbose=False, n_jobs=1)\n",
    "reg.fit(train_inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importances x: 0.314563, y: 0.249262, theta: 0.436175\n",
      "\n",
      "R^2 score: 0.801145 \n",
      "\n",
      "Mean Absolute Error:\n",
      "0.04795014\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "76.94 %.\n",
      "\n",
      "NMSE\n",
      "0.20109603291958672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features importances x: %f, y: %f, theta: %f\" %(reg.feature_importances_[0], reg.feature_importances_[1], reg.feature_importances_[2]))\n",
    "print()\n",
    "predictions_targets = reg.predict(test_inputs)\n",
    "\n",
    "print(\"R^2 score: %f \\n\" % reg.score(test_inputs, test_targets))\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions_targets - test_targets)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:')\n",
    "print(round(np.mean(np.mean(errors)), 8))\n",
    "print()\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_targets)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print()\n",
    "print('Accuracy:')\n",
    "print(round(np.mean(accuracy), 2), '%.')\n",
    "print()\n",
    "\n",
    "nmse = np.mean((predictions_targets - test_targets)**2/np.var(test_targets))\n",
    "print(\"NMSE\")\n",
    "print(np.mean(nmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input the neural network receives the x, y coordinates and rotation angle $\\theta$. The output are the sensor measurements. The hidden layer uses relu as activation function. The loss function is MSE and it serves as a metric\n",
    "to minimize the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NN Architecture](nn_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(train_data):\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(8))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0191 - mae: 0.1093 - val_loss: 0.0170 - val_mae: 0.1035\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 27s 852us/step - loss: 0.0161 - mae: 0.0995 - val_loss: 0.0153 - val_mae: 0.0958\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0145 - mae: 0.0937 - val_loss: 0.0140 - val_mae: 0.0919\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0118 - val_mae: 0.0837\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 27s 850us/step - loss: 0.0122 - mae: 0.0849 - val_loss: 0.0125 - val_mae: 0.0859\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0111 - val_mae: 0.0798\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 27s 858us/step - loss: 0.0116 - mae: 0.0827 - val_loss: 0.0117 - val_mae: 0.0838\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0115 - mae: 0.0822 - val_loss: 0.0131 - val_mae: 0.0890\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 27s 851us/step - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0112 - val_mae: 0.0802\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0114 - mae: 0.0818 - val_loss: 0.0117 - val_mae: 0.0834\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0114 - mae: 0.0818 - val_loss: 0.0108 - val_mae: 0.0783\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0110 - val_mae: 0.0797\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 26s 841us/step - loss: 0.0113 - mae: 0.0816 - val_loss: 0.0110 - val_mae: 0.0801\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0111 - mae: 0.0809 - val_loss: 0.0110 - val_mae: 0.0806\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 28s 902us/step - loss: 0.0110 - mae: 0.0802 - val_loss: 0.0110 - val_mae: 0.0804\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 29s 916us/step - loss: 0.0109 - mae: 0.0801 - val_loss: 0.0114 - val_mae: 0.0825\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 29s 911us/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0102 - val_mae: 0.0771\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 30s 963us/step - loss: 0.0109 - mae: 0.0802 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 29s 910us/step - loss: 0.0109 - mae: 0.0802 - val_loss: 0.0102 - val_mae: 0.0763\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 27s 857us/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0111 - val_mae: 0.0806\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0103 - val_mae: 0.0771\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0144 - val_mae: 0.0944\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0112 - val_mae: 0.0819\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0110 - mae: 0.0805 - val_loss: 0.0109 - val_mae: 0.0799\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0113 - val_mae: 0.0818\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0110 - mae: 0.0806 - val_loss: 0.0127 - val_mae: 0.0868\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0110 - mae: 0.0806 - val_loss: 0.0120 - val_mae: 0.0842\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 27s 856us/step - loss: 0.0111 - mae: 0.0807 - val_loss: 0.0113 - val_mae: 0.0813\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0111 - mae: 0.0807 - val_loss: 0.0124 - val_mae: 0.0847\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0112 - mae: 0.0810 - val_loss: 0.0104 - val_mae: 0.0771\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 27s 858us/step - loss: 0.0112 - mae: 0.0810 - val_loss: 0.0105 - val_mae: 0.0773\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0134 - val_mae: 0.0909\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 26s 825us/step - loss: 0.0113 - mae: 0.0813 - val_loss: 0.0113 - val_mae: 0.0821\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0113 - mae: 0.0815 - val_loss: 0.0140 - val_mae: 0.0931\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 26s 828us/step - loss: 0.0113 - mae: 0.0813 - val_loss: 0.0130 - val_mae: 0.0889\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 26s 827us/step - loss: 0.0113 - mae: 0.0813 - val_loss: 0.0118 - val_mae: 0.0837\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 27s 850us/step - loss: 0.0113 - mae: 0.0814 - val_loss: 0.0104 - val_mae: 0.0788\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0113 - mae: 0.0814 - val_loss: 0.0117 - val_mae: 0.0825\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 27s 850us/step - loss: 0.0113 - mae: 0.0815 - val_loss: 0.0103 - val_mae: 0.0771\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0112 - mae: 0.0812 - val_loss: 0.0102 - val_mae: 0.0768\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 26s 831us/step - loss: 0.0111 - mae: 0.0810 - val_loss: 0.0113 - val_mae: 0.0818\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 26s 829us/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0120 - val_mae: 0.0851\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 26s 827us/step - loss: 0.0113 - mae: 0.0815 - val_loss: 0.0107 - val_mae: 0.0789\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 26s 830us/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0148 - val_mae: 0.0936\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 26s 831us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0124 - val_mae: 0.0861\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 26s 828us/step - loss: 0.0118 - mae: 0.0840 - val_loss: 0.0122 - val_mae: 0.0862\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0121 - mae: 0.0850 - val_loss: 0.0117 - val_mae: 0.0834\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 26s 831us/step - loss: 0.0123 - mae: 0.0856 - val_loss: 0.0138 - val_mae: 0.0912\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0124 - mae: 0.0859 - val_loss: 0.0119 - val_mae: 0.0845\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 26s 824us/step - loss: 0.0125 - mae: 0.0863 - val_loss: 0.0123 - val_mae: 0.0850\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 26s 832us/step - loss: 0.0126 - mae: 0.0866 - val_loss: 0.0188 - val_mae: 0.1093\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 26s 829us/step - loss: 0.0126 - mae: 0.0865 - val_loss: 0.0114 - val_mae: 0.0814\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 26s 829us/step - loss: 0.0126 - mae: 0.0867 - val_loss: 0.0145 - val_mae: 0.0929\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 26s 832us/step - loss: 0.0127 - mae: 0.0871 - val_loss: 0.0121 - val_mae: 0.0851\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 26s 836us/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0124 - val_mae: 0.0866\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 26s 829us/step - loss: 0.0130 - mae: 0.0882 - val_loss: 0.0119 - val_mae: 0.0842\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 26s 833us/step - loss: 0.0130 - mae: 0.0882 - val_loss: 0.0120 - val_mae: 0.0838\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 26s 827us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0136 - val_mae: 0.0893\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 28s 887us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0121 - val_mae: 0.0857\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 29s 919us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0120 - val_mae: 0.0841\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 30s 943us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0126 - val_mae: 0.0876\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 28s 898us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0122 - val_mae: 0.0843\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 28s 901us/step - loss: 0.0129 - mae: 0.0871 - val_loss: 0.0123 - val_mae: 0.0843\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0171 - val_mae: 0.1016\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 30s 962us/step - loss: 0.0131 - mae: 0.0879 - val_loss: 0.0129 - val_mae: 0.0860\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 29s 938us/step - loss: 0.0133 - mae: 0.0883 - val_loss: 0.0127 - val_mae: 0.0860\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 29s 918us/step - loss: 0.0131 - mae: 0.0877 - val_loss: 0.0129 - val_mae: 0.0868\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 31s 1ms/step - loss: 0.0122 - mae: 0.0849 - val_loss: 0.0116 - val_mae: 0.0828\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 30s 958us/step - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0123 - val_mae: 0.0860\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0118 - val_mae: 0.0828\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 26s 843us/step - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0126 - val_mae: 0.0841\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 26s 841us/step - loss: 0.0118 - mae: 0.0832 - val_loss: 0.0109 - val_mae: 0.0807\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 26s 845us/step - loss: 0.0118 - mae: 0.0833 - val_loss: 0.0114 - val_mae: 0.0800\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 27s 845us/step - loss: 0.0119 - mae: 0.0835 - val_loss: 0.0110 - val_mae: 0.0798\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 27s 860us/step - loss: 0.0120 - mae: 0.0838 - val_loss: 0.0123 - val_mae: 0.0855\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0122 - mae: 0.0845 - val_loss: 0.0135 - val_mae: 0.0896\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0123 - mae: 0.0850 - val_loss: 0.0117 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0125 - mae: 0.0856 - val_loss: 0.0146 - val_mae: 0.0927\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 30s 961us/step - loss: 0.0126 - mae: 0.0859 - val_loss: 0.0127 - val_mae: 0.0841\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 28s 886us/step - loss: 0.0127 - mae: 0.0862 - val_loss: 0.0135 - val_mae: 0.0906\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 29s 909us/step - loss: 0.0127 - mae: 0.0863 - val_loss: 0.0116 - val_mae: 0.0829\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 29s 917us/step - loss: 0.0128 - mae: 0.0866 - val_loss: 0.0135 - val_mae: 0.0892\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0128 - mae: 0.0867 - val_loss: 0.0163 - val_mae: 0.0995\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 27s 854us/step - loss: 0.0129 - mae: 0.0871 - val_loss: 0.0118 - val_mae: 0.0815\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0131 - mae: 0.0877 - val_loss: 0.0154 - val_mae: 0.0949\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0134 - mae: 0.0885 - val_loss: 0.0123 - val_mae: 0.0853\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 28s 891us/step - loss: 0.0135 - mae: 0.0890 - val_loss: 0.0149 - val_mae: 0.0944\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0136 - mae: 0.0895 - val_loss: 0.0134 - val_mae: 0.0889\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 27s 851us/step - loss: 0.0136 - mae: 0.0894 - val_loss: 0.0138 - val_mae: 0.0918\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0139 - mae: 0.0904 - val_loss: 0.0159 - val_mae: 0.0978\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0141 - mae: 0.0914 - val_loss: 0.0147 - val_mae: 0.0940\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0144 - mae: 0.0925 - val_loss: 0.0143 - val_mae: 0.0914\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0147 - mae: 0.0932 - val_loss: 0.0158 - val_mae: 0.0972\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0146 - mae: 0.0934 - val_loss: 0.0144 - val_mae: 0.0932\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0148 - mae: 0.0940 - val_loss: 0.0147 - val_mae: 0.0929\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0149 - mae: 0.0944 - val_loss: 0.0141 - val_mae: 0.0921\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 28s 881us/step - loss: 0.0150 - mae: 0.0949 - val_loss: 0.0169 - val_mae: 0.1011\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 29s 935us/step - loss: 0.0149 - mae: 0.0945 - val_loss: 0.0144 - val_mae: 0.0929\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 32s 1ms/step - loss: 0.0140 - mae: 0.0916 - val_loss: 0.0132 - val_mae: 0.0889\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0133 - mae: 0.0892 - val_loss: 0.0128 - val_mae: 0.0877\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0130 - mae: 0.0883 - val_loss: 0.0125 - val_mae: 0.0861\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 28s 898us/step - loss: 0.0128 - mae: 0.0878 - val_loss: 0.0131 - val_mae: 0.0880\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 28s 880us/step - loss: 0.0127 - mae: 0.0874 - val_loss: 0.0121 - val_mae: 0.0850\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0130 - val_mae: 0.0886\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 28s 906us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0854\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 30s 952us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0122 - val_mae: 0.0851\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 28s 882us/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0135 - val_mae: 0.0894\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 28s 898us/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0129 - val_mae: 0.0872\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 29s 922us/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0131 - val_mae: 0.0895\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 31s 975us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0149 - val_mae: 0.0950\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 29s 912us/step - loss: 0.0130 - mae: 0.0884 - val_loss: 0.0125 - val_mae: 0.0872\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0132 - mae: 0.0891 - val_loss: 0.0132 - val_mae: 0.0896\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0134 - mae: 0.0898 - val_loss: 0.0130 - val_mae: 0.0886\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0136 - mae: 0.0904 - val_loss: 0.0138 - val_mae: 0.0917\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0143 - val_mae: 0.0932\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 27s 851us/step - loss: 0.0137 - mae: 0.0910 - val_loss: 0.0137 - val_mae: 0.0913\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0143 - val_mae: 0.0929\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 26s 845us/step - loss: 0.0139 - mae: 0.0916 - val_loss: 0.0158 - val_mae: 0.0983\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0139 - mae: 0.0916 - val_loss: 0.0138 - val_mae: 0.0910\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0140 - mae: 0.0917 - val_loss: 0.0136 - val_mae: 0.0905\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0140 - mae: 0.0917 - val_loss: 0.0137 - val_mae: 0.0903\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0140 - mae: 0.0917 - val_loss: 0.0143 - val_mae: 0.0930\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0137 - val_mae: 0.0901\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0132 - val_mae: 0.0888\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0144 - val_mae: 0.0933\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 27s 858us/step - loss: 0.0130 - mae: 0.0880 - val_loss: 0.0135 - val_mae: 0.0906\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0131 - mae: 0.0883 - val_loss: 0.0133 - val_mae: 0.0891\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0132 - mae: 0.0888 - val_loss: 0.0135 - val_mae: 0.0899\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 27s 857us/step - loss: 0.0133 - mae: 0.0890 - val_loss: 0.0130 - val_mae: 0.0886\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 28s 898us/step - loss: 0.0134 - mae: 0.0893 - val_loss: 0.0139 - val_mae: 0.0909\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 26s 841us/step - loss: 0.0134 - mae: 0.0893 - val_loss: 0.0135 - val_mae: 0.0902\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0135 - mae: 0.0896 - val_loss: 0.0143 - val_mae: 0.0930\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0135 - mae: 0.0898 - val_loss: 0.0144 - val_mae: 0.0929\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 29s 921us/step - loss: 0.0136 - mae: 0.0898 - val_loss: 0.0143 - val_mae: 0.0934\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0136 - val_mae: 0.0899\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 28s 903us/step - loss: 0.0137 - mae: 0.0905 - val_loss: 0.0139 - val_mae: 0.0903\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 29s 919us/step - loss: 0.0138 - mae: 0.0905 - val_loss: 0.0139 - val_mae: 0.0904\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0907 - val_loss: 0.0162 - val_mae: 0.0996\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 31s 976us/step - loss: 0.0139 - mae: 0.0909 - val_loss: 0.0136 - val_mae: 0.0899\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0139 - mae: 0.0909 - val_loss: 0.0147 - val_mae: 0.0928\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0139 - mae: 0.0909 - val_loss: 0.0137 - val_mae: 0.0888\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 26s 837us/step - loss: 0.0140 - mae: 0.0913 - val_loss: 0.0141 - val_mae: 0.0924\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 26s 828us/step - loss: 0.0141 - mae: 0.0915 - val_loss: 0.0138 - val_mae: 0.0898\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0141 - mae: 0.0916 - val_loss: 0.0145 - val_mae: 0.0925\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0142 - mae: 0.0917 - val_loss: 0.0142 - val_mae: 0.0927\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 27s 860us/step - loss: 0.0142 - mae: 0.0917 - val_loss: 0.0145 - val_mae: 0.0920\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0142 - mae: 0.0918 - val_loss: 0.0141 - val_mae: 0.0912\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 30s 944us/step - loss: 0.0142 - mae: 0.0919 - val_loss: 0.0141 - val_mae: 0.0928\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 28s 880us/step - loss: 0.0143 - mae: 0.0920 - val_loss: 0.0142 - val_mae: 0.0908\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 28s 895us/step - loss: 0.0142 - mae: 0.0919 - val_loss: 0.0133 - val_mae: 0.0886\n",
      "processing fold # 1\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 28s 903us/step - loss: 0.0193 - mae: 0.1093 - val_loss: 0.0153 - val_mae: 0.0968\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 31s 976us/step - loss: 0.0136 - mae: 0.0894 - val_loss: 0.0126 - val_mae: 0.0854\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 29s 938us/step - loss: 0.0123 - mae: 0.0846 - val_loss: 0.0120 - val_mae: 0.0838\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 30s 967us/step - loss: 0.0124 - mae: 0.0848 - val_loss: 0.0122 - val_mae: 0.0843\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 30s 958us/step - loss: 0.0123 - mae: 0.0849 - val_loss: 0.0124 - val_mae: 0.0861\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0122 - mae: 0.0849 - val_loss: 0.0123 - val_mae: 0.0858\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0121 - mae: 0.0845 - val_loss: 0.0120 - val_mae: 0.0843\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0120 - mae: 0.0841 - val_loss: 0.0130 - val_mae: 0.0877\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 26s 840us/step - loss: 0.0119 - mae: 0.0838 - val_loss: 0.0116 - val_mae: 0.0829\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0116 - val_mae: 0.0821\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0118 - mae: 0.0833 - val_loss: 0.0118 - val_mae: 0.0838\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 29s 938us/step - loss: 0.0119 - mae: 0.0833 - val_loss: 0.0115 - val_mae: 0.0820\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0120 - mae: 0.0839 - val_loss: 0.0119 - val_mae: 0.0837\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 27s 855us/step - loss: 0.0123 - mae: 0.0848 - val_loss: 0.0124 - val_mae: 0.0845\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0124 - mae: 0.0850 - val_loss: 0.0123 - val_mae: 0.0848\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 29s 910us/step - loss: 0.0125 - mae: 0.0853 - val_loss: 0.0122 - val_mae: 0.0842\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 31s 978us/step - loss: 0.0126 - mae: 0.0861 - val_loss: 0.0130 - val_mae: 0.0878\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 27s 855us/step - loss: 0.0126 - mae: 0.0862 - val_loss: 0.0128 - val_mae: 0.0867\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0125 - mae: 0.0860 - val_loss: 0.0125 - val_mae: 0.0866\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0125 - mae: 0.0860 - val_loss: 0.0122 - val_mae: 0.0850\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0124 - mae: 0.0855 - val_loss: 0.0129 - val_mae: 0.0882\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 26s 840us/step - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0122 - val_mae: 0.0849\n",
      "Epoch 23/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 26s 836us/step - loss: 0.0126 - mae: 0.0862 - val_loss: 0.0120 - val_mae: 0.0844\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 26s 833us/step - loss: 0.0128 - mae: 0.0870 - val_loss: 0.0126 - val_mae: 0.0865\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 26s 834us/step - loss: 0.0131 - mae: 0.0880 - val_loss: 0.0132 - val_mae: 0.0890\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0133 - mae: 0.0890 - val_loss: 0.0127 - val_mae: 0.0867\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 26s 836us/step - loss: 0.0134 - mae: 0.0897 - val_loss: 0.0132 - val_mae: 0.0887\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 28s 895us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0129 - val_mae: 0.0886\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 30s 956us/step - loss: 0.0134 - mae: 0.0894 - val_loss: 0.0128 - val_mae: 0.0871\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 27s 855us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0161 - val_mae: 0.0995\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0135 - mae: 0.0897 - val_loss: 0.0130 - val_mae: 0.0882\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0135 - mae: 0.0899 - val_loss: 0.0141 - val_mae: 0.0923\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0135 - mae: 0.0899 - val_loss: 0.0132 - val_mae: 0.0895\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0135 - mae: 0.0897 - val_loss: 0.0134 - val_mae: 0.0886\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 27s 845us/step - loss: 0.0136 - mae: 0.0900 - val_loss: 0.0142 - val_mae: 0.0926\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0136 - mae: 0.0902 - val_loss: 0.0135 - val_mae: 0.0895\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 29s 924us/step - loss: 0.0136 - mae: 0.0902 - val_loss: 0.0129 - val_mae: 0.0881\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 29s 915us/step - loss: 0.0137 - mae: 0.0904 - val_loss: 0.0127 - val_mae: 0.0875\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 27s 854us/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0128 - val_mae: 0.0876\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0145 - val_mae: 0.0937\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 26s 834us/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0131 - val_mae: 0.0888\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0144 - val_mae: 0.0947\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 26s 840us/step - loss: 0.0137 - mae: 0.0905 - val_loss: 0.0153 - val_mae: 0.0970\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0131 - val_mae: 0.0890\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0145 - val_mae: 0.0942\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0130 - val_mae: 0.0882\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0152 - val_mae: 0.0943\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 26s 829us/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0133 - val_mae: 0.0891\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 31s 983us/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0130 - val_mae: 0.0887\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 26s 840us/step - loss: 0.0139 - mae: 0.0912 - val_loss: 0.0147 - val_mae: 0.0939\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 27s 857us/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0134 - val_mae: 0.08921s - loss: 0.0138 - mae: \n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 27s 855us/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0130 - val_mae: 0.0878\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0139 - mae: 0.0912 - val_loss: 0.0150 - val_mae: 0.0955\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 26s 832us/step - loss: 0.0139 - mae: 0.0912 - val_loss: 0.0133 - val_mae: 0.0893\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 26s 845us/step - loss: 0.0129 - mae: 0.0878 - val_loss: 0.0116 - val_mae: 0.0823\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0122 - val_mae: 0.0855\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 26s 834us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0125 - val_mae: 0.0869\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0129 - mae: 0.0878 - val_loss: 0.0128 - val_mae: 0.0869\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 27s 859us/step - loss: 0.0130 - mae: 0.0881 - val_loss: 0.0124 - val_mae: 0.0857\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0124 - val_mae: 0.0852\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0123 - val_mae: 0.0869\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0127 - mae: 0.0869 - val_loss: 0.0116 - val_mae: 0.0835\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 27s 856us/step - loss: 0.0126 - mae: 0.0866 - val_loss: 0.0120 - val_mae: 0.0841\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 27s 854us/step - loss: 0.0126 - mae: 0.0868 - val_loss: 0.0133 - val_mae: 0.0885\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 29s 916us/step - loss: 0.0127 - mae: 0.0868 - val_loss: 0.0120 - val_mae: 0.0834\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0127 - mae: 0.0869 - val_loss: 0.0132 - val_mae: 0.0884\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 28s 889us/step - loss: 0.0127 - mae: 0.0870 - val_loss: 0.0120 - val_mae: 0.0843\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0127 - mae: 0.0869 - val_loss: 0.0124 - val_mae: 0.0863\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 26s 834us/step - loss: 0.0127 - mae: 0.0869 - val_loss: 0.0145 - val_mae: 0.0945\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0127 - mae: 0.0869 - val_loss: 0.0125 - val_mae: 0.0858\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0127 - mae: 0.0870 - val_loss: 0.0128 - val_mae: 0.0876\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0127 - mae: 0.0868 - val_loss: 0.0123 - val_mae: 0.0852\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 26s 840us/step - loss: 0.0127 - mae: 0.0867 - val_loss: 0.0132 - val_mae: 0.0890\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 26s 841us/step - loss: 0.0126 - mae: 0.0865 - val_loss: 0.0121 - val_mae: 0.0844\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0125 - mae: 0.0862 - val_loss: 0.0127 - val_mae: 0.0879\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0125 - mae: 0.0860 - val_loss: 0.0130 - val_mae: 0.0895\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0125 - mae: 0.0863 - val_loss: 0.0130 - val_mae: 0.0884\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0125 - mae: 0.0862 - val_loss: 0.0123 - val_mae: 0.0855\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 30s 952us/step - loss: 0.0126 - mae: 0.0865 - val_loss: 0.0118 - val_mae: 0.0837\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 30s 945us/step - loss: 0.0126 - mae: 0.0866 - val_loss: 0.0120 - val_mae: 0.0840\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0127 - mae: 0.0870 - val_loss: 0.0122 - val_mae: 0.0853\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 29s 912us/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0135 - val_mae: 0.0900\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 31s 988us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0144 - val_mae: 0.0925\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0130 - mae: 0.0884 - val_loss: 0.0133 - val_mae: 0.0894\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0132 - mae: 0.0889 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0133 - mae: 0.0892 - val_loss: 0.0125 - val_mae: 0.0863\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 28s 880us/step - loss: 0.0134 - mae: 0.0898 - val_loss: 0.0126 - val_mae: 0.0866\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 30s 962us/step - loss: 0.0136 - mae: 0.0904 - val_loss: 0.0135 - val_mae: 0.0907\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 29s 914us/step - loss: 0.0137 - mae: 0.0909 - val_loss: 0.0130 - val_mae: 0.0880\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0137 - mae: 0.0909 - val_loss: 0.0141 - val_mae: 0.0921\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 28s 894us/step - loss: 0.0137 - mae: 0.0911 - val_loss: 0.0135 - val_mae: 0.0910\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 28s 894us/step - loss: 0.0138 - mae: 0.0913 - val_loss: 0.0148 - val_mae: 0.0947\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 28s 888us/step - loss: 0.0139 - mae: 0.0913 - val_loss: 0.0138 - val_mae: 0.0905\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 28s 895us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0135 - val_mae: 0.0912\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 28s 908us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0145 - val_mae: 0.0937\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 28s 886us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0138 - val_mae: 0.0915\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 29s 919us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0134 - val_mae: 0.0902\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 28s 889us/step - loss: 0.0139 - mae: 0.0916 - val_loss: 0.0130 - val_mae: 0.0881\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 28s 891us/step - loss: 0.0139 - mae: 0.0916 - val_loss: 0.0142 - val_mae: 0.0915\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0132 - val_mae: 0.0900\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0139 - mae: 0.0913 - val_loss: 0.0143 - val_mae: 0.0932\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 29s 922us/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0128 - val_mae: 0.0867\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 40s 1ms/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0132 - val_mae: 0.0893\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0136 - val_mae: 0.0906\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 31s 992us/step - loss: 0.0137 - mae: 0.0905 - val_loss: 0.0153 - val_mae: 0.0967\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 29s 918us/step - loss: 0.0136 - mae: 0.0903 - val_loss: 0.0136 - val_mae: 0.0905\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 27s 858us/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0143 - val_mae: 0.0927\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0135 - mae: 0.0899 - val_loss: 0.0153 - val_mae: 0.0967\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0134 - mae: 0.0897 - val_loss: 0.0131 - val_mae: 0.0889\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0125 - val_mae: 0.0867\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 26s 836us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0128 - val_mae: 0.0878\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 26s 836us/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0133 - val_mae: 0.0891\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 26s 839us/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0138 - val_mae: 0.0909\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0133 - mae: 0.0893 - val_loss: 0.0124 - val_mae: 0.0859\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 26s 834us/step - loss: 0.0133 - mae: 0.0893 - val_loss: 0.0161 - val_mae: 0.0996\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 26s 837us/step - loss: 0.0133 - mae: 0.0893 - val_loss: 0.0135 - val_mae: 0.0901\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0126 - val_mae: 0.0867\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0134 - mae: 0.0896 - val_loss: 0.0149 - val_mae: 0.0958\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0136 - mae: 0.0899 - val_loss: 0.0128 - val_mae: 0.0869\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0138 - mae: 0.0906 - val_loss: 0.0144 - val_mae: 0.0931\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0137 - val_mae: 0.0909\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 26s 837us/step - loss: 0.0135 - mae: 0.0902 - val_loss: 0.0136 - val_mae: 0.0905\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 26s 834us/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0125 - val_mae: 0.0863\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0131 - mae: 0.0889 - val_loss: 0.0130 - val_mae: 0.0892\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0130 - mae: 0.0884 - val_loss: 0.0143 - val_mae: 0.0934\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0129 - mae: 0.0881 - val_loss: 0.0115 - val_mae: 0.0826\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0127 - mae: 0.0875 - val_loss: 0.0119 - val_mae: 0.0843\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 26s 836us/step - loss: 0.0126 - mae: 0.0871 - val_loss: 0.0118 - val_mae: 0.0849\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 26s 833us/step - loss: 0.0125 - mae: 0.0868 - val_loss: 0.0129 - val_mae: 0.0872\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0125 - mae: 0.0868 - val_loss: 0.0120 - val_mae: 0.0847\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 26s 834us/step - loss: 0.0125 - mae: 0.0867 - val_loss: 0.0122 - val_mae: 0.0862\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0125 - mae: 0.0865 - val_loss: 0.0119 - val_mae: 0.0852\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 27s 851us/step - loss: 0.0124 - mae: 0.0863 - val_loss: 0.0118 - val_mae: 0.0847\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0123 - mae: 0.0858 - val_loss: 0.0116 - val_mae: 0.0836\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 27s 860us/step - loss: 0.0121 - mae: 0.0853 - val_loss: 0.0114 - val_mae: 0.0825\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 27s 851us/step - loss: 0.0120 - mae: 0.0849 - val_loss: 0.0114 - val_mae: 0.0829\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0120 - mae: 0.0847 - val_loss: 0.0120 - val_mae: 0.0855\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 27s 860us/step - loss: 0.0120 - mae: 0.0846 - val_loss: 0.0141 - val_mae: 0.0925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 26s 835us/step - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0124 - val_mae: 0.0877\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 26s 836us/step - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0110 - val_mae: 0.0803\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 26s 838us/step - loss: 0.0119 - mae: 0.0842 - val_loss: 0.0110 - val_mae: 0.0806\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 28s 898us/step - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0112 - val_mae: 0.0813\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0112 - val_mae: 0.0814\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0119 - mae: 0.0842 - val_loss: 0.0129 - val_mae: 0.0892\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0115 - val_mae: 0.0830\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0114 - val_mae: 0.0828\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 27s 856us/step - loss: 0.0118 - mae: 0.0840 - val_loss: 0.0121 - val_mae: 0.0851\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 27s 856us/step - loss: 0.0118 - mae: 0.0840 - val_loss: 0.0108 - val_mae: 0.0797\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 29s 937us/step - loss: 0.0119 - mae: 0.0842 - val_loss: 0.0124 - val_mae: 0.0859\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0119 - mae: 0.0840 - val_loss: 0.0119 - val_mae: 0.0846\n",
      "processing fold # 2\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 36s 1ms/step - loss: 0.0190 - mae: 0.1086 - val_loss: 0.0153 - val_mae: 0.0959\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0142 - mae: 0.0917 - val_loss: 0.0129 - val_mae: 0.0869\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0128 - mae: 0.0866 - val_loss: 0.0120 - val_mae: 0.0840\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0121 - mae: 0.0843 - val_loss: 0.0116 - val_mae: 0.0826\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0114 - val_mae: 0.0829\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 29s 923us/step - loss: 0.0119 - mae: 0.0838 - val_loss: 0.0116 - val_mae: 0.0828\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 28s 891us/step - loss: 0.0121 - mae: 0.0846 - val_loss: 0.0117 - val_mae: 0.0829\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0122 - mae: 0.0850 - val_loss: 0.0120 - val_mae: 0.0842\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 28s 890us/step - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0138 - val_mae: 0.0912\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0126 - mae: 0.0862 - val_loss: 0.0125 - val_mae: 0.0862\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0127 - mae: 0.0868 - val_loss: 0.0123 - val_mae: 0.0857\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 28s 891us/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0133 - val_mae: 0.0894\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 28s 881us/step - loss: 0.0130 - mae: 0.0877 - val_loss: 0.0123 - val_mae: 0.0849\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 31s 997us/step - loss: 0.0131 - mae: 0.0881 - val_loss: 0.0127 - val_mae: 0.0859\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0131 - mae: 0.0880 - val_loss: 0.0134 - val_mae: 0.0883\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 30s 959us/step - loss: 0.0131 - mae: 0.0880 - val_loss: 0.0127 - val_mae: 0.0864\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 28s 890us/step - loss: 0.0130 - mae: 0.0878 - val_loss: 0.0128 - val_mae: 0.0876\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 30s 968us/step - loss: 0.0131 - mae: 0.0879 - val_loss: 0.0128 - val_mae: 0.0869\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 30s 959us/step - loss: 0.0130 - mae: 0.0878 - val_loss: 0.0134 - val_mae: 0.0897\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 31s 989us/step - loss: 0.0130 - mae: 0.0877 - val_loss: 0.0126 - val_mae: 0.0862\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 28s 889us/step - loss: 0.0130 - mae: 0.0878 - val_loss: 0.0123 - val_mae: 0.0849\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0130 - mae: 0.0877 - val_loss: 0.0125 - val_mae: 0.0862\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0130 - mae: 0.0877 - val_loss: 0.0126 - val_mae: 0.0862\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0134 - val_mae: 0.0893\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0129 - val_mae: 0.0868\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 28s 882us/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0120 - val_mae: 0.0837\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0121 - val_mae: 0.0843\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 29s 934us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0129 - val_mae: 0.0872\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 39s 1ms/step - loss: 0.0128 - mae: 0.0870 - val_loss: 0.0130 - val_mae: 0.0883\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 31s 981us/step - loss: 0.0127 - mae: 0.0868 - val_loss: 0.0117 - val_mae: 0.0831\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0127 - mae: 0.0867 - val_loss: 0.0154 - val_mae: 0.0959\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 28s 899us/step - loss: 0.0126 - mae: 0.0866 - val_loss: 0.0122 - val_mae: 0.0859\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 31s 993us/step - loss: 0.0125 - mae: 0.0862 - val_loss: 0.0139 - val_mae: 0.0913\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 28s 905us/step - loss: 0.0124 - mae: 0.0858 - val_loss: 0.0122 - val_mae: 0.0859\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 28s 907us/step - loss: 0.0124 - mae: 0.0858 - val_loss: 0.0124 - val_mae: 0.0862\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 28s 887us/step - loss: 0.0122 - mae: 0.0853 - val_loss: 0.0115 - val_mae: 0.0826\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 32s 1ms/step - loss: 0.0121 - mae: 0.0848 - val_loss: 0.0113 - val_mae: 0.0825\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 28s 896us/step - loss: 0.0120 - mae: 0.0845 - val_loss: 0.0115 - val_mae: 0.0824\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 30s 969us/step - loss: 0.0120 - mae: 0.0845 - val_loss: 0.0111 - val_mae: 0.0806\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 29s 910us/step - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0114 - val_mae: 0.0827\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0119 - mae: 0.0840 - val_loss: 0.0118 - val_mae: 0.0836\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 28s 889us/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0129 - val_mae: 0.0886\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0115 - val_mae: 0.0829\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 28s 886us/step - loss: 0.0119 - mae: 0.0840 - val_loss: 0.0110 - val_mae: 0.0802\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 28s 888us/step - loss: 0.0119 - mae: 0.0839 - val_loss: 0.0109 - val_mae: 0.0805\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0110 - val_mae: 0.0811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0121 - val_mae: 0.0857\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0118 - val_mae: 0.0848\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 31s 999us/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0151 - val_mae: 0.0961\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 26s 845us/step - loss: 0.0118 - mae: 0.0839 - val_loss: 0.0123 - val_mae: 0.0857\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 27s 845us/step - loss: 0.0118 - mae: 0.0839 - val_loss: 0.0114 - val_mae: 0.0826\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0111 - val_mae: 0.0819\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0122 - val_mae: 0.0856\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 27s 854us/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0118 - val_mae: 0.0834\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 27s 851us/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0108 - val_mae: 0.0800\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 30s 948us/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0112 - val_mae: 0.0822\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0105 - val_mae: 0.0788\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 28s 888us/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0107 - val_mae: 0.0796\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 30s 945us/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0110 - val_mae: 0.0806\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 28s 880us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0126 - val_mae: 0.0874\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 29s 913us/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0114 - val_mae: 0.0822\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 32s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0116 - val_mae: 0.0822\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 28s 889us/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0118 - val_mae: 0.0843\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0118 - mae: 0.0836 - val_loss: 0.0110 - val_mae: 0.0807\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 27s 850us/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0111 - val_mae: 0.0822\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 27s 850us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0108 - val_mae: 0.0804\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 26s 844us/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0118 - val_mae: 0.0837\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0128 - val_mae: 0.0876\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 31s 975us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0125 - val_mae: 0.0867\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 29s 919us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0108 - val_mae: 0.0803\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 29s 920us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0114 - val_mae: 0.0826\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 29s 935us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0113 - val_mae: 0.0818\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 29s 921us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0108 - val_mae: 0.0801\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 29s 927us/step - loss: 0.0118 - mae: 0.0836 - val_loss: 0.0120 - val_mae: 0.0837\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 29s 920us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0108 - val_mae: 0.0801\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 29s 912us/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0133 - val_mae: 0.0899\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 29s 923us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0112 - val_mae: 0.0810\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 29s 923us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0110 - val_mae: 0.0811\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 29s 925us/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0112 - val_mae: 0.0813\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 29s 923us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0107 - val_mae: 0.0801\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 30s 970us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0105 - val_mae: 0.0788\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 28s 907us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0111 - val_mae: 0.0813\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0128 - val_mae: 0.0874\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 27s 856us/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0136 - val_mae: 0.0896\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0105 - val_mae: 0.0781\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0117 - mae: 0.0833 - val_loss: 0.0106 - val_mae: 0.0791\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0833 - val_loss: 0.0103 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 30s 944us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0106 - val_mae: 0.0793\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 29s 921us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0146 - val_mae: 0.0939\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 29s 914us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0129 - val_mae: 0.0886\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 29s 911us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0104 - val_mae: 0.0779\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 29s 912us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0120 - val_mae: 0.0847\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 29s 924us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0117 - val_mae: 0.0832\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 29s 921us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0117 - val_mae: 0.0831\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 29s 921us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0150 - val_mae: 0.0958\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 29s 921us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0109 - val_mae: 0.0807\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 29s 924us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0126 - val_mae: 0.0865\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 29s 920us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0107 - val_mae: 0.0798\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 29s 926us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0106 - val_mae: 0.0791\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 29s 923us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0111 - val_mae: 0.0814\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 29s 924us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0110 - val_mae: 0.0810\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 29s 926us/step - loss: 0.0116 - mae: 0.0830 - val_loss: 0.0109 - val_mae: 0.0809\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 29s 926us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0107 - val_mae: 0.0805\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 35s 1ms/step - loss: 0.0116 - mae: 0.0830 - val_loss: 0.0151 - val_mae: 0.0967\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 30s 951us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0121 - val_mae: 0.0867\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0103 - val_mae: 0.0783\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 31s 996us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0104 - val_mae: 0.0784\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 29s 934us/step - loss: 0.0116 - mae: 0.0830 - val_loss: 0.0111 - val_mae: 0.0812\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 29s 939us/step - loss: 0.0116 - mae: 0.0830 - val_loss: 0.0119 - val_mae: 0.0838\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 29s 928us/step - loss: 0.0116 - mae: 0.0830 - val_loss: 0.0110 - val_mae: 0.0811\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 31s 987us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0104 - val_mae: 0.0782\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 31s 980us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0105 - val_mae: 0.0791\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 31s 1ms/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0104 - val_mae: 0.0789\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 31s 999us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0113 - val_mae: 0.0817\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 27s 856us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0111 - val_mae: 0.0809\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 27s 853us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0109 - val_mae: 0.0802\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 27s 850us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0109 - val_mae: 0.0802\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 27s 852us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0120 - val_mae: 0.0842\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 27s 848us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0107 - val_mae: 0.0794\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0109 - val_mae: 0.0809\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 27s 846us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0104 - val_mae: 0.0783\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0122 - val_mae: 0.0853\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0109 - val_mae: 0.0804\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 27s 845us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0112 - val_mae: 0.0815\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 27s 845us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0109 - val_mae: 0.0804\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 27s 852us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0117 - val_mae: 0.0848\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 27s 849us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0176 - val_mae: 0.1047\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 26s 845us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0112 - val_mae: 0.0815\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 26s 842us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0106 - val_mae: 0.0792\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 27s 847us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0130 - val_mae: 0.0880\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 27s 845us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0106 - val_mae: 0.0786\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 27s 860us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0119 - val_mae: 0.0855\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 32s 1ms/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0113 - val_mae: 0.0828\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 28s 907us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0153 - val_mae: 0.0967\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0116 - val_mae: 0.0830\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 31s 978us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0121 - val_mae: 0.0851\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0112 - val_mae: 0.0812\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 27s 854us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0119 - val_mae: 0.0849\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 27s 859us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0122 - val_mae: 0.0856\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 27s 861us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0107 - val_mae: 0.0788\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 27s 855us/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0112 - val_mae: 0.0819\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 27s 861us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0120 - val_mae: 0.0847\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 27s 852us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0125 - val_mae: 0.0868\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 27s 858us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0110 - val_mae: 0.0819\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 27s 860us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0133 - val_mae: 0.0905\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0112 - val_mae: 0.0807\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 27s 854us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0106 - val_mae: 0.0791\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 27s 856us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0105 - val_mae: 0.0789\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 27s 858us/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0168 - val_mae: 0.1023\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 27s 854us/step - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0122 - val_mae: 0.0860\n",
      "processing fold # 3\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0204 - mae: 0.1130 - val_loss: 0.0179 - val_mae: 0.1052\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 27s 865us/step - loss: 0.0163 - mae: 0.0993 - val_loss: 0.0155 - val_mae: 0.0967\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0149 - mae: 0.0944 - val_loss: 0.0141 - val_mae: 0.0916\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0141 - mae: 0.0916 - val_loss: 0.0133 - val_mae: 0.0887\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0132 - mae: 0.0882 - val_loss: 0.0135 - val_mae: 0.0893\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0127 - val_mae: 0.0871\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0125 - mae: 0.0861 - val_loss: 0.0121 - val_mae: 0.0845\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0124 - val_mae: 0.0855\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0124 - mae: 0.0858 - val_loss: 0.0122 - val_mae: 0.0848\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0129 - val_mae: 0.0886\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0125 - mae: 0.0861 - val_loss: 0.0127 - val_mae: 0.0871\n",
      "Epoch 12/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0125 - mae: 0.0861 - val_loss: 0.0126 - val_mae: 0.0864\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 27s 860us/step - loss: 0.0124 - mae: 0.0860 - val_loss: 0.0121 - val_mae: 0.0848\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0123 - mae: 0.0857 - val_loss: 0.0121 - val_mae: 0.0849\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0122 - mae: 0.0852 - val_loss: 0.0117 - val_mae: 0.0834\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0121 - mae: 0.0848 - val_loss: 0.0122 - val_mae: 0.0852\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0121 - mae: 0.0846 - val_loss: 0.0120 - val_mae: 0.0844\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0120 - mae: 0.0845 - val_loss: 0.0118 - val_mae: 0.0835\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 27s 861us/step - loss: 0.0121 - mae: 0.0846 - val_loss: 0.0118 - val_mae: 0.0833\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0121 - mae: 0.0846 - val_loss: 0.0117 - val_mae: 0.0834\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0121 - mae: 0.0846 - val_loss: 0.0119 - val_mae: 0.0847\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0121 - mae: 0.0846 - val_loss: 0.0122 - val_mae: 0.0851\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 27s 865us/step - loss: 0.0121 - mae: 0.0848 - val_loss: 0.0117 - val_mae: 0.0835\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 27s 861us/step - loss: 0.0121 - mae: 0.0847 - val_loss: 0.0122 - val_mae: 0.0848\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 27s 857us/step - loss: 0.0121 - mae: 0.0848 - val_loss: 0.0119 - val_mae: 0.0830\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 27s 857us/step - loss: 0.0121 - mae: 0.0849 - val_loss: 0.0123 - val_mae: 0.0853\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0121 - mae: 0.0850 - val_loss: 0.0119 - val_mae: 0.0845\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 28s 898us/step - loss: 0.0121 - mae: 0.0850 - val_loss: 0.0120 - val_mae: 0.0838\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 27s 859us/step - loss: 0.0121 - mae: 0.0850 - val_loss: 0.0122 - val_mae: 0.0856\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0122 - mae: 0.0852 - val_loss: 0.0117 - val_mae: 0.0835\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0122 - mae: 0.0853 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0122 - mae: 0.0855 - val_loss: 0.0142 - val_mae: 0.0927\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0123 - mae: 0.0855 - val_loss: 0.0119 - val_mae: 0.0838\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0123 - mae: 0.0857 - val_loss: 0.0121 - val_mae: 0.0841\n",
      "Epoch 35/150\n",
      "31364/31364 [==============================] - 27s 859us/step - loss: 0.0124 - mae: 0.0860 - val_loss: 0.0126 - val_mae: 0.0869\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 27s 858us/step - loss: 0.0125 - mae: 0.0863 - val_loss: 0.0121 - val_mae: 0.0852\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0125 - mae: 0.0864 - val_loss: 0.0123 - val_mae: 0.0854\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0126 - mae: 0.0867 - val_loss: 0.0125 - val_mae: 0.0861\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0127 - mae: 0.0869 - val_loss: 0.0137 - val_mae: 0.0907\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0855\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0129 - val_mae: 0.0877\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0121 - val_mae: 0.0847\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0132 - val_mae: 0.0891\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 27s 865us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0122 - val_mae: 0.0848\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0129 - val_mae: 0.0876\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0848\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 27s 862us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0138 - val_mae: 0.0911\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0131 - val_mae: 0.0879\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0127 - mae: 0.0871 - val_loss: 0.0137 - val_mae: 0.0907\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0150 - val_mae: 0.0954\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 27s 863us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0121 - val_mae: 0.0841\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0131 - val_mae: 0.0893\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0127 - val_mae: 0.0872\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 27s 865us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0126 - val_mae: 0.0862\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 27s 861us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0123 - val_mae: 0.0850\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 27s 861us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0119 - val_mae: 0.0838\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 27s 855us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0122 - val_mae: 0.0846\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 32s 1ms/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0129 - val_mae: 0.0869\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 28s 881us/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0129 - val_mae: 0.0886\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 1236s 39ms/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0137 - val_mae: 0.0910\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 1228s 39ms/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0129 - val_mae: 0.0879\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 1260s 40ms/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0126 - val_mae: 0.0867\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 1273s 41ms/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0120 - val_mae: 0.0845\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 678s 22ms/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0130 - val_mae: 0.0883\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 156s 5ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0121 - val_mae: 0.0845\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 116s 4ms/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0129 - val_mae: 0.0884\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 105s 3ms/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0138 - val_mae: 0.0908\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 104s 3ms/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0127 - val_mae: 0.0871\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 2101s 67ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0126 - val_mae: 0.0862\n",
      "Epoch 70/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 85s 3ms/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0130 - val_mae: 0.0873\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 81s 3ms/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0142 - val_mae: 0.0939\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 82s 3ms/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0120 - val_mae: 0.0841\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 83s 3ms/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0127 - val_mae: 0.0868\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0119 - val_mae: 0.0839\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 85s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0130 - val_mae: 0.0879\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 87s 3ms/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0126 - val_mae: 0.0858\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 2347s 75ms/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0134 - val_mae: 0.0904\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 82s 3ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0120 - val_mae: 0.0841\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 88s 3ms/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0126 - val_mae: 0.0869\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 83s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0120 - val_mae: 0.0838\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0134 - val_mae: 0.0899\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0133 - val_mae: 0.0899\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 85s 3ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0131 - val_mae: 0.0893\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 86s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0129 - val_mae: 0.0878\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 1061s 34ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0182 - val_mae: 0.1061\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 2020s 64ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0120 - val_mae: 0.0835\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 86s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 83s 3ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0122 - val_mae: 0.0844\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 87s 3ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0121 - val_mae: 0.0850\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 85s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0122 - val_mae: 0.0852\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0877 - val_loss: 0.0123 - val_mae: 0.0850\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 85s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0123 - val_mae: 0.0853\n",
      "Epoch 93/150\n",
      "31364/31364 [==============================] - 86s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0134 - val_mae: 0.0898\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 85s 3ms/step - loss: 0.0129 - mae: 0.0876 - val_loss: 0.0127 - val_mae: 0.0864\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 2110s 67ms/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0145 - val_mae: 0.0950\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0875 - val_loss: 0.0123 - val_mae: 0.0853\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0122 - val_mae: 0.0849\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0128 - val_mae: 0.0884\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 84s 3ms/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0126 - val_mae: 0.0862\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 85s 3ms/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0121 - val_mae: 0.0843\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 87s 3ms/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0130 - val_mae: 0.0883\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 10436s 333ms/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0121 - val_mae: 0.0840\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 33s 1ms/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0124 - val_mae: 0.0860\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 28s 901us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0119 - val_mae: 0.0839\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 28s 886us/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0140 - val_mae: 0.0920\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0120 - val_mae: 0.0841\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 28s 882us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0121 - val_mae: 0.0847\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 28s 888us/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0121 - val_mae: 0.0840\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0123 - val_mae: 0.0851\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0125 - val_mae: 0.0867\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0123 - val_mae: 0.0847\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0858\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0130 - val_mae: 0.0879\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 28s 890us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0127 - val_mae: 0.0867\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 28s 882us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0126 - val_mae: 0.0869\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0124 - val_mae: 0.0855\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0140 - val_mae: 0.0915\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0125 - val_mae: 0.0849\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0128 - val_mae: 0.0876\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0123 - val_mae: 0.0858\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0121 - val_mae: 0.0841\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0127 - val_mae: 0.0870\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0122 - val_mae: 0.0847\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0124 - val_mae: 0.0857\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0133 - val_mae: 0.0891\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0153 - val_mae: 0.0962\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 27s 877us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0173 - val_mae: 0.1026\n",
      "Epoch 128/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0134 - val_mae: 0.0894\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 28s 881us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0146 - val_mae: 0.0939\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 28s 894us/step - loss: 0.0128 - mae: 0.0870 - val_loss: 0.0132 - val_mae: 0.0895\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 27s 877us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0124 - val_mae: 0.0850\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0124 - val_mae: 0.0855\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0856\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0135 - val_mae: 0.0900\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 27s 865us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0127 - val_mae: 0.0862\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0849\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0128 - mae: 0.0873 - val_loss: 0.0136 - val_mae: 0.0904\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0122 - val_mae: 0.0848\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0145 - val_mae: 0.0938\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0852\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0128 - val_mae: 0.0881\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0129 - val_mae: 0.0875\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0124 - val_mae: 0.0860\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0131 - val_mae: 0.0884\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0128 - mae: 0.0871 - val_loss: 0.0140 - val_mae: 0.0911\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0845\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0129 - val_mae: 0.0868\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0139 - val_mae: 0.0904\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0122 - val_mae: 0.0852\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0128 - mae: 0.0872 - val_loss: 0.0139 - val_mae: 0.0918\n",
      "processing fold # 4\n",
      "Train on 31364 samples, validate on 7840 samples\n",
      "Epoch 1/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0209 - mae: 0.1146 - val_loss: 0.0183 - val_mae: 0.1059\n",
      "Epoch 2/150\n",
      "31364/31364 [==============================] - 28s 900us/step - loss: 0.0171 - mae: 0.1024 - val_loss: 0.0155 - val_mae: 0.0970\n",
      "Epoch 3/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0158 - mae: 0.0975 - val_loss: 0.0155 - val_mae: 0.0976\n",
      "Epoch 4/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0156 - mae: 0.0966 - val_loss: 0.0154 - val_mae: 0.0973\n",
      "Epoch 5/150\n",
      "31364/31364 [==============================] - 28s 887us/step - loss: 0.0156 - mae: 0.0967 - val_loss: 0.0167 - val_mae: 0.1009\n",
      "Epoch 6/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0156 - mae: 0.0968 - val_loss: 0.0165 - val_mae: 0.0998\n",
      "Epoch 7/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0156 - mae: 0.0968 - val_loss: 0.0150 - val_mae: 0.0943\n",
      "Epoch 8/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0157 - mae: 0.0970 - val_loss: 0.0161 - val_mae: 0.0968\n",
      "Epoch 9/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0156 - mae: 0.0968 - val_loss: 0.0159 - val_mae: 0.0978\n",
      "Epoch 10/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0156 - mae: 0.0966 - val_loss: 0.0165 - val_mae: 0.0988\n",
      "Epoch 11/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0154 - mae: 0.0958 - val_loss: 0.0154 - val_mae: 0.0935\n",
      "Epoch 12/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0153 - mae: 0.0954 - val_loss: 0.0180 - val_mae: 0.1051\n",
      "Epoch 13/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0153 - mae: 0.0958 - val_loss: 0.0153 - val_mae: 0.0964\n",
      "Epoch 14/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0153 - mae: 0.0957 - val_loss: 0.0173 - val_mae: 0.1034\n",
      "Epoch 15/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0149 - mae: 0.0947 - val_loss: 0.0176 - val_mae: 0.1022\n",
      "Epoch 16/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0144 - mae: 0.0928 - val_loss: 0.0134 - val_mae: 0.0904\n",
      "Epoch 17/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0139 - mae: 0.0911 - val_loss: 0.0130 - val_mae: 0.0881\n",
      "Epoch 18/150\n",
      "31364/31364 [==============================] - 29s 911us/step - loss: 0.0137 - mae: 0.0905 - val_loss: 0.0141 - val_mae: 0.0914\n",
      "Epoch 19/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0136 - mae: 0.0903 - val_loss: 0.0131 - val_mae: 0.0889\n",
      "Epoch 20/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0136 - mae: 0.0904 - val_loss: 0.0136 - val_mae: 0.0894\n",
      "Epoch 21/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0136 - mae: 0.0903 - val_loss: 0.0133 - val_mae: 0.0906\n",
      "Epoch 22/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0136 - mae: 0.0905 - val_loss: 0.0130 - val_mae: 0.0880\n",
      "Epoch 23/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0137 - mae: 0.0907 - val_loss: 0.0141 - val_mae: 0.0926\n",
      "Epoch 24/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0133 - val_mae: 0.0895\n",
      "Epoch 25/150\n",
      "31364/31364 [==============================] - 27s 877us/step - loss: 0.0136 - mae: 0.0906 - val_loss: 0.0139 - val_mae: 0.0907\n",
      "Epoch 26/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0150 - val_mae: 0.0951\n",
      "Epoch 27/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0149 - val_mae: 0.0949\n",
      "Epoch 28/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0141 - val_mae: 0.0913\n",
      "Epoch 29/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0137 - mae: 0.0907 - val_loss: 0.0131 - val_mae: 0.0892\n",
      "Epoch 30/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0137 - mae: 0.0907 - val_loss: 0.0132 - val_mae: 0.0888\n",
      "Epoch 31/150\n",
      "31364/31364 [==============================] - 28s 891us/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0130 - val_mae: 0.0874\n",
      "Epoch 32/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0153 - val_mae: 0.0966\n",
      "Epoch 33/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0139 - mae: 0.0913 - val_loss: 0.0169 - val_mae: 0.1022\n",
      "Epoch 34/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0140 - mae: 0.0917 - val_loss: 0.0145 - val_mae: 0.0930\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0141 - mae: 0.0920 - val_loss: 0.0140 - val_mae: 0.0923\n",
      "Epoch 36/150\n",
      "31364/31364 [==============================] - 28s 881us/step - loss: 0.0142 - mae: 0.0922 - val_loss: 0.0137 - val_mae: 0.0900\n",
      "Epoch 37/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0144 - mae: 0.0926 - val_loss: 0.0139 - val_mae: 0.0912\n",
      "Epoch 38/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0145 - mae: 0.0930 - val_loss: 0.0142 - val_mae: 0.0918\n",
      "Epoch 39/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0146 - mae: 0.0934 - val_loss: 0.0145 - val_mae: 0.0933\n",
      "Epoch 40/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0148 - mae: 0.0942 - val_loss: 0.0154 - val_mae: 0.0954\n",
      "Epoch 41/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0148 - mae: 0.0946 - val_loss: 0.0170 - val_mae: 0.1010\n",
      "Epoch 42/150\n",
      "31364/31364 [==============================] - 27s 864us/step - loss: 0.0145 - mae: 0.0937 - val_loss: 0.0140 - val_mae: 0.0916\n",
      "Epoch 43/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0140 - mae: 0.0923 - val_loss: 0.0132 - val_mae: 0.0890\n",
      "Epoch 44/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0136 - mae: 0.0906 - val_loss: 0.0129 - val_mae: 0.0881\n",
      "Epoch 45/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0132 - mae: 0.0892 - val_loss: 0.0132 - val_mae: 0.0879\n",
      "Epoch 46/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0130 - mae: 0.0885 - val_loss: 0.0140 - val_mae: 0.0933\n",
      "Epoch 47/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0130 - mae: 0.0882 - val_loss: 0.0128 - val_mae: 0.0878\n",
      "Epoch 48/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0130 - mae: 0.0883 - val_loss: 0.0127 - val_mae: 0.0871\n",
      "Epoch 49/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0129 - mae: 0.0878 - val_loss: 0.0138 - val_mae: 0.0928\n",
      "Epoch 50/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0128 - mae: 0.0878 - val_loss: 0.0122 - val_mae: 0.0863\n",
      "Epoch 51/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0128 - mae: 0.0876 - val_loss: 0.0138 - val_mae: 0.0912\n",
      "Epoch 52/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0128 - val_mae: 0.0885\n",
      "Epoch 53/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0161 - val_mae: 0.0991\n",
      "Epoch 54/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0127 - val_mae: 0.0857\n",
      "Epoch 55/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0859\n",
      "Epoch 56/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0127 - mae: 0.0872 - val_loss: 0.0117 - val_mae: 0.0832\n",
      "Epoch 57/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0127 - mae: 0.0873 - val_loss: 0.0124 - val_mae: 0.0861\n",
      "Epoch 58/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0127 - mae: 0.0874 - val_loss: 0.0119 - val_mae: 0.0845\n",
      "Epoch 59/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0128 - mae: 0.0874 - val_loss: 0.0129 - val_mae: 0.0872\n",
      "Epoch 60/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0137 - val_mae: 0.0911\n",
      "Epoch 61/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0125 - val_mae: 0.0867\n",
      "Epoch 62/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0120 - val_mae: 0.0851\n",
      "Epoch 63/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0129 - mae: 0.0878 - val_loss: 0.0125 - val_mae: 0.0869\n",
      "Epoch 64/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0115 - val_mae: 0.0823\n",
      "Epoch 65/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0129 - mae: 0.0878 - val_loss: 0.0116 - val_mae: 0.0825\n",
      "Epoch 66/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0122 - val_mae: 0.0854\n",
      "Epoch 67/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0127 - val_mae: 0.0880\n",
      "Epoch 68/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0128 - val_mae: 0.0881\n",
      "Epoch 69/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0118 - val_mae: 0.0849\n",
      "Epoch 70/150\n",
      "31364/31364 [==============================] - 27s 877us/step - loss: 0.0128 - mae: 0.0879 - val_loss: 0.0117 - val_mae: 0.0842\n",
      "Epoch 71/150\n",
      "31364/31364 [==============================] - 28s 880us/step - loss: 0.0129 - mae: 0.0879 - val_loss: 0.0130 - val_mae: 0.0887\n",
      "Epoch 72/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0129 - mae: 0.0880 - val_loss: 0.0141 - val_mae: 0.0934\n",
      "Epoch 73/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0128 - mae: 0.0879 - val_loss: 0.0121 - val_mae: 0.0854\n",
      "Epoch 74/150\n",
      "31364/31364 [==============================] - 28s 880us/step - loss: 0.0129 - mae: 0.0880 - val_loss: 0.0115 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0129 - mae: 0.0881 - val_loss: 0.0120 - val_mae: 0.0851\n",
      "Epoch 76/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0129 - mae: 0.0880 - val_loss: 0.0133 - val_mae: 0.0898\n",
      "Epoch 77/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0129 - mae: 0.0881 - val_loss: 0.0142 - val_mae: 0.0925\n",
      "Epoch 78/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0129 - mae: 0.0882 - val_loss: 0.0134 - val_mae: 0.0905\n",
      "Epoch 79/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0129 - mae: 0.0882 - val_loss: 0.0122 - val_mae: 0.0855\n",
      "Epoch 80/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0129 - mae: 0.0882 - val_loss: 0.0122 - val_mae: 0.0852\n",
      "Epoch 81/150\n",
      "31364/31364 [==============================] - 27s 877us/step - loss: 0.0129 - mae: 0.0883 - val_loss: 0.0132 - val_mae: 0.0895\n",
      "Epoch 82/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0130 - mae: 0.0884 - val_loss: 0.0119 - val_mae: 0.0844\n",
      "Epoch 83/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0130 - mae: 0.0884 - val_loss: 0.0154 - val_mae: 0.0980\n",
      "Epoch 84/150\n",
      "31364/31364 [==============================] - 28s 899us/step - loss: 0.0130 - mae: 0.0883 - val_loss: 0.0121 - val_mae: 0.0855\n",
      "Epoch 85/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0130 - mae: 0.0885 - val_loss: 0.0128 - val_mae: 0.0873\n",
      "Epoch 86/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0130 - mae: 0.0886 - val_loss: 0.0133 - val_mae: 0.0897\n",
      "Epoch 87/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0130 - mae: 0.0885 - val_loss: 0.0138 - val_mae: 0.0928\n",
      "Epoch 88/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0130 - mae: 0.0885 - val_loss: 0.0136 - val_mae: 0.0917\n",
      "Epoch 89/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0130 - mae: 0.0884 - val_loss: 0.0123 - val_mae: 0.0857\n",
      "Epoch 90/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0130 - mae: 0.0886 - val_loss: 0.0122 - val_mae: 0.0855\n",
      "Epoch 91/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0130 - mae: 0.0885 - val_loss: 0.0168 - val_mae: 0.1031\n",
      "Epoch 92/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0131 - mae: 0.0888 - val_loss: 0.0122 - val_mae: 0.0862\n",
      "Epoch 93/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0131 - mae: 0.0887 - val_loss: 0.0114 - val_mae: 0.0821\n",
      "Epoch 94/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0131 - mae: 0.0888 - val_loss: 0.0162 - val_mae: 0.1004\n",
      "Epoch 95/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0131 - mae: 0.0887 - val_loss: 0.0122 - val_mae: 0.0861\n",
      "Epoch 96/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0131 - mae: 0.0888 - val_loss: 0.0122 - val_mae: 0.0851\n",
      "Epoch 97/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0131 - mae: 0.0887 - val_loss: 0.0133 - val_mae: 0.0899\n",
      "Epoch 98/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0131 - mae: 0.0888 - val_loss: 0.0140 - val_mae: 0.0926\n",
      "Epoch 99/150\n",
      "31364/31364 [==============================] - 27s 865us/step - loss: 0.0131 - mae: 0.0888 - val_loss: 0.0157 - val_mae: 0.0988\n",
      "Epoch 100/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0131 - mae: 0.0889 - val_loss: 0.0151 - val_mae: 0.0957\n",
      "Epoch 101/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0132 - mae: 0.0890 - val_loss: 0.0133 - val_mae: 0.0898\n",
      "Epoch 102/150\n",
      "31364/31364 [==============================] - 27s 867us/step - loss: 0.0132 - mae: 0.0890 - val_loss: 0.0125 - val_mae: 0.0871\n",
      "Epoch 103/150\n",
      "31364/31364 [==============================] - 28s 881us/step - loss: 0.0132 - mae: 0.0892 - val_loss: 0.0118 - val_mae: 0.0838\n",
      "Epoch 104/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0132 - mae: 0.0891 - val_loss: 0.0126 - val_mae: 0.0864\n",
      "Epoch 105/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0133 - mae: 0.0893 - val_loss: 0.0145 - val_mae: 0.0944\n",
      "Epoch 106/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0133 - mae: 0.0892 - val_loss: 0.0131 - val_mae: 0.0883\n",
      "Epoch 107/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0134 - mae: 0.0896 - val_loss: 0.0125 - val_mae: 0.0869\n",
      "Epoch 108/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0133 - mae: 0.0895 - val_loss: 0.0120 - val_mae: 0.0841\n",
      "Epoch 109/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0133 - mae: 0.0893 - val_loss: 0.0133 - val_mae: 0.0904\n",
      "Epoch 110/150\n",
      "31364/31364 [==============================] - 28s 879us/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0118 - val_mae: 0.0841\n",
      "Epoch 111/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0132 - mae: 0.0891 - val_loss: 0.0155 - val_mae: 0.0977\n",
      "Epoch 112/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0132 - mae: 0.0890 - val_loss: 0.0127 - val_mae: 0.0870\n",
      "Epoch 113/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0132 - mae: 0.0892 - val_loss: 0.0134 - val_mae: 0.0894\n",
      "Epoch 114/150\n",
      "31364/31364 [==============================] - 27s 869us/step - loss: 0.0132 - mae: 0.0891 - val_loss: 0.0127 - val_mae: 0.0875\n",
      "Epoch 115/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0133 - mae: 0.0893 - val_loss: 0.0117 - val_mae: 0.0836\n",
      "Epoch 116/150\n",
      "31364/31364 [==============================] - 27s 868us/step - loss: 0.0133 - mae: 0.0892 - val_loss: 0.0141 - val_mae: 0.0928\n",
      "Epoch 117/150\n",
      "31364/31364 [==============================] - 28s 884us/step - loss: 0.0133 - mae: 0.0893 - val_loss: 0.0159 - val_mae: 0.0984\n",
      "Epoch 118/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0130 - val_mae: 0.0891\n",
      "Epoch 119/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0133 - mae: 0.0894 - val_loss: 0.0162 - val_mae: 0.0999\n",
      "Epoch 120/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0133 - mae: 0.0895 - val_loss: 0.0126 - val_mae: 0.0866\n",
      "Epoch 121/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0134 - mae: 0.0896 - val_loss: 0.0149 - val_mae: 0.0963\n",
      "Epoch 122/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0134 - mae: 0.0897 - val_loss: 0.0161 - val_mae: 0.0998\n",
      "Epoch 123/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0137 - val_mae: 0.0909\n",
      "Epoch 124/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0134 - mae: 0.0895 - val_loss: 0.0119 - val_mae: 0.0828\n",
      "Epoch 125/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0134 - mae: 0.0896 - val_loss: 0.0127 - val_mae: 0.0862\n",
      "Epoch 126/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0134 - mae: 0.0896 - val_loss: 0.0133 - val_mae: 0.0894\n",
      "Epoch 127/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0134 - mae: 0.0896 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 128/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0134 - mae: 0.0897 - val_loss: 0.0131 - val_mae: 0.0885\n",
      "Epoch 129/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0135 - mae: 0.0899 - val_loss: 0.0117 - val_mae: 0.0824\n",
      "Epoch 130/150\n",
      "31364/31364 [==============================] - 27s 870us/step - loss: 0.0135 - mae: 0.0899 - val_loss: 0.0123 - val_mae: 0.0851\n",
      "Epoch 131/150\n",
      "31364/31364 [==============================] - 27s 866us/step - loss: 0.0135 - mae: 0.0901 - val_loss: 0.0117 - val_mae: 0.0833\n",
      "Epoch 132/150\n",
      "31364/31364 [==============================] - 27s 877us/step - loss: 0.0135 - mae: 0.0902 - val_loss: 0.0144 - val_mae: 0.0929\n",
      "Epoch 133/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0135 - mae: 0.0902 - val_loss: 0.0124 - val_mae: 0.0859\n",
      "Epoch 134/150\n",
      "31364/31364 [==============================] - 28s 877us/step - loss: 0.0135 - mae: 0.0901 - val_loss: 0.0128 - val_mae: 0.0888\n",
      "Epoch 135/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0136 - mae: 0.0904 - val_loss: 0.0133 - val_mae: 0.0898\n",
      "Epoch 136/150\n",
      "31364/31364 [==============================] - 28s 883us/step - loss: 0.0136 - mae: 0.0904 - val_loss: 0.0140 - val_mae: 0.0928\n",
      "Epoch 137/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0136 - mae: 0.0906 - val_loss: 0.0118 - val_mae: 0.0837\n",
      "Epoch 138/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0137 - mae: 0.0907 - val_loss: 0.0124 - val_mae: 0.0855\n",
      "Epoch 139/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0123 - val_mae: 0.0855\n",
      "Epoch 140/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0165 - val_mae: 0.1006\n",
      "Epoch 141/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0123 - val_mae: 0.0861\n",
      "Epoch 142/150\n",
      "31364/31364 [==============================] - 27s 872us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0144 - val_mae: 0.0932\n",
      "Epoch 143/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0141 - val_mae: 0.0927\n",
      "Epoch 144/150\n",
      "31364/31364 [==============================] - 28s 878us/step - loss: 0.0139 - mae: 0.0913 - val_loss: 0.0121 - val_mae: 0.0853\n",
      "Epoch 145/150\n",
      "31364/31364 [==============================] - 27s 875us/step - loss: 0.0139 - mae: 0.0916 - val_loss: 0.0122 - val_mae: 0.0851\n",
      "Epoch 146/150\n",
      "31364/31364 [==============================] - 27s 871us/step - loss: 0.0140 - mae: 0.0919 - val_loss: 0.0144 - val_mae: 0.0937\n",
      "Epoch 147/150\n",
      "31364/31364 [==============================] - 27s 873us/step - loss: 0.0141 - mae: 0.0924 - val_loss: 0.0146 - val_mae: 0.0940\n",
      "Epoch 148/150\n",
      "31364/31364 [==============================] - 27s 874us/step - loss: 0.0142 - mae: 0.0926 - val_loss: 0.0132 - val_mae: 0.0889\n",
      "Epoch 149/150\n",
      "31364/31364 [==============================] - 28s 885us/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0150 - val_mae: 0.0961\n",
      "Epoch 150/150\n",
      "31364/31364 [==============================] - 27s 876us/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0139 - val_mae: 0.0912\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "num_val_samples = len(train_inputs) // k\n",
    "validation_scores = []\n",
    "num_epochs = 150\n",
    "histories = []\n",
    "nmse = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples] \n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_inputs[:i * num_val_samples],\n",
    "         train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "    \n",
    " \n",
    "    model = get_model(train_inputs)\n",
    "    \n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    histories.append(history.history)\n",
    "    \n",
    "    predictions_targets = model.predict(val_data)\n",
    "    nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.5656547113984921\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse))\n",
    "\n",
    "val_mae_history = [np.mean([x['val_mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "mae_history = [np.mean([x['mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(val_mae_history) + 1), val_mae_history, 'ro')\n",
    "plt.plot(range(1, len(mae_history) + 1), mae_history, 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_history = [np.mean([x['val_loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "loss_history = [np.mean([x['loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, 'ro')\n",
    "plt.plot(range(1, len(loss_history) + 1), loss_history, 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_with(train_data, number_neurons):\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(number_neurons, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(8))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING NUMBER OF NEURONS  2\n",
      "PROCESSING FOLD # 0\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0236 - mae: 0.1224 - val_loss: 0.0211 - val_mae: 0.1166\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0210 - mae: 0.1158 - val_loss: 0.0212 - val_mae: 0.1167\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1158 - val_loss: 0.0213 - val_mae: 0.1169\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0210 - mae: 0.1161 - val_loss: 0.0211 - val_mae: 0.1168\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0211 - mae: 0.1165 - val_loss: 0.0212 - val_mae: 0.1170\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0212 - mae: 0.1169 - val_loss: 0.0215 - val_mae: 0.1179\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0212 - mae: 0.1171 - val_loss: 0.0216 - val_mae: 0.1180\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0213 - mae: 0.1173 - val_loss: 0.0216 - val_mae: 0.1182\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0214 - mae: 0.1175 - val_loss: 0.0215 - val_mae: 0.1181\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0214 - mae: 0.1176 - val_loss: 0.0214 - val_mae: 0.1176\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0213 - mae: 0.1173 - val_loss: 0.0214 - val_mae: 0.1174\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0212 - mae: 0.1168 - val_loss: 0.0214 - val_mae: 0.1174\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0212 - mae: 0.1166 - val_loss: 0.0212 - val_mae: 0.1168\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0211 - mae: 0.1166 - val_loss: 0.0219 - val_mae: 0.1187\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0211 - mae: 0.1165 - val_loss: 0.0212 - val_mae: 0.1171\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0210 - mae: 0.1161 - val_loss: 0.0213 - val_mae: 0.1177\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0209 - mae: 0.1159 - val_loss: 0.0208 - val_mae: 0.1161\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0209 - mae: 0.1159 - val_loss: 0.0209 - val_mae: 0.1162\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0209 - mae: 0.1159 - val_loss: 0.0214 - val_mae: 0.1176\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0208 - mae: 0.1158 - val_loss: 0.0209 - val_mae: 0.1159\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0209 - mae: 0.1160 - val_loss: 0.0209 - val_mae: 0.1158\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0209 - mae: 0.1159 - val_loss: 0.0209 - val_mae: 0.1160\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0209 - mae: 0.1160 - val_loss: 0.0211 - val_mae: 0.1160\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0209 - mae: 0.1160 - val_loss: 0.0214 - val_mae: 0.1173\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0209 - mae: 0.1159 - val_loss: 0.0211 - val_mae: 0.1168\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0209 - mae: 0.1160 - val_loss: 0.0212 - val_mae: 0.1173\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0209 - mae: 0.1161 - val_loss: 0.0211 - val_mae: 0.1167\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0209 - mae: 0.1161 - val_loss: 0.0210 - val_mae: 0.1168\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1161 - val_loss: 0.0210 - val_mae: 0.1164\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0209 - mae: 0.1161 - val_loss: 0.0217 - val_mae: 0.1182\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0228 - val_mae: 0.1207\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0209 - mae: 0.1161 - val_loss: 0.0210 - val_mae: 0.1165\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0209 - mae: 0.1162 - val_loss: 0.0227 - val_mae: 0.1205\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0209 - mae: 0.1161 - val_loss: 0.0210 - val_mae: 0.1164\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0210 - val_mae: 0.1167\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0210 - val_mae: 0.1164\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0215 - val_mae: 0.1173\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0211 - val_mae: 0.1167\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0210 - val_mae: 0.1163\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0209 - mae: 0.1161 - val_loss: 0.0209 - val_mae: 0.1159\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0210 - val_mae: 0.1164\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0218 - val_mae: 0.1184\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0210 - val_mae: 0.1165\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1165\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1167\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0211 - val_mae: 0.1161\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0209 - mae: 0.1162 - val_loss: 0.0209 - val_mae: 0.1161\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0208 - val_mae: 0.1163\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0209 - val_mae: 0.1159\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1170\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1163\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1164\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0209 - val_mae: 0.1158\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0211 - val_mae: 0.1169\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0212 - val_mae: 0.1172\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0212 - val_mae: 0.1174\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0211 - val_mae: 0.1168\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0211 - val_mae: 0.1167\n",
      "Epoch 59/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0216 - val_mae: 0.1176\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1164 - val_loss: 0.0211 - val_mae: 0.1166\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1164 - val_loss: 0.0209 - val_mae: 0.1163\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1161\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1162\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1164 - val_loss: 0.0213 - val_mae: 0.1174\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1162\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1164 - val_loss: 0.0211 - val_mae: 0.1173\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1164 - val_loss: 0.0210 - val_mae: 0.1166\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0210 - mae: 0.1164 - val_loss: 0.0221 - val_mae: 0.1202\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0210 - mae: 0.1162 - val_loss: 0.0211 - val_mae: 0.1171\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0211 - val_mae: 0.1166\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0211 - val_mae: 0.1167\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0211 - val_mae: 0.1164\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0212 - val_mae: 0.1171\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0210 - mae: 0.1164 - val_loss: 0.0211 - val_mae: 0.1167\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0211 - val_mae: 0.1163\n",
      "PROCESSING FOLD # 1\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0239 - mae: 0.1251 - val_loss: 0.0221 - val_mae: 0.1204\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0223 - mae: 0.1207 - val_loss: 0.0213 - val_mae: 0.1175\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0214 - mae: 0.1181 - val_loss: 0.0209 - val_mae: 0.1164\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0213 - mae: 0.1176 - val_loss: 0.0213 - val_mae: 0.1173\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0214 - mae: 0.1176 - val_loss: 0.0210 - val_mae: 0.1165\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0213 - mae: 0.1174 - val_loss: 0.0210 - val_mae: 0.1164\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0213 - mae: 0.1175 - val_loss: 0.0210 - val_mae: 0.1162\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0213 - mae: 0.1175 - val_loss: 0.0208 - val_mae: 0.1162\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0213 - mae: 0.1174 - val_loss: 0.0209 - val_mae: 0.1156\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0213 - mae: 0.1174 - val_loss: 0.0209 - val_mae: 0.1162\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0213 - mae: 0.1175 - val_loss: 0.0213 - val_mae: 0.1173\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0213 - mae: 0.1175 - val_loss: 0.0209 - val_mae: 0.1162\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0213 - mae: 0.1175 - val_loss: 0.0209 - val_mae: 0.1161\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0210 - val_mae: 0.1164\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0214 - mae: 0.1176 - val_loss: 0.0208 - val_mae: 0.1159\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0208 - val_mae: 0.1160\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0211 - val_mae: 0.1173\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0211 - val_mae: 0.1168\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0209 - val_mae: 0.1165\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0226 - val_mae: 0.1197\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0220 - val_mae: 0.1192\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0211 - val_mae: 0.1166\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0209 - val_mae: 0.1164\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0214 - mae: 0.1177 - val_loss: 0.0209 - val_mae: 0.1159\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0209 - val_mae: 0.1162\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0207 - val_mae: 0.1165\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0215 - val_mae: 0.1182\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0209 - val_mae: 0.1162\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0208 - val_mae: 0.1158\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0215 - mae: 0.1178 - val_loss: 0.0208 - val_mae: 0.1156\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0214 - mae: 0.1179 - val_loss: 0.0214 - val_mae: 0.1175\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0215 - mae: 0.1179 - val_loss: 0.0209 - val_mae: 0.1165\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0215 - mae: 0.1179 - val_loss: 0.0209 - val_mae: 0.1163\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0209 - val_mae: 0.1156\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0215 - mae: 0.1179 - val_loss: 0.0210 - val_mae: 0.1167\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0215 - mae: 0.1179 - val_loss: 0.0220 - val_mae: 0.1191\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0215 - mae: 0.1180 - val_loss: 0.0221 - val_mae: 0.1194\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0215 - mae: 0.1179 - val_loss: 0.0209 - val_mae: 0.1158\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0215 - mae: 0.1180 - val_loss: 0.0210 - val_mae: 0.1173\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0207 - val_mae: 0.1154\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0214 - mae: 0.1179 - val_loss: 0.0211 - val_mae: 0.1163\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0214 - mae: 0.1179 - val_loss: 0.0210 - val_mae: 0.1166\n",
      "Epoch 43/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0210 - val_mae: 0.1168\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0214 - mae: 0.1178 - val_loss: 0.0209 - val_mae: 0.1156\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0212 - mae: 0.1173 - val_loss: 0.0205 - val_mae: 0.1151\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0207 - mae: 0.1156 - val_loss: 0.0201 - val_mae: 0.1136\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0216 - val_mae: 0.1171\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0199 - val_mae: 0.1127\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0204 - mae: 0.1145 - val_loss: 0.0200 - val_mae: 0.1133\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0201 - val_mae: 0.1132\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0204 - mae: 0.1144 - val_loss: 0.0201 - val_mae: 0.1132\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0201 - val_mae: 0.1132\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0205 - mae: 0.1144 - val_loss: 0.0200 - val_mae: 0.1130\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0207 - val_mae: 0.1150\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0206 - val_mae: 0.1147\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0209 - val_mae: 0.1151\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0205 - mae: 0.1146 - val_loss: 0.0204 - val_mae: 0.1143\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0205 - mae: 0.1146 - val_loss: 0.0204 - val_mae: 0.1139\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0205 - mae: 0.1146 - val_loss: 0.0200 - val_mae: 0.1130\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0205 - mae: 0.1146 - val_loss: 0.0201 - val_mae: 0.1137\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0206 - mae: 0.1147 - val_loss: 0.0202 - val_mae: 0.1139\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0206 - mae: 0.1146 - val_loss: 0.0202 - val_mae: 0.1138\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0201 - val_mae: 0.1130\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0205 - mae: 0.1144 - val_loss: 0.0200 - val_mae: 0.1130\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0205 - mae: 0.1142 - val_loss: 0.0202 - val_mae: 0.1129\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0203 - mae: 0.1138 - val_loss: 0.0200 - val_mae: 0.1124\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0203 - mae: 0.1137 - val_loss: 0.0200 - val_mae: 0.1129\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0203 - mae: 0.1137 - val_loss: 0.0199 - val_mae: 0.1125\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0203 - mae: 0.1138 - val_loss: 0.0201 - val_mae: 0.1133\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0203 - mae: 0.1138 - val_loss: 0.0203 - val_mae: 0.1146\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0203 - mae: 0.1139 - val_loss: 0.0201 - val_mae: 0.1132\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0204 - mae: 0.1139 - val_loss: 0.0201 - val_mae: 0.1130\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 31s 1ms/step - loss: 0.0204 - mae: 0.1141 - val_loss: 0.0200 - val_mae: 0.1127\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0204 - mae: 0.1141 - val_loss: 0.0200 - val_mae: 0.1132\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0204 - mae: 0.1142 - val_loss: 0.0201 - val_mae: 0.1132\n",
      "PROCESSING FOLD # 2\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0232 - mae: 0.1230 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0225 - mae: 0.1213 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1216\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1216\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1217\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1211\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0225 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1216\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0227 - val_mae: 0.1215\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1215\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0228 - val_mae: 0.1214\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1212\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1214\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0225 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1211\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1215\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0227 - val_mae: 0.1214\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1212\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1212\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1215\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1215\n",
      "Epoch 27/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1212\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1214\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0225 - mae: 0.1211 - val_loss: 0.0227 - val_mae: 0.1217\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1214\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1211\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1213\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1217\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1211\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1215\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0227 - val_mae: 0.1214\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1213\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1212\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0227 - val_mae: 0.1220\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1217\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1217\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0227 - val_mae: 0.1214\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0227 - val_mae: 0.1218\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1215\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1216\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1213\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1212\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1214\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1210\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0227 - val_mae: 0.1217\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1211\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1213\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0225 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1212\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1215\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0227 - val_mae: 0.1213\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1213\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1214\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1214\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1216\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1213\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1217\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1215\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1211\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0225 - mae: 0.1212 - val_loss: 0.0225 - val_mae: 0.1213\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1212\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0224 - mae: 0.1212 - val_loss: 0.0226 - val_mae: 0.1213\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0225 - mae: 0.1211 - val_loss: 0.0225 - val_mae: 0.1215\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1214\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0224 - mae: 0.1211 - val_loss: 0.0226 - val_mae: 0.1211\n",
      "PROCESSING NUMBER OF NEURONS  5\n",
      "PROCESSING FOLD # 0\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0218 - mae: 0.1181 - val_loss: 0.0212 - val_mae: 0.1171\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0210 - mae: 0.1161 - val_loss: 0.0213 - val_mae: 0.1169\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0210 - mae: 0.1163 - val_loss: 0.0210 - val_mae: 0.1168\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0205 - mae: 0.1145 - val_loss: 0.0205 - val_mae: 0.1143\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0197 - mae: 0.1118 - val_loss: 0.0197 - val_mae: 0.1126\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0192 - mae: 0.1103 - val_loss: 0.0196 - val_mae: 0.1107\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0190 - mae: 0.1095 - val_loss: 0.0190 - val_mae: 0.1095\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0188 - mae: 0.1086 - val_loss: 0.0189 - val_mae: 0.1086\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0185 - mae: 0.1075 - val_loss: 0.0186 - val_mae: 0.1069\n",
      "Epoch 10/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0180 - mae: 0.1057 - val_loss: 0.0177 - val_mae: 0.1047\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0177 - mae: 0.1046 - val_loss: 0.0177 - val_mae: 0.1052\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0174 - mae: 0.1039 - val_loss: 0.0175 - val_mae: 0.1037\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0173 - mae: 0.1037 - val_loss: 0.0174 - val_mae: 0.1034\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0173 - mae: 0.1037 - val_loss: 0.0176 - val_mae: 0.1050\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0173 - mae: 0.1038 - val_loss: 0.0173 - val_mae: 0.1036\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0174 - mae: 0.1040 - val_loss: 0.0176 - val_mae: 0.1046\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0174 - val_mae: 0.1035\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0174 - mae: 0.1041 - val_loss: 0.0175 - val_mae: 0.1035\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0174 - mae: 0.1040 - val_loss: 0.0172 - val_mae: 0.1036\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0174 - mae: 0.1041 - val_loss: 0.0178 - val_mae: 0.1046\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0175 - mae: 0.1044 - val_loss: 0.0177 - val_mae: 0.1054\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0176 - mae: 0.1045 - val_loss: 0.0185 - val_mae: 0.1069\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0176 - mae: 0.1048 - val_loss: 0.0184 - val_mae: 0.1065\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0177 - mae: 0.1049 - val_loss: 0.0178 - val_mae: 0.1047\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0177 - mae: 0.1050 - val_loss: 0.0176 - val_mae: 0.1042\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0178 - mae: 0.1053 - val_loss: 0.0177 - val_mae: 0.1045\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0178 - mae: 0.1054 - val_loss: 0.0187 - val_mae: 0.1082\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0179 - mae: 0.1056 - val_loss: 0.0178 - val_mae: 0.1054\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0179 - mae: 0.1058 - val_loss: 0.0179 - val_mae: 0.1051\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0180 - mae: 0.1059 - val_loss: 0.0183 - val_mae: 0.1064\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0180 - mae: 0.1060 - val_loss: 0.0178 - val_mae: 0.1051\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0180 - mae: 0.1061 - val_loss: 0.0180 - val_mae: 0.1060\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0181 - mae: 0.1063 - val_loss: 0.0179 - val_mae: 0.1057\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0181 - mae: 0.1063 - val_loss: 0.0188 - val_mae: 0.1089\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0180 - mae: 0.1059 - val_loss: 0.0175 - val_mae: 0.1039\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0178 - mae: 0.1050 - val_loss: 0.0187 - val_mae: 0.1082\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0179 - mae: 0.1054 - val_loss: 0.0182 - val_mae: 0.1068\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0179 - mae: 0.1052 - val_loss: 0.0173 - val_mae: 0.1032\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0178 - mae: 0.1051 - val_loss: 0.0172 - val_mae: 0.1028\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0177 - mae: 0.1048 - val_loss: 0.0209 - val_mae: 0.1133\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0177 - mae: 0.1049 - val_loss: 0.0172 - val_mae: 0.1034\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0177 - mae: 0.1046 - val_loss: 0.0171 - val_mae: 0.1029\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0176 - mae: 0.1045 - val_loss: 0.0174 - val_mae: 0.1038\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1044 - val_loss: 0.0170 - val_mae: 0.1026\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0176 - mae: 0.1044 - val_loss: 0.0173 - val_mae: 0.1037\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1044 - val_loss: 0.0169 - val_mae: 0.1021\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1042 - val_loss: 0.0176 - val_mae: 0.1030\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1042 - val_loss: 0.0168 - val_mae: 0.1025\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0182 - val_mae: 0.1071\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0178 - val_mae: 0.1048\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0175 - mae: 0.1040 - val_loss: 0.0172 - val_mae: 0.1030\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0171 - val_mae: 0.1031\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0170 - val_mae: 0.1016\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0173 - val_mae: 0.1032\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0175 - mae: 0.1040 - val_loss: 0.0170 - val_mae: 0.1020\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0176 - val_mae: 0.1049\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0175 - mae: 0.1040 - val_loss: 0.0182 - val_mae: 0.1065\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0172 - val_mae: 0.1030\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0171 - val_mae: 0.1032\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0173 - val_mae: 0.1037\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0199 - val_mae: 0.1105\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0169 - val_mae: 0.1016\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1044 - val_loss: 0.0183 - val_mae: 0.1072\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0177 - mae: 0.1045 - val_loss: 0.0177 - val_mae: 0.1048\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0174 - val_mae: 0.1033\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0187 - val_mae: 0.1070\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0170 - val_mae: 0.1019\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0174 - val_mae: 0.1033\n",
      "Epoch 69/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0176 - mae: 0.1040 - val_loss: 0.0184 - val_mae: 0.1060\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1042 - val_loss: 0.0196 - val_mae: 0.1104\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0176 - mae: 0.1042 - val_loss: 0.0189 - val_mae: 0.1073\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0176 - mae: 0.1043 - val_loss: 0.0174 - val_mae: 0.1038\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0177 - mae: 0.1045 - val_loss: 0.0174 - val_mae: 0.1039\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0176 - mae: 0.1044 - val_loss: 0.0169 - val_mae: 0.1016\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0176 - mae: 0.1044 - val_loss: 0.0170 - val_mae: 0.1022\n",
      "PROCESSING FOLD # 1\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0232 - mae: 0.1209 - val_loss: 0.0207 - val_mae: 0.1152\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0203 - mae: 0.1132 - val_loss: 0.0200 - val_mae: 0.1110\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0190 - mae: 0.1089 - val_loss: 0.0183 - val_mae: 0.1055\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0176 - mae: 0.1040 - val_loss: 0.0165 - val_mae: 0.1000\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0168 - mae: 0.1012 - val_loss: 0.0165 - val_mae: 0.1006\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0166 - mae: 0.1004 - val_loss: 0.0159 - val_mae: 0.0985\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0165 - mae: 0.1005 - val_loss: 0.0164 - val_mae: 0.0994\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0165 - mae: 0.1004 - val_loss: 0.0171 - val_mae: 0.1028\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0164 - mae: 0.1002 - val_loss: 0.0156 - val_mae: 0.0976\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0157 - mae: 0.0979 - val_loss: 0.0145 - val_mae: 0.0939\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0142 - mae: 0.0926 - val_loss: 0.0133 - val_mae: 0.0890\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0137 - mae: 0.0905 - val_loss: 0.0136 - val_mae: 0.0902\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0904 - val_loss: 0.0131 - val_mae: 0.0883\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0136 - mae: 0.0902 - val_loss: 0.0131 - val_mae: 0.0889\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0133 - val_mae: 0.0890\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0134 - val_mae: 0.0893\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0129 - val_mae: 0.0879\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0131 - val_mae: 0.0882\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0131 - val_mae: 0.0884\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0900 - val_loss: 0.0134 - val_mae: 0.0897\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0132 - val_mae: 0.0882\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0902 - val_loss: 0.0137 - val_mae: 0.0902\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0136 - mae: 0.0903 - val_loss: 0.0142 - val_mae: 0.0912\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0903 - val_loss: 0.0139 - val_mae: 0.0915\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0136 - mae: 0.0904 - val_loss: 0.0137 - val_mae: 0.0903\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0136 - mae: 0.0905 - val_loss: 0.0136 - val_mae: 0.0903\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0137 - mae: 0.0906 - val_loss: 0.0137 - val_mae: 0.0908\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0137 - mae: 0.0907 - val_loss: 0.0131 - val_mae: 0.0890\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0149 - val_mae: 0.0966\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0136 - val_mae: 0.0915\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0131 - val_mae: 0.0885\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0135 - val_mae: 0.0896\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0134 - val_mae: 0.0895\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0139 - val_mae: 0.0915\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0131 - val_mae: 0.0883\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0137 - val_mae: 0.0910\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0911 - val_loss: 0.0135 - val_mae: 0.0912\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0130 - val_mae: 0.0885\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0132 - val_mae: 0.0892\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0136 - val_mae: 0.0905\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0135 - val_mae: 0.0907\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0143 - val_mae: 0.0940\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0134 - val_mae: 0.0893\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0134 - val_mae: 0.0905\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0130 - val_mae: 0.0884\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0157 - val_mae: 0.0967\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0137 - mae: 0.0908 - val_loss: 0.0138 - val_mae: 0.0918\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0132 - val_mae: 0.0897\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0911 - val_loss: 0.0133 - val_mae: 0.0900\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0135 - val_mae: 0.0904\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0131 - val_mae: 0.0878\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0130 - val_mae: 0.0885\n",
      "Epoch 53/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0135 - val_mae: 0.0912\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0912 - val_loss: 0.0137 - val_mae: 0.0908\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0135 - val_mae: 0.0895\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0128 - val_mae: 0.0873\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0134 - val_mae: 0.0896\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0134 - val_mae: 0.0890\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0145 - val_mae: 0.0928\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0148 - val_mae: 0.0941\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0136 - val_mae: 0.0908\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0128 - val_mae: 0.0880\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0135 - val_mae: 0.0893\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0134 - val_mae: 0.0893\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0129 - val_mae: 0.0882\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0134 - val_mae: 0.0892\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0912 - val_loss: 0.0136 - val_mae: 0.0908\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0137 - val_mae: 0.0914\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0134 - val_mae: 0.0894\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0128 - val_mae: 0.0874\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0911 - val_loss: 0.0134 - val_mae: 0.0889\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0133 - val_mae: 0.0892\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0138 - mae: 0.0909 - val_loss: 0.0129 - val_mae: 0.0881\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0138 - mae: 0.0910 - val_loss: 0.0132 - val_mae: 0.0883\n",
      "PROCESSING FOLD # 2\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0190 - mae: 0.1083 - val_loss: 0.0165 - val_mae: 0.0997\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0161 - mae: 0.0983 - val_loss: 0.0160 - val_mae: 0.0979\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0159 - mae: 0.0977 - val_loss: 0.0160 - val_mae: 0.0979\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0159 - mae: 0.0976 - val_loss: 0.0158 - val_mae: 0.0964\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0160 - mae: 0.0977 - val_loss: 0.0159 - val_mae: 0.0983\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0160 - mae: 0.0980 - val_loss: 0.0159 - val_mae: 0.0978\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0160 - mae: 0.0978 - val_loss: 0.0160 - val_mae: 0.0979\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0158 - mae: 0.0975 - val_loss: 0.0155 - val_mae: 0.0965\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0155 - mae: 0.0964 - val_loss: 0.0150 - val_mae: 0.0949\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0151 - mae: 0.0953 - val_loss: 0.0146 - val_mae: 0.0936\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0148 - mae: 0.0944 - val_loss: 0.0146 - val_mae: 0.0938\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0146 - mae: 0.0939 - val_loss: 0.0141 - val_mae: 0.0921\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0144 - mae: 0.0932 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0143 - mae: 0.0928 - val_loss: 0.0140 - val_mae: 0.0914\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0143 - mae: 0.0926 - val_loss: 0.0139 - val_mae: 0.0916\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0142 - mae: 0.0923 - val_loss: 0.0140 - val_mae: 0.0914\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0142 - mae: 0.0922 - val_loss: 0.0146 - val_mae: 0.0943\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0141 - mae: 0.0921 - val_loss: 0.0144 - val_mae: 0.0925\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0141 - mae: 0.0921 - val_loss: 0.0140 - val_mae: 0.0913\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0141 - mae: 0.0922 - val_loss: 0.0139 - val_mae: 0.0915\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0142 - mae: 0.0922 - val_loss: 0.0142 - val_mae: 0.0929\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0142 - mae: 0.0923 - val_loss: 0.0136 - val_mae: 0.0902\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0142 - mae: 0.0923 - val_loss: 0.0139 - val_mae: 0.0904\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0142 - mae: 0.0924 - val_loss: 0.0145 - val_mae: 0.0942\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0142 - mae: 0.0923 - val_loss: 0.0140 - val_mae: 0.0913\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0143 - mae: 0.0925 - val_loss: 0.0138 - val_mae: 0.0904\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0142 - mae: 0.0924 - val_loss: 0.0141 - val_mae: 0.0913\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0142 - mae: 0.0923 - val_loss: 0.0138 - val_mae: 0.0908\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0143 - mae: 0.0926 - val_loss: 0.0136 - val_mae: 0.0896\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0143 - mae: 0.0925 - val_loss: 0.0155 - val_mae: 0.0962\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0143 - mae: 0.0925 - val_loss: 0.0145 - val_mae: 0.0934\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0143 - mae: 0.0926 - val_loss: 0.0135 - val_mae: 0.0896\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0143 - mae: 0.0926 - val_loss: 0.0153 - val_mae: 0.0967\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0143 - mae: 0.0925 - val_loss: 0.0151 - val_mae: 0.0961\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0143 - mae: 0.0927 - val_loss: 0.0158 - val_mae: 0.0977\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0142 - mae: 0.0923 - val_loss: 0.0138 - val_mae: 0.0902\n",
      "Epoch 37/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0142 - mae: 0.0923 - val_loss: 0.0140 - val_mae: 0.0917\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0142 - mae: 0.0924 - val_loss: 0.0182 - val_mae: 0.1060\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0142 - mae: 0.0922 - val_loss: 0.0143 - val_mae: 0.0934\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0141 - mae: 0.0920 - val_loss: 0.0137 - val_mae: 0.0897\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0140 - mae: 0.0918 - val_loss: 0.0140 - val_mae: 0.0917\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0140 - mae: 0.0917 - val_loss: 0.0139 - val_mae: 0.0920\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0140 - mae: 0.0916 - val_loss: 0.0153 - val_mae: 0.0950\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0140 - mae: 0.0915 - val_loss: 0.0133 - val_mae: 0.0900\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0916 - val_loss: 0.0131 - val_mae: 0.0889\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0133 - val_mae: 0.0895\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0131 - val_mae: 0.0882\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0133 - val_mae: 0.0892\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0914 - val_loss: 0.0152 - val_mae: 0.0960\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0915 - val_loss: 0.0133 - val_mae: 0.0890\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0139 - mae: 0.0917 - val_loss: 0.0137 - val_mae: 0.0911\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0139 - mae: 0.0917 - val_loss: 0.0133 - val_mae: 0.0892\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0140 - mae: 0.0919 - val_loss: 0.0134 - val_mae: 0.0898\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 32s 1ms/step - loss: 0.0140 - mae: 0.0918 - val_loss: 0.0135 - val_mae: 0.0901\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0140 - mae: 0.0920 - val_loss: 0.0135 - val_mae: 0.0902\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0140 - mae: 0.0920 - val_loss: 0.0143 - val_mae: 0.0927\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0140 - mae: 0.0920 - val_loss: 0.0140 - val_mae: 0.0922\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0139 - val_mae: 0.0915\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0140 - mae: 0.0921 - val_loss: 0.0138 - val_mae: 0.0913\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0132 - val_mae: 0.0892\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0140 - mae: 0.0922 - val_loss: 0.0134 - val_mae: 0.0898\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0137 - val_mae: 0.0903\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 44s 2ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0147 - val_mae: 0.0945\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0141 - val_mae: 0.0918\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0141 - mae: 0.0924 - val_loss: 0.0134 - val_mae: 0.0894\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0141 - mae: 0.0925 - val_loss: 0.0156 - val_mae: 0.0977\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0132 - val_mae: 0.0891\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0141 - mae: 0.0924 - val_loss: 0.0138 - val_mae: 0.0914\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0141 - mae: 0.0924 - val_loss: 0.0133 - val_mae: 0.0902\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0141 - mae: 0.0924 - val_loss: 0.0145 - val_mae: 0.0931\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0141 - mae: 0.0924 - val_loss: 0.0154 - val_mae: 0.0956\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0141 - mae: 0.0924 - val_loss: 0.0147 - val_mae: 0.0949\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0134 - val_mae: 0.0897\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0142 - mae: 0.0926 - val_loss: 0.0138 - val_mae: 0.0912\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0141 - mae: 0.0925 - val_loss: 0.0136 - val_mae: 0.0900\n",
      "PROCESSING NUMBER OF NEURONS  8\n",
      "PROCESSING FOLD # 0\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0225 - mae: 0.1206 - val_loss: 0.0199 - val_mae: 0.1122\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0174 - mae: 0.1033 - val_loss: 0.0156 - val_mae: 0.0967\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0150 - mae: 0.0945 - val_loss: 0.0147 - val_mae: 0.0933\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0144 - mae: 0.0919 - val_loss: 0.0137 - val_mae: 0.0899\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0134 - mae: 0.0881 - val_loss: 0.0140 - val_mae: 0.0912\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0132 - mae: 0.0878 - val_loss: 0.0132 - val_mae: 0.0884\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0133 - mae: 0.0881 - val_loss: 0.0133 - val_mae: 0.0879\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0133 - mae: 0.0884 - val_loss: 0.0133 - val_mae: 0.0881\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0135 - mae: 0.0887 - val_loss: 0.0140 - val_mae: 0.0903\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 33s 1ms/step - loss: 0.0135 - mae: 0.0889 - val_loss: 0.0136 - val_mae: 0.0897\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0135 - mae: 0.0890 - val_loss: 0.0134 - val_mae: 0.0891\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0135 - mae: 0.0892 - val_loss: 0.0137 - val_mae: 0.0892\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0135 - mae: 0.0895 - val_loss: 0.0135 - val_mae: 0.0898\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0138 - mae: 0.0903 - val_loss: 0.0143 - val_mae: 0.0917\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0139 - mae: 0.0908 - val_loss: 0.0139 - val_mae: 0.0901\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0141 - mae: 0.0913 - val_loss: 0.0141 - val_mae: 0.0924\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0143 - mae: 0.0920 - val_loss: 0.0156 - val_mae: 0.0976\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0144 - mae: 0.0923 - val_loss: 0.0148 - val_mae: 0.0943\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0146 - mae: 0.0930 - val_loss: 0.0148 - val_mae: 0.0942\n",
      "Epoch 20/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0147 - mae: 0.0935 - val_loss: 0.0144 - val_mae: 0.0921\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0148 - mae: 0.0939 - val_loss: 0.0147 - val_mae: 0.0944\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0149 - mae: 0.0943 - val_loss: 0.0151 - val_mae: 0.0951\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0150 - mae: 0.0948 - val_loss: 0.0155 - val_mae: 0.0973\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0150 - mae: 0.0950 - val_loss: 0.0147 - val_mae: 0.0944\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 44s 2ms/step - loss: 0.0151 - mae: 0.0951 - val_loss: 0.0149 - val_mae: 0.0944\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0150 - mae: 0.0948 - val_loss: 0.0150 - val_mae: 0.0962\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0148 - mae: 0.0941 - val_loss: 0.0143 - val_mae: 0.0933\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0145 - mae: 0.0934 - val_loss: 0.0149 - val_mae: 0.0944\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0144 - mae: 0.0931 - val_loss: 0.0143 - val_mae: 0.0921\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0145 - mae: 0.0932 - val_loss: 0.0140 - val_mae: 0.0918\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0146 - mae: 0.0935 - val_loss: 0.0142 - val_mae: 0.0924\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0147 - mae: 0.0937 - val_loss: 0.0148 - val_mae: 0.0947\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0148 - mae: 0.0940 - val_loss: 0.0144 - val_mae: 0.0932\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0148 - mae: 0.0944 - val_loss: 0.0152 - val_mae: 0.0957\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0151 - mae: 0.0951 - val_loss: 0.0147 - val_mae: 0.0933\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0153 - mae: 0.0958 - val_loss: 0.0151 - val_mae: 0.0958\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0155 - mae: 0.0968 - val_loss: 0.0159 - val_mae: 0.0981\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0157 - mae: 0.0974 - val_loss: 0.0155 - val_mae: 0.0968\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0158 - mae: 0.0980 - val_loss: 0.0170 - val_mae: 0.1022\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0160 - mae: 0.0987 - val_loss: 0.0153 - val_mae: 0.0966\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0162 - mae: 0.0994 - val_loss: 0.0160 - val_mae: 0.0987- loss: 0.0162 - mae\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0163 - mae: 0.0999 - val_loss: 0.0160 - val_mae: 0.0991\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0164 - mae: 0.1001 - val_loss: 0.0179 - val_mae: 0.1038\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0165 - mae: 0.1005 - val_loss: 0.0175 - val_mae: 0.1036\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0165 - mae: 0.1006 - val_loss: 0.0159 - val_mae: 0.0993\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0165 - mae: 0.1006 - val_loss: 0.0162 - val_mae: 0.0994\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0166 - mae: 0.1009 - val_loss: 0.0165 - val_mae: 0.1006\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0166 - mae: 0.1011 - val_loss: 0.0171 - val_mae: 0.1021\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0166 - mae: 0.1010 - val_loss: 0.0162 - val_mae: 0.0996\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0166 - mae: 0.1009 - val_loss: 0.0160 - val_mae: 0.0992\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0167 - mae: 0.1009 - val_loss: 0.0160 - val_mae: 0.0989\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0166 - mae: 0.1005 - val_loss: 0.0162 - val_mae: 0.0989\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0166 - mae: 0.1007 - val_loss: 0.0164 - val_mae: 0.0995\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0166 - mae: 0.1007 - val_loss: 0.0169 - val_mae: 0.1023\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0167 - mae: 0.1009 - val_loss: 0.0165 - val_mae: 0.1000\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0167 - mae: 0.1011 - val_loss: 0.0163 - val_mae: 0.0997\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0168 - mae: 0.1011 - val_loss: 0.0165 - val_mae: 0.1002\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0168 - mae: 0.1013 - val_loss: 0.0164 - val_mae: 0.1001\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0168 - mae: 0.1013 - val_loss: 0.0171 - val_mae: 0.1024\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0169 - mae: 0.1016 - val_loss: 0.0173 - val_mae: 0.1023\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0169 - mae: 0.1017 - val_loss: 0.0165 - val_mae: 0.1004\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0170 - mae: 0.1019 - val_loss: 0.0164 - val_mae: 0.0998\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0170 - mae: 0.1021 - val_loss: 0.0168 - val_mae: 0.1016\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0171 - mae: 0.1023 - val_loss: 0.0171 - val_mae: 0.1023\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0171 - mae: 0.1023 - val_loss: 0.0175 - val_mae: 0.1029\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0171 - mae: 0.1024 - val_loss: 0.0170 - val_mae: 0.1021\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0171 - mae: 0.1024 - val_loss: 0.0187 - val_mae: 0.1080\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0172 - mae: 0.1026 - val_loss: 0.0178 - val_mae: 0.1042\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0172 - mae: 0.1027 - val_loss: 0.0167 - val_mae: 0.1009\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0172 - mae: 0.1027 - val_loss: 0.0164 - val_mae: 0.0999\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0173 - mae: 0.1029 - val_loss: 0.0175 - val_mae: 0.1026\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0172 - mae: 0.1028 - val_loss: 0.0167 - val_mae: 0.1011\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0173 - mae: 0.1030 - val_loss: 0.0168 - val_mae: 0.1011\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0173 - mae: 0.1030 - val_loss: 0.0165 - val_mae: 0.1002\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0173 - mae: 0.1032 - val_loss: 0.0169 - val_mae: 0.1021\n",
      "PROCESSING FOLD # 1\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0191 - mae: 0.1082 - val_loss: 0.0158 - val_mae: 0.0981\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0155 - mae: 0.0963 - val_loss: 0.0150 - val_mae: 0.0956\n",
      "Epoch 3/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0152 - mae: 0.0950 - val_loss: 0.0145 - val_mae: 0.0931\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0143 - mae: 0.0919 - val_loss: 0.0131 - val_mae: 0.0879\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0134 - mae: 0.0892 - val_loss: 0.0128 - val_mae: 0.0873\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0135 - mae: 0.0896 - val_loss: 0.0134 - val_mae: 0.0893A: 1s - loss: 0.0135 - mae: 0.089 - ETA:\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0137 - mae: 0.0905 - val_loss: 0.0133 - val_mae: 0.0891\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0138 - mae: 0.0907 - val_loss: 0.0135 - val_mae: 0.0892\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0138 - mae: 0.0905 - val_loss: 0.0137 - val_mae: 0.0907\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0137 - mae: 0.0903 - val_loss: 0.0133 - val_mae: 0.0891\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0138 - mae: 0.0907 - val_loss: 0.0138 - val_mae: 0.0906\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 54s 2ms/step - loss: 0.0139 - mae: 0.0908 - val_loss: 0.0136 - val_mae: 0.0902\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 52s 2ms/step - loss: 0.0139 - mae: 0.0910 - val_loss: 0.0137 - val_mae: 0.0903\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0139 - mae: 0.0910 - val_loss: 0.0136 - val_mae: 0.0903\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0139 - mae: 0.0910 - val_loss: 0.0138 - val_mae: 0.0905\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0139 - mae: 0.0910 - val_loss: 0.0134 - val_mae: 0.0892\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0139 - mae: 0.0911 - val_loss: 0.0137 - val_mae: 0.0898\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0139 - mae: 0.0910 - val_loss: 0.0136 - val_mae: 0.0903\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0139 - mae: 0.0910 - val_loss: 0.0137 - val_mae: 0.0905\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0139 - mae: 0.0911 - val_loss: 0.0137 - val_mae: 0.0911\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0139 - mae: 0.0911 - val_loss: 0.0133 - val_mae: 0.0894\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0139 - mae: 0.0913 - val_loss: 0.0143 - val_mae: 0.0925\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0139 - mae: 0.0913 - val_loss: 0.0136 - val_mae: 0.0903\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0140 - mae: 0.0914 - val_loss: 0.0138 - val_mae: 0.0917\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0140 - mae: 0.0917 - val_loss: 0.0139 - val_mae: 0.0909\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0140 - mae: 0.0917 - val_loss: 0.0135 - val_mae: 0.0899\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0141 - mae: 0.0918 - val_loss: 0.0149 - val_mae: 0.0942\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0141 - mae: 0.0918 - val_loss: 0.0145 - val_mae: 0.0935\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0141 - mae: 0.0920 - val_loss: 0.0150 - val_mae: 0.0960\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0141 - mae: 0.0920 - val_loss: 0.0136 - val_mae: 0.0904\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0142 - mae: 0.0922 - val_loss: 0.0150 - val_mae: 0.0952\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0142 - mae: 0.0924 - val_loss: 0.0135 - val_mae: 0.0906\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0143 - mae: 0.0924 - val_loss: 0.0134 - val_mae: 0.0891\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0143 - mae: 0.0925 - val_loss: 0.0145 - val_mae: 0.0938\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0144 - mae: 0.0928 - val_loss: 0.0140 - val_mae: 0.0913\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0144 - mae: 0.0929 - val_loss: 0.0142 - val_mae: 0.0928\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0144 - mae: 0.0928 - val_loss: 0.0144 - val_mae: 0.0937\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0144 - mae: 0.0931 - val_loss: 0.0147 - val_mae: 0.0943\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0144 - mae: 0.0931 - val_loss: 0.0162 - val_mae: 0.0997\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0145 - mae: 0.0933 - val_loss: 0.0141 - val_mae: 0.0914\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0146 - mae: 0.0935 - val_loss: 0.0134 - val_mae: 0.0895\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0146 - mae: 0.0933 - val_loss: 0.0141 - val_mae: 0.0918\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0146 - mae: 0.0935 - val_loss: 0.0146 - val_mae: 0.0938\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0146 - mae: 0.0937 - val_loss: 0.0151 - val_mae: 0.0959\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0146 - mae: 0.0937 - val_loss: 0.0143 - val_mae: 0.0929\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0147 - mae: 0.0939 - val_loss: 0.0152 - val_mae: 0.0954\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0147 - mae: 0.0939 - val_loss: 0.0159 - val_mae: 0.0977\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0147 - mae: 0.0940 - val_loss: 0.0152 - val_mae: 0.0961\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0148 - mae: 0.0943 - val_loss: 0.0143 - val_mae: 0.0928\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0149 - mae: 0.0945 - val_loss: 0.0142 - val_mae: 0.0921\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0148 - mae: 0.0943 - val_loss: 0.0155 - val_mae: 0.0957\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0149 - mae: 0.0947 - val_loss: 0.0171 - val_mae: 0.0999\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0149 - mae: 0.0945 - val_loss: 0.0138 - val_mae: 0.0910\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0149 - mae: 0.0946 - val_loss: 0.0148 - val_mae: 0.0942\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0150 - mae: 0.0948 - val_loss: 0.0137 - val_mae: 0.0903\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0150 - mae: 0.0949 - val_loss: 0.0158 - val_mae: 0.0967\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0150 - mae: 0.0950 - val_loss: 0.0153 - val_mae: 0.0950\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0151 - mae: 0.0952 - val_loss: 0.0151 - val_mae: 0.0947\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0151 - mae: 0.0954 - val_loss: 0.0147 - val_mae: 0.0942\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0152 - mae: 0.0956 - val_loss: 0.0148 - val_mae: 0.0945\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0151 - mae: 0.0954 - val_loss: 0.0169 - val_mae: 0.1012\n",
      "Epoch 62/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0152 - mae: 0.0957 - val_loss: 0.0147 - val_mae: 0.0936\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0152 - mae: 0.0956 - val_loss: 0.0142 - val_mae: 0.0924\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0152 - mae: 0.0955 - val_loss: 0.0146 - val_mae: 0.0938\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0152 - mae: 0.0956 - val_loss: 0.0142 - val_mae: 0.0927\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0152 - mae: 0.0955 - val_loss: 0.0167 - val_mae: 0.0995\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0153 - mae: 0.0959 - val_loss: 0.0144 - val_mae: 0.0934\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0152 - mae: 0.0957 - val_loss: 0.0152 - val_mae: 0.0955\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0152 - mae: 0.0957 - val_loss: 0.0158 - val_mae: 0.0973\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0152 - mae: 0.0956 - val_loss: 0.0142 - val_mae: 0.0920\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0152 - mae: 0.0958 - val_loss: 0.0146 - val_mae: 0.0940\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0153 - mae: 0.0959 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0153 - mae: 0.0959 - val_loss: 0.0153 - val_mae: 0.0963\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0153 - mae: 0.0960 - val_loss: 0.0149 - val_mae: 0.0951\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0153 - mae: 0.0960 - val_loss: 0.0151 - val_mae: 0.0956\n",
      "PROCESSING FOLD # 2\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0197 - mae: 0.1104 - val_loss: 0.0156 - val_mae: 0.0981\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0147 - mae: 0.0944 - val_loss: 0.0139 - val_mae: 0.0918\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0141 - mae: 0.0919 - val_loss: 0.0139 - val_mae: 0.0912\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 49s 2ms/step - loss: 0.0140 - mae: 0.0916 - val_loss: 0.0144 - val_mae: 0.0931\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 49s 2ms/step - loss: 0.0141 - mae: 0.0918 - val_loss: 0.0152 - val_mae: 0.0960\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0141 - mae: 0.0921 - val_loss: 0.0147 - val_mae: 0.0941\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0142 - mae: 0.0922 - val_loss: 0.0141 - val_mae: 0.0919\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0140 - mae: 0.0915 - val_loss: 0.0135 - val_mae: 0.0893\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0133 - mae: 0.0891 - val_loss: 0.0130 - val_mae: 0.0889\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0132 - mae: 0.0885 - val_loss: 0.0135 - val_mae: 0.0897\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0133 - mae: 0.0885 - val_loss: 0.0130 - val_mae: 0.0872\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0132 - mae: 0.0877 - val_loss: 0.0127 - val_mae: 0.0861\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0126 - mae: 0.0859 - val_loss: 0.0123 - val_mae: 0.0853\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0124 - mae: 0.0855 - val_loss: 0.0122 - val_mae: 0.0843\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 55s 2ms/step - loss: 0.0123 - mae: 0.0852 - val_loss: 0.0146 - val_mae: 0.0934\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 50s 2ms/step - loss: 0.0122 - mae: 0.0850 - val_loss: 0.0115 - val_mae: 0.0826\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 54s 2ms/step - loss: 0.0122 - mae: 0.0850 - val_loss: 0.0127 - val_mae: 0.0866\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0123 - mae: 0.0851 - val_loss: 0.0130 - val_mae: 0.0882\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0123 - mae: 0.0852 - val_loss: 0.0118 - val_mae: 0.0835\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0124 - mae: 0.0854 - val_loss: 0.0126 - val_mae: 0.0871\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0124 - mae: 0.0855 - val_loss: 0.0121 - val_mae: 0.0842\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0121 - val_mae: 0.0850\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 44s 2ms/step - loss: 0.0124 - mae: 0.0859 - val_loss: 0.0117 - val_mae: 0.0833\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 48s 2ms/step - loss: 0.0125 - mae: 0.0863 - val_loss: 0.0127 - val_mae: 0.0875\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0126 - mae: 0.0867 - val_loss: 0.0123 - val_mae: 0.0857\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0125 - mae: 0.0863 - val_loss: 0.0116 - val_mae: 0.0828\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0124 - mae: 0.0858 - val_loss: 0.0121 - val_mae: 0.0844\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0124 - mae: 0.0860 - val_loss: 0.0120 - val_mae: 0.0844\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0125 - mae: 0.0859 - val_loss: 0.0139 - val_mae: 0.0912\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0123 - mae: 0.0856 - val_loss: 0.0121 - val_mae: 0.0847\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0120 - mae: 0.0844 - val_loss: 0.0110 - val_mae: 0.0807\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0115 - mae: 0.0825 - val_loss: 0.0111 - val_mae: 0.0809\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0113 - mae: 0.0819 - val_loss: 0.0116 - val_mae: 0.0836\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0113 - mae: 0.0819 - val_loss: 0.0110 - val_mae: 0.0803\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0112 - mae: 0.0816 - val_loss: 0.0113 - val_mae: 0.0823\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0114 - val_mae: 0.0824\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0105 - val_mae: 0.0787\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0112 - mae: 0.0814 - val_loss: 0.0110 - val_mae: 0.0810\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0111 - val_mae: 0.0798\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0112 - mae: 0.0814 - val_loss: 0.0107 - val_mae: 0.0793\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0107 - val_mae: 0.0789\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0107 - val_mae: 0.0791\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 49s 2ms/step - loss: 0.0111 - mae: 0.0812 - val_loss: 0.0109 - val_mae: 0.0801\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0111 - mae: 0.0810 - val_loss: 0.0107 - val_mae: 0.0789\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0111 - mae: 0.0809 - val_loss: 0.0108 - val_mae: 0.0804\n",
      "Epoch 46/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0110 - mae: 0.0808 - val_loss: 0.0110 - val_mae: 0.0809\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 50s 2ms/step - loss: 0.0110 - mae: 0.0808 - val_loss: 0.0116 - val_mae: 0.0831\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 39s 2ms/step - loss: 0.0110 - mae: 0.0807 - val_loss: 0.0102 - val_mae: 0.0773\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0110 - mae: 0.0808 - val_loss: 0.0105 - val_mae: 0.0784\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0110 - mae: 0.0809 - val_loss: 0.0125 - val_mae: 0.0856\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0111 - mae: 0.0809 - val_loss: 0.0110 - val_mae: 0.0796\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0111 - mae: 0.0812 - val_loss: 0.0117 - val_mae: 0.0843\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0131 - val_mae: 0.0897\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0110 - val_mae: 0.0799\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0113 - mae: 0.0816 - val_loss: 0.0105 - val_mae: 0.0782\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0113 - mae: 0.0818 - val_loss: 0.0107 - val_mae: 0.0791\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0113 - mae: 0.0819 - val_loss: 0.0120 - val_mae: 0.0843\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0114 - mae: 0.0819 - val_loss: 0.0116 - val_mae: 0.0824\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0114 - mae: 0.0821 - val_loss: 0.0109 - val_mae: 0.0789\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0112 - val_mae: 0.0812\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0115 - mae: 0.0823 - val_loss: 0.0113 - val_mae: 0.0820\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0115 - mae: 0.0824 - val_loss: 0.0112 - val_mae: 0.0816\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0115 - mae: 0.0825 - val_loss: 0.0111 - val_mae: 0.0803\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0115 - mae: 0.0826 - val_loss: 0.0137 - val_mae: 0.0904\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0116 - mae: 0.0827 - val_loss: 0.0112 - val_mae: 0.0804\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0116 - mae: 0.0827 - val_loss: 0.0113 - val_mae: 0.0819\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0116 - mae: 0.0827 - val_loss: 0.0140 - val_mae: 0.0919\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0116 - mae: 0.0829 - val_loss: 0.0112 - val_mae: 0.0815\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0120 - val_mae: 0.0832\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0111 - val_mae: 0.0802\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0109 - val_mae: 0.0799\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0117 - val_mae: 0.0831\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 49s 2ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0115 - val_mae: 0.0827\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 44s 2ms/step - loss: 0.0117 - mae: 0.0829 - val_loss: 0.0123 - val_mae: 0.0838\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0109 - val_mae: 0.0795\n",
      "PROCESSING NUMBER OF NEURONS  12\n",
      "PROCESSING FOLD # 0\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 44s 2ms/step - loss: 0.0212 - mae: 0.1150 - val_loss: 0.0195 - val_mae: 0.1101\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0186 - mae: 0.1074 - val_loss: 0.0180 - val_mae: 0.1059\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0154 - mae: 0.0966 - val_loss: 0.0129 - val_mae: 0.0879\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0125 - mae: 0.0862 - val_loss: 0.0120 - val_mae: 0.0847\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0118 - mae: 0.0831 - val_loss: 0.0113 - val_mae: 0.0809\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0115 - mae: 0.0823 - val_loss: 0.0116 - val_mae: 0.0824\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0119 - val_mae: 0.0840\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0113 - val_mae: 0.0812\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0113 - mae: 0.0818 - val_loss: 0.0112 - val_mae: 0.0810\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0114 - mae: 0.0819 - val_loss: 0.0116 - val_mae: 0.0830\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0114 - mae: 0.0819 - val_loss: 0.0115 - val_mae: 0.0825\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0116 - val_mae: 0.0833\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0114 - mae: 0.0821 - val_loss: 0.0111 - val_mae: 0.0801\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0115 - mae: 0.0822 - val_loss: 0.0116 - val_mae: 0.0821\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0115 - mae: 0.0824 - val_loss: 0.0111 - val_mae: 0.0800\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0116 - mae: 0.0824 - val_loss: 0.0140 - val_mae: 0.0931\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0116 - mae: 0.0826 - val_loss: 0.0114 - val_mae: 0.0813\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0116 - mae: 0.0828 - val_loss: 0.0124 - val_mae: 0.0867\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0829 - val_loss: 0.0116 - val_mae: 0.0835\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0114 - val_mae: 0.0818\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0118 - mae: 0.0832 - val_loss: 0.0117 - val_mae: 0.0832\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0112 - val_mae: 0.0806\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 39s 2ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0113 - val_mae: 0.0821\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0115 - val_mae: 0.0834\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0117 - mae: 0.0832 - val_loss: 0.0114 - val_mae: 0.0818\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0114 - val_mae: 0.0819\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0118 - mae: 0.0833 - val_loss: 0.0117 - val_mae: 0.0840\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0124 - val_mae: 0.0855\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0168 - val_mae: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0118 - mae: 0.0833 - val_loss: 0.0115 - val_mae: 0.0820\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0114 - val_mae: 0.0823\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0125 - val_mae: 0.0855\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0115 - val_mae: 0.0820\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 41s 2ms/step - loss: 0.0118 - mae: 0.0836 - val_loss: 0.0112 - val_mae: 0.0810\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 40s 2ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0126 - val_mae: 0.0865\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 39s 1ms/step - loss: 0.0119 - mae: 0.0839 - val_loss: 0.0124 - val_mae: 0.0849\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0119 - mae: 0.0840 - val_loss: 0.0113 - val_mae: 0.0811\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0119 - mae: 0.0840 - val_loss: 0.0122 - val_mae: 0.0845\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 42s 2ms/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0113 - val_mae: 0.0817\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0110 - val_mae: 0.0803\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0120 - mae: 0.0844 - val_loss: 0.0126 - val_mae: 0.0869\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0140 - val_mae: 0.0921\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0120 - mae: 0.0842 - val_loss: 0.0131 - val_mae: 0.0888\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0119 - mae: 0.0839 - val_loss: 0.0120 - val_mae: 0.0834\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0111 - val_mae: 0.0798\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0137 - val_mae: 0.0898\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 43s 2ms/step - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0117 - val_mae: 0.0829\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0111 - val_mae: 0.0809\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 46s 2ms/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0108 - val_mae: 0.0790\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 47s 2ms/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0115 - val_mae: 0.0824\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 45s 2ms/step - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0118 - val_mae: 0.0833\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 38s 1ms/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0110 - val_mae: 0.0802\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0124 - val_mae: 0.0861\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0836 - val_loss: 0.0118 - val_mae: 0.0823\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0109 - val_mae: 0.0808\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0112 - val_mae: 0.0810\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0839 - val_loss: 0.0118 - val_mae: 0.0839\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0841 - val_loss: 0.0128 - val_mae: 0.0876\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0119 - val_mae: 0.0844\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0120 - mae: 0.0844 - val_loss: 0.0112 - val_mae: 0.0809\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0120 - mae: 0.0844 - val_loss: 0.0116 - val_mae: 0.0825\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0121 - mae: 0.0847 - val_loss: 0.0120 - val_mae: 0.0849\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0121 - mae: 0.0849 - val_loss: 0.0114 - val_mae: 0.0821\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0121 - mae: 0.0850 - val_loss: 0.0121 - val_mae: 0.0848\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0122 - mae: 0.0850 - val_loss: 0.0144 - val_mae: 0.0935\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0122 - mae: 0.0852 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0123 - mae: 0.0855 - val_loss: 0.0154 - val_mae: 0.0981\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0123 - mae: 0.0856 - val_loss: 0.0132 - val_mae: 0.0886\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0123 - mae: 0.0857 - val_loss: 0.0169 - val_mae: 0.1026\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0124 - mae: 0.0858 - val_loss: 0.0122 - val_mae: 0.0858\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0124 - mae: 0.0858 - val_loss: 0.0139 - val_mae: 0.0928\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0124 - mae: 0.0861 - val_loss: 0.0122 - val_mae: 0.0852\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0125 - mae: 0.0862 - val_loss: 0.0125 - val_mae: 0.0855\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0124 - mae: 0.0861 - val_loss: 0.0114 - val_mae: 0.0820\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0124 - mae: 0.0861 - val_loss: 0.0112 - val_mae: 0.0812\n",
      "PROCESSING FOLD # 1\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0207 - mae: 0.1142 - val_loss: 0.0180 - val_mae: 0.1057\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0179 - mae: 0.1047 - val_loss: 0.0167 - val_mae: 0.1001\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0165 - mae: 0.0993 - val_loss: 0.0148 - val_mae: 0.0951\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0141 - mae: 0.0914 - val_loss: 0.0138 - val_mae: 0.0911\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0133 - mae: 0.0884 - val_loss: 0.0127 - val_mae: 0.0872\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0125 - mae: 0.0857 - val_loss: 0.0161 - val_mae: 0.0996\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0840 - val_loss: 0.0118 - val_mae: 0.0837\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0832 - val_loss: 0.0108 - val_mae: 0.0799\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0823 - val_loss: 0.0114 - val_mae: 0.0822\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0810 - val_loss: 0.0110 - val_mae: 0.0806\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0805 - val_loss: 0.0111 - val_mae: 0.0813\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0804 - val_loss: 0.0104 - val_mae: 0.0778\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0104 - val_mae: 0.0780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0109 - mae: 0.0803 - val_loss: 0.0107 - val_mae: 0.0793\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0109 - mae: 0.0803 - val_loss: 0.0102 - val_mae: 0.0769\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0106 - val_mae: 0.0786\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0104 - val_mae: 0.0784\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0103 - val_mae: 0.0767\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0806 - val_loss: 0.0124 - val_mae: 0.0865\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0806 - val_loss: 0.0110 - val_mae: 0.0804\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0807 - val_loss: 0.0106 - val_mae: 0.0792\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0807 - val_loss: 0.0104 - val_mae: 0.0773\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0805 - val_loss: 0.0114 - val_mae: 0.0835\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0807 - val_loss: 0.0103 - val_mae: 0.0771\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0807 - val_loss: 0.0104 - val_mae: 0.0785\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0808 - val_loss: 0.0112 - val_mae: 0.0817\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0809 - val_loss: 0.0105 - val_mae: 0.0790\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0809 - val_loss: 0.0110 - val_mae: 0.0794\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0103 - val_mae: 0.0784\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0810 - val_loss: 0.0105 - val_mae: 0.0785\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0117 - val_mae: 0.0838\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0812 - val_loss: 0.0106 - val_mae: 0.0791\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0105 - val_mae: 0.0786\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0811 - val_loss: 0.0105 - val_mae: 0.0785\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0810 - val_loss: 0.0134 - val_mae: 0.0899\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0809 - val_loss: 0.0106 - val_mae: 0.0783\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0810 - val_loss: 0.0107 - val_mae: 0.0794\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0812 - val_loss: 0.0108 - val_mae: 0.0804\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0812 - val_loss: 0.0112 - val_mae: 0.0817\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0131 - val_mae: 0.0894\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0109 - val_mae: 0.0804\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0111 - val_mae: 0.0817\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0120 - val_mae: 0.0849\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0112 - val_mae: 0.0814\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0113 - mae: 0.0815 - val_loss: 0.0105 - val_mae: 0.0783\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0107 - val_mae: 0.0803\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0814 - val_loss: 0.0106 - val_mae: 0.0792\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0814 - val_loss: 0.0103 - val_mae: 0.0779\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0815 - val_loss: 0.0112 - val_mae: 0.0810\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0134 - val_mae: 0.0896\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0815 - val_loss: 0.0108 - val_mae: 0.0788\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0815 - val_loss: 0.0106 - val_mae: 0.0789\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0816 - val_loss: 0.0120 - val_mae: 0.0845\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0108 - val_mae: 0.0790\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0144 - val_mae: 0.0944\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0101 - val_mae: 0.0763\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0816 - val_loss: 0.0106 - val_mae: 0.0794\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0110 - val_mae: 0.0807\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0818 - val_loss: 0.0103 - val_mae: 0.0779\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0819 - val_loss: 0.0106 - val_mae: 0.0790\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0113 - val_mae: 0.0808\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0821 - val_loss: 0.0104 - val_mae: 0.0781\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0112 - val_mae: 0.0821\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0109 - val_mae: 0.0800\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0117 - val_mae: 0.0836\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0106 - val_mae: 0.0787\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0104 - val_mae: 0.0795\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0120 - val_mae: 0.0841\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0821 - val_loss: 0.0121 - val_mae: 0.0853\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0823 - val_loss: 0.0129 - val_mae: 0.0884\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0823 - val_loss: 0.0113 - val_mae: 0.0819\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0823 - val_loss: 0.0125 - val_mae: 0.0873\n",
      "Epoch 73/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0823 - val_loss: 0.0105 - val_mae: 0.0779\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0199 - val_mae: 0.1115\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0118 - val_mae: 0.0841\n",
      "PROCESSING FOLD # 2\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0185 - mae: 0.1061 - val_loss: 0.0156 - val_mae: 0.0970\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0151 - mae: 0.0957 - val_loss: 0.0145 - val_mae: 0.0938\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0140 - mae: 0.0918 - val_loss: 0.0146 - val_mae: 0.0921\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0132 - mae: 0.0882 - val_loss: 0.0123 - val_mae: 0.0854\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0127 - mae: 0.0860 - val_loss: 0.0126 - val_mae: 0.0867\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0125 - mae: 0.0855 - val_loss: 0.0125 - val_mae: 0.0855\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0847 - val_loss: 0.0116 - val_mae: 0.0819\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0828 - val_loss: 0.0115 - val_mae: 0.0826\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0816 - val_loss: 0.0121 - val_mae: 0.0840\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0106 - val_mae: 0.0788\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0111 - mae: 0.0805 - val_loss: 0.0108 - val_mae: 0.0795\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0110 - mae: 0.0799 - val_loss: 0.0103 - val_mae: 0.0768\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0109 - mae: 0.0795 - val_loss: 0.0105 - val_mae: 0.0778\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0108 - mae: 0.0793 - val_loss: 0.0101 - val_mae: 0.0763\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0108 - mae: 0.0792 - val_loss: 0.0104 - val_mae: 0.0775\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0108 - mae: 0.0791 - val_loss: 0.0101 - val_mae: 0.0748\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0108 - mae: 0.0794 - val_loss: 0.0112 - val_mae: 0.0816\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0108 - mae: 0.0795 - val_loss: 0.0103 - val_mae: 0.0764\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0109 - mae: 0.0799 - val_loss: 0.0106 - val_mae: 0.0790\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0115 - val_mae: 0.0831\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0111 - mae: 0.0807 - val_loss: 0.0107 - val_mae: 0.0784\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0812 - val_loss: 0.0109 - val_mae: 0.0811\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0106 - val_mae: 0.0792\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0812 - val_loss: 0.0108 - val_mae: 0.0784\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0107 - val_mae: 0.0794\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0814 - val_loss: 0.0106 - val_mae: 0.0790\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0112 - mae: 0.0816 - val_loss: 0.0108 - val_mae: 0.0798\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0113 - mae: 0.0818 - val_loss: 0.0115 - val_mae: 0.0829\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0113 - mae: 0.0819 - val_loss: 0.0106 - val_mae: 0.0800\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0111 - val_mae: 0.0808\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0105 - val_mae: 0.0782\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0825 - val_loss: 0.0110 - val_mae: 0.0802\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0114 - mae: 0.0826 - val_loss: 0.0112 - val_mae: 0.0814\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0115 - mae: 0.0829 - val_loss: 0.0109 - val_mae: 0.0795\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0116 - mae: 0.0831 - val_loss: 0.0109 - val_mae: 0.0792\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0834 - val_loss: 0.0109 - val_mae: 0.0806\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0118 - val_mae: 0.0854\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0111 - val_mae: 0.0806\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0116 - mae: 0.0835 - val_loss: 0.0126 - val_mae: 0.0873\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0116 - mae: 0.0835 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0116 - mae: 0.0836 - val_loss: 0.0109 - val_mae: 0.0802\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0125 - val_mae: 0.0876\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0124 - val_mae: 0.0868\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0117 - val_mae: 0.0836\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0117 - val_mae: 0.0838\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0109 - val_mae: 0.0796\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0838 - val_loss: 0.0134 - val_mae: 0.0904\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0842 - val_loss: 0.0115 - val_mae: 0.0830\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0843 - val_loss: 0.0103 - val_mae: 0.0781\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0844 - val_loss: 0.0128 - val_mae: 0.0888\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0843 - val_loss: 0.0139 - val_mae: 0.0920\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0841 - val_loss: 0.0121 - val_mae: 0.0864\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0841 - val_loss: 0.0106 - val_mae: 0.0790\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0842 - val_loss: 0.0146 - val_mae: 0.0938\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0843 - val_loss: 0.0113 - val_mae: 0.0820\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0844 - val_loss: 0.0110 - val_mae: 0.0812\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0844 - val_loss: 0.0116 - val_mae: 0.0832\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0844 - val_loss: 0.0110 - val_mae: 0.0819\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0846 - val_loss: 0.0149 - val_mae: 0.0957\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0848 - val_loss: 0.0123 - val_mae: 0.0861\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0846 - val_loss: 0.0186 - val_mae: 0.1094\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0843 - val_loss: 0.0154 - val_mae: 0.0978\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0841 - val_loss: 0.0128 - val_mae: 0.0890\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0840 - val_loss: 0.0148 - val_mae: 0.0953\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0840 - val_loss: 0.0116 - val_mae: 0.0838\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0117 - mae: 0.0841 - val_loss: 0.0105 - val_mae: 0.0786\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0841 - val_loss: 0.0108 - val_mae: 0.0806\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0118 - mae: 0.0843 - val_loss: 0.0151 - val_mae: 0.0951\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0846 - val_loss: 0.0146 - val_mae: 0.0941\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0119 - mae: 0.0847 - val_loss: 0.0106 - val_mae: 0.0785\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0120 - mae: 0.0850 - val_loss: 0.0144 - val_mae: 0.0941\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0121 - mae: 0.0853 - val_loss: 0.0113 - val_mae: 0.0824\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0122 - mae: 0.0855 - val_loss: 0.0125 - val_mae: 0.0865\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0123 - mae: 0.0860 - val_loss: 0.0121 - val_mae: 0.0856\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0124 - mae: 0.0861 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "PROCESSING NUMBER OF NEURONS  16\n",
      "PROCESSING FOLD # 0\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0204 - mae: 0.1128 - val_loss: 0.0190 - val_mae: 0.1083\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0172 - mae: 0.1025 - val_loss: 0.0144 - val_mae: 0.0928\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0130 - mae: 0.0881 - val_loss: 0.0128 - val_mae: 0.0874\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0855 - val_loss: 0.0135 - val_mae: 0.0901\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0122 - mae: 0.0849 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0121 - mae: 0.0845 - val_loss: 0.0122 - val_mae: 0.0849\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0843 - val_loss: 0.0121 - val_mae: 0.0840\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0840 - val_loss: 0.0121 - val_mae: 0.0840\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0840 - val_loss: 0.0121 - val_mae: 0.0836\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0837 - val_loss: 0.0120 - val_mae: 0.0839\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0836 - val_loss: 0.0122 - val_mae: 0.0852\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0119 - mae: 0.0835 - val_loss: 0.0115 - val_mae: 0.0817\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0119 - mae: 0.0836 - val_loss: 0.0132 - val_mae: 0.0887\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0119 - mae: 0.0837 - val_loss: 0.0119 - val_mae: 0.0844\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0839 - val_loss: 0.0124 - val_mae: 0.0851\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0122 - mae: 0.0845 - val_loss: 0.0129 - val_mae: 0.0876\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0124 - mae: 0.0851 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0125 - mae: 0.0857 - val_loss: 0.0130 - val_mae: 0.0884\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0128 - mae: 0.0867 - val_loss: 0.0128 - val_mae: 0.0874\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0130 - mae: 0.0873 - val_loss: 0.0128 - val_mae: 0.0869\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0130 - mae: 0.0874 - val_loss: 0.0132 - val_mae: 0.0884\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0129 - mae: 0.0873 - val_loss: 0.0125 - val_mae: 0.0856\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0127 - mae: 0.0864 - val_loss: 0.0128 - val_mae: 0.0868\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0127 - mae: 0.0861 - val_loss: 0.0128 - val_mae: 0.0864\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0858 - val_loss: 0.0131 - val_mae: 0.0876\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0859 - val_loss: 0.0130 - val_mae: 0.0874\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0127 - mae: 0.0859 - val_loss: 0.0126 - val_mae: 0.0865\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0858 - val_loss: 0.0128 - val_mae: 0.0856\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0858 - val_loss: 0.0123 - val_mae: 0.0844\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0857 - val_loss: 0.0126 - val_mae: 0.0856\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0858 - val_loss: 0.0126 - val_mae: 0.0855\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0856 - val_loss: 0.0129 - val_mae: 0.0874\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0126 - mae: 0.0856 - val_loss: 0.0130 - val_mae: 0.0866\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0125 - mae: 0.0857 - val_loss: 0.0131 - val_mae: 0.0872\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0125 - mae: 0.0855 - val_loss: 0.0127 - val_mae: 0.0862\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0125 - mae: 0.0855 - val_loss: 0.0124 - val_mae: 0.0862\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0125 - mae: 0.0855 - val_loss: 0.0128 - val_mae: 0.0861\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0125 - mae: 0.0853 - val_loss: 0.0125 - val_mae: 0.0854\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0124 - mae: 0.0851 - val_loss: 0.0135 - val_mae: 0.0896\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0849 - val_loss: 0.0122 - val_mae: 0.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0849 - val_loss: 0.0124 - val_mae: 0.0847\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0850 - val_loss: 0.0123 - val_mae: 0.0848\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0850 - val_loss: 0.0131 - val_mae: 0.0883\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0124 - mae: 0.0853 - val_loss: 0.0128 - val_mae: 0.0870\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0124 - mae: 0.0852 - val_loss: 0.0124 - val_mae: 0.0852\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0850 - val_loss: 0.0121 - val_mae: 0.0840\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0122 - mae: 0.0847 - val_loss: 0.0121 - val_mae: 0.0836\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0120 - mae: 0.0837 - val_loss: 0.0125 - val_mae: 0.0856\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0830 - val_loss: 0.0121 - val_mae: 0.0843\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0116 - mae: 0.0823 - val_loss: 0.0111 - val_mae: 0.0800\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0115 - mae: 0.0822 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0115 - mae: 0.0821 - val_loss: 0.0115 - val_mae: 0.0818\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0115 - mae: 0.0821 - val_loss: 0.0109 - val_mae: 0.0799\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0115 - mae: 0.0822 - val_loss: 0.0108 - val_mae: 0.0794\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0115 - mae: 0.0823 - val_loss: 0.0109 - val_mae: 0.0792\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0115 - mae: 0.0823 - val_loss: 0.0112 - val_mae: 0.0810\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0116 - mae: 0.0825 - val_loss: 0.0123 - val_mae: 0.0855\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0116 - mae: 0.0828 - val_loss: 0.0115 - val_mae: 0.0817\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0116 - mae: 0.0827 - val_loss: 0.0114 - val_mae: 0.0816\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0116 - mae: 0.0829 - val_loss: 0.0114 - val_mae: 0.0816\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0111 - val_mae: 0.0814\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0111 - val_mae: 0.0810\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0832 - val_loss: 0.0120 - val_mae: 0.0849\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0833 - val_loss: 0.0112 - val_mae: 0.0813\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0833 - val_loss: 0.0123 - val_mae: 0.0856\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0117 - mae: 0.0832 - val_loss: 0.0111 - val_mae: 0.0805\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0115 - val_mae: 0.0823\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0118 - mae: 0.0835 - val_loss: 0.0116 - val_mae: 0.0825\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0124 - val_mae: 0.0865\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0111 - val_mae: 0.0810\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0122 - val_mae: 0.0852\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0114 - val_mae: 0.0822\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0115 - val_mae: 0.0831\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0114 - val_mae: 0.0820\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0118 - mae: 0.0837 - val_loss: 0.0134 - val_mae: 0.0909\n",
      "PROCESSING FOLD # 1\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0180 - mae: 0.1048 - val_loss: 0.0134 - val_mae: 0.0897\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0123 - mae: 0.0847 - val_loss: 0.0112 - val_mae: 0.0802\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0804 - val_loss: 0.0107 - val_mae: 0.0789\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0784 - val_loss: 0.0107 - val_mae: 0.0785\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0104 - mae: 0.0777 - val_loss: 0.0100 - val_mae: 0.0766\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0103 - mae: 0.0774 - val_loss: 0.0100 - val_mae: 0.0754\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0102 - mae: 0.0771 - val_loss: 0.0098 - val_mae: 0.0755\n",
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0102 - mae: 0.0771 - val_loss: 0.0100 - val_mae: 0.0756\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0103 - mae: 0.0774 - val_loss: 0.0101 - val_mae: 0.0765\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0104 - mae: 0.0777 - val_loss: 0.0101 - val_mae: 0.0764\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0784 - val_loss: 0.0103 - val_mae: 0.0772\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0799 - val_loss: 0.0112 - val_mae: 0.0815\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0110 - val_mae: 0.0810\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0113 - mae: 0.0814 - val_loss: 0.0108 - val_mae: 0.0790\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0111 - mae: 0.0807 - val_loss: 0.0102 - val_mae: 0.0779\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0793 - val_loss: 0.0100 - val_mae: 0.0760\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0791 - val_loss: 0.0106 - val_mae: 0.0791\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0789 - val_loss: 0.0104 - val_mae: 0.0783\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0790 - val_loss: 0.0101 - val_mae: 0.0770\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0792 - val_loss: 0.0106 - val_mae: 0.0787\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0790 - val_loss: 0.0100 - val_mae: 0.0769\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0788 - val_loss: 0.0101 - val_mae: 0.0768\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0105 - mae: 0.0785 - val_loss: 0.0102 - val_mae: 0.0766\n",
      "Epoch 24/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0105 - mae: 0.0784 - val_loss: 0.0106 - val_mae: 0.0797\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0105 - mae: 0.0783 - val_loss: 0.0106 - val_mae: 0.0790\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0105 - mae: 0.0782 - val_loss: 0.0111 - val_mae: 0.0813\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0105 - mae: 0.0783 - val_loss: 0.0105 - val_mae: 0.0784\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0105 - mae: 0.0783 - val_loss: 0.0104 - val_mae: 0.0773\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0105 - mae: 0.0785 - val_loss: 0.0100 - val_mae: 0.0762\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0785 - val_loss: 0.0102 - val_mae: 0.0768\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0786 - val_loss: 0.0103 - val_mae: 0.0776\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0786 - val_loss: 0.0104 - val_mae: 0.0789\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0786 - val_loss: 0.0099 - val_mae: 0.0759\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0787 - val_loss: 0.0105 - val_mae: 0.0789\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0788 - val_loss: 0.0101 - val_mae: 0.0767\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0106 - mae: 0.0789 - val_loss: 0.0104 - val_mae: 0.0780\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0790 - val_loss: 0.0104 - val_mae: 0.0778\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0790 - val_loss: 0.0111 - val_mae: 0.0809\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0789 - val_loss: 0.0104 - val_mae: 0.0782\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0791 - val_loss: 0.0103 - val_mae: 0.0770\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0792 - val_loss: 0.0109 - val_mae: 0.0804\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0791 - val_loss: 0.0102 - val_mae: 0.0766\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0793 - val_loss: 0.0104 - val_mae: 0.0782\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 34s 1ms/step - loss: 0.0108 - mae: 0.0794 - val_loss: 0.0114 - val_mae: 0.0813\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0108 - mae: 0.0793 - val_loss: 0.0104 - val_mae: 0.0780\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0794 - val_loss: 0.0108 - val_mae: 0.0799\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0795 - val_loss: 0.0108 - val_mae: 0.0795\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0109 - val_mae: 0.0806\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0795 - val_loss: 0.0106 - val_mae: 0.0790\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0106 - val_mae: 0.0780\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0105 - val_mae: 0.0786\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0109 - val_mae: 0.0797\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0112 - val_mae: 0.0815\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0102 - val_mae: 0.0777\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0103 - val_mae: 0.0774\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0799 - val_loss: 0.0119 - val_mae: 0.0846\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0799 - val_loss: 0.0109 - val_mae: 0.0796\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0801 - val_loss: 0.0106 - val_mae: 0.0784\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0801 - val_loss: 0.0100 - val_mae: 0.0765\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0802 - val_loss: 0.0122 - val_mae: 0.0843\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0109 - mae: 0.0801 - val_loss: 0.0115 - val_mae: 0.0819\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0801 - val_loss: 0.0112 - val_mae: 0.0816\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0801 - val_loss: 0.0101 - val_mae: 0.0771\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0802 - val_loss: 0.0106 - val_mae: 0.0786\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0802 - val_loss: 0.0105 - val_mae: 0.0785\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0102 - val_mae: 0.0773\n",
      "Epoch 67/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0118 - val_mae: 0.0838\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0113 - val_mae: 0.0808\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0111 - val_mae: 0.0808\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0107 - val_mae: 0.0789\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0104 - val_mae: 0.0777\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0103 - val_mae: 0.0778\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0111 - val_mae: 0.0816\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0103 - val_mae: 0.0780\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0806 - val_loss: 0.0123 - val_mae: 0.0842\n",
      "PROCESSING FOLD # 2\n",
      "Train on 26136 samples, validate on 13068 samples\n",
      "Epoch 1/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0176 - mae: 0.1037 - val_loss: 0.0144 - val_mae: 0.0938\n",
      "Epoch 2/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0126 - mae: 0.0859 - val_loss: 0.0113 - val_mae: 0.0808\n",
      "Epoch 3/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0105 - mae: 0.0781 - val_loss: 0.0101 - val_mae: 0.0755\n",
      "Epoch 4/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0097 - mae: 0.0750 - val_loss: 0.0096 - val_mae: 0.0743\n",
      "Epoch 5/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0095 - mae: 0.0740 - val_loss: 0.0092 - val_mae: 0.0731\n",
      "Epoch 6/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0094 - mae: 0.0735 - val_loss: 0.0095 - val_mae: 0.0742\n",
      "Epoch 7/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0093 - mae: 0.0733 - val_loss: 0.0096 - val_mae: 0.0749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0093 - mae: 0.0731 - val_loss: 0.0090 - val_mae: 0.0723\n",
      "Epoch 9/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0093 - mae: 0.0731 - val_loss: 0.0093 - val_mae: 0.0731\n",
      "Epoch 10/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0093 - mae: 0.0732 - val_loss: 0.0095 - val_mae: 0.0742\n",
      "Epoch 11/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0093 - mae: 0.0733 - val_loss: 0.0100 - val_mae: 0.0763\n",
      "Epoch 12/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0093 - mae: 0.0733 - val_loss: 0.0092 - val_mae: 0.0725\n",
      "Epoch 13/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0093 - mae: 0.0733 - val_loss: 0.0094 - val_mae: 0.0741\n",
      "Epoch 14/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0093 - mae: 0.0734 - val_loss: 0.0095 - val_mae: 0.0742\n",
      "Epoch 15/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0093 - mae: 0.0734 - val_loss: 0.0092 - val_mae: 0.0734\n",
      "Epoch 16/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0094 - mae: 0.0735 - val_loss: 0.0090 - val_mae: 0.0710\n",
      "Epoch 17/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0094 - mae: 0.0736 - val_loss: 0.0090 - val_mae: 0.0719\n",
      "Epoch 18/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0094 - mae: 0.0737 - val_loss: 0.0102 - val_mae: 0.0764\n",
      "Epoch 19/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0094 - mae: 0.0737 - val_loss: 0.0097 - val_mae: 0.0743\n",
      "Epoch 20/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0094 - mae: 0.0736 - val_loss: 0.0102 - val_mae: 0.0773\n",
      "Epoch 21/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0094 - mae: 0.0737 - val_loss: 0.0091 - val_mae: 0.0718\n",
      "Epoch 22/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0095 - mae: 0.0739 - val_loss: 0.0094 - val_mae: 0.0739\n",
      "Epoch 23/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0094 - mae: 0.0738 - val_loss: 0.0096 - val_mae: 0.0738\n",
      "Epoch 24/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0094 - mae: 0.0738 - val_loss: 0.0096 - val_mae: 0.0754\n",
      "Epoch 25/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0095 - mae: 0.0740 - val_loss: 0.0090 - val_mae: 0.0716\n",
      "Epoch 26/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0095 - mae: 0.0741 - val_loss: 0.0098 - val_mae: 0.0749\n",
      "Epoch 27/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0095 - mae: 0.0742 - val_loss: 0.0091 - val_mae: 0.0720\n",
      "Epoch 28/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0096 - mae: 0.0744 - val_loss: 0.0093 - val_mae: 0.0729\n",
      "Epoch 29/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0096 - mae: 0.0747 - val_loss: 0.0095 - val_mae: 0.0737\n",
      "Epoch 30/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0096 - mae: 0.0746 - val_loss: 0.0095 - val_mae: 0.0732\n",
      "Epoch 31/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0097 - mae: 0.0748 - val_loss: 0.0092 - val_mae: 0.0729\n",
      "Epoch 32/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0097 - mae: 0.0751 - val_loss: 0.0094 - val_mae: 0.0732\n",
      "Epoch 33/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0098 - mae: 0.0752 - val_loss: 0.0095 - val_mae: 0.0747\n",
      "Epoch 34/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0098 - mae: 0.0755 - val_loss: 0.0098 - val_mae: 0.0749\n",
      "Epoch 35/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0099 - mae: 0.0758 - val_loss: 0.0109 - val_mae: 0.0792\n",
      "Epoch 36/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0099 - mae: 0.0759 - val_loss: 0.0103 - val_mae: 0.0782\n",
      "Epoch 37/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0100 - mae: 0.0760 - val_loss: 0.0096 - val_mae: 0.0744\n",
      "Epoch 38/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0100 - mae: 0.0762 - val_loss: 0.0101 - val_mae: 0.0761\n",
      "Epoch 39/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0100 - mae: 0.0764 - val_loss: 0.0102 - val_mae: 0.0760\n",
      "Epoch 40/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0101 - mae: 0.0767 - val_loss: 0.0099 - val_mae: 0.0757\n",
      "Epoch 41/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0101 - mae: 0.0767 - val_loss: 0.0100 - val_mae: 0.0758\n",
      "Epoch 42/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0101 - mae: 0.0767 - val_loss: 0.0112 - val_mae: 0.0822\n",
      "Epoch 43/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0102 - mae: 0.0770 - val_loss: 0.0097 - val_mae: 0.0745\n",
      "Epoch 44/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0103 - mae: 0.0771 - val_loss: 0.0101 - val_mae: 0.0759\n",
      "Epoch 45/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0103 - mae: 0.0774 - val_loss: 0.0095 - val_mae: 0.0739\n",
      "Epoch 46/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0104 - mae: 0.0777 - val_loss: 0.0115 - val_mae: 0.0826\n",
      "Epoch 47/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0104 - mae: 0.0780 - val_loss: 0.0102 - val_mae: 0.0764\n",
      "Epoch 48/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0106 - mae: 0.0784 - val_loss: 0.0101 - val_mae: 0.0773\n",
      "Epoch 49/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0107 - mae: 0.0789 - val_loss: 0.0119 - val_mae: 0.0839\n",
      "Epoch 50/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0104 - val_mae: 0.0774\n",
      "Epoch 51/75\n",
      "26136/26136 [==============================] - 37s 1ms/step - loss: 0.0111 - mae: 0.0805 - val_loss: 0.0129 - val_mae: 0.0883\n",
      "Epoch 52/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0114 - val_mae: 0.0810\n",
      "Epoch 53/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0113 - mae: 0.0812 - val_loss: 0.0124 - val_mae: 0.0859\n",
      "Epoch 54/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0112 - mae: 0.0810 - val_loss: 0.0105 - val_mae: 0.0776\n",
      "Epoch 55/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0112 - mae: 0.0812 - val_loss: 0.0109 - val_mae: 0.0796\n",
      "Epoch 56/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0109 - val_mae: 0.0808\n",
      "Epoch 57/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0114 - val_mae: 0.0819\n",
      "Epoch 58/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0113 - mae: 0.0818 - val_loss: 0.0121 - val_mae: 0.0847\n",
      "Epoch 59/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0112 - mae: 0.0814 - val_loss: 0.0129 - val_mae: 0.0897\n",
      "Epoch 60/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0111 - mae: 0.0813 - val_loss: 0.0103 - val_mae: 0.0773\n",
      "Epoch 61/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0110 - mae: 0.0807 - val_loss: 0.0104 - val_mae: 0.0779\n",
      "Epoch 62/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0804 - val_loss: 0.0112 - val_mae: 0.0820\n",
      "Epoch 63/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0109 - mae: 0.0803 - val_loss: 0.0106 - val_mae: 0.0791\n",
      "Epoch 64/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0800 - val_loss: 0.0114 - val_mae: 0.0832\n",
      "Epoch 65/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0801 - val_loss: 0.0109 - val_mae: 0.0795\n",
      "Epoch 66/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0800 - val_loss: 0.0103 - val_mae: 0.0774\n",
      "Epoch 67/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0110 - val_mae: 0.0804\n",
      "Epoch 68/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0111 - val_mae: 0.0806\n",
      "Epoch 69/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0102 - val_mae: 0.0773\n",
      "Epoch 70/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0799 - val_loss: 0.0107 - val_mae: 0.0797\n",
      "Epoch 71/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0799 - val_loss: 0.0107 - val_mae: 0.0795\n",
      "Epoch 72/75\n",
      "26136/26136 [==============================] - 36s 1ms/step - loss: 0.0108 - mae: 0.0800 - val_loss: 0.0103 - val_mae: 0.0772\n",
      "Epoch 73/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0109 - val_mae: 0.0807\n",
      "Epoch 74/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0797 - val_loss: 0.0111 - val_mae: 0.0812\n",
      "Epoch 75/75\n",
      "26136/26136 [==============================] - 35s 1ms/step - loss: 0.0107 - mae: 0.0794 - val_loss: 0.0104 - val_mae: 0.0781\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "num_val_samples = len(train_inputs) // k\n",
    "num_epochs = 75\n",
    "maes = []\n",
    "val_maes = []\n",
    "nmses = []\n",
    "number_neurons = [2, 5, 8, 12, 16];\n",
    "\n",
    "for nn in number_neurons:\n",
    "    mae = []\n",
    "    val_mae = []\n",
    "    nmse = []\n",
    "    print('PROCESSING NUMBER OF NEURONS ', nn);\n",
    "    for i in range(k):\n",
    "        print('PROCESSING FOLD #', i)\n",
    "        val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples] \n",
    "        val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [train_inputs[:i * num_val_samples],\n",
    "             train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [train_targets[:i * num_val_samples],\n",
    "             train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "\n",
    "        model = get_model_with(train_inputs, nn)\n",
    "\n",
    "        history = model.fit(partial_train_data, partial_train_targets,\n",
    "                            validation_data=(val_data, val_targets),\n",
    "                            epochs=num_epochs, batch_size=1, verbose=1)\n",
    "        mae.append(history.history['mae'])\n",
    "        val_mae.append(history.history['val_mae'])\n",
    "        predictions_targets = model.predict(val_data)\n",
    "        nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "        \n",
    "    maes.append(np.mean([x[num_epochs-1] for x in mae]))\n",
    "    val_maes.append(np.mean([x[num_epochs-1] for x in val_mae]))\n",
    "    nmses.append(np.mean(nmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x136a51c88>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(number_neurons, maes, 'ro')\n",
    "plt.plot(number_neurons, val_maes, 'bo')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'NMSE')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(number_neurons, nmses, 'ro')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('NMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "65341/65341 [==============================] - 73s 1ms/step - loss: 0.0158 - mae: 0.0967\n",
      "Epoch 2/75\n",
      "65341/65341 [==============================] - 73s 1ms/step - loss: 0.0124 - mae: 0.0853\n",
      "Epoch 3/75\n",
      "65341/65341 [==============================] - 74s 1ms/step - loss: 0.0119 - mae: 0.0838\n",
      "Epoch 4/75\n",
      "65341/65341 [==============================] - ETA: 0s - loss: 0.0119 - mae: 0.083 - 75s 1ms/step - loss: 0.0119 - mae: 0.0833\n",
      "Epoch 5/75\n",
      "65341/65341 [==============================] - 74s 1ms/step - loss: 0.0123 - mae: 0.0843\n",
      "Epoch 6/75\n",
      "65341/65341 [==============================] - 69s 1ms/step - loss: 0.0124 - mae: 0.0849\n",
      "Epoch 7/75\n",
      "65341/65341 [==============================] - 93s 1ms/step - loss: 0.0123 - mae: 0.0846\n",
      "Epoch 8/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0117 - mae: 0.0826\n",
      "Epoch 9/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0116 - mae: 0.0824\n",
      "Epoch 10/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0116 - mae: 0.0826\n",
      "Epoch 11/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0117 - mae: 0.0827\n",
      "Epoch 12/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0118 - mae: 0.0833\n",
      "Epoch 13/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0120 - mae: 0.0839\n",
      "Epoch 14/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0122 - mae: 0.0845\n",
      "Epoch 15/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0122 - mae: 0.0849\n",
      "Epoch 16/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0124 - mae: 0.0856\n",
      "Epoch 17/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0124 - mae: 0.0856\n",
      "Epoch 18/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0124 - mae: 0.0856\n",
      "Epoch 19/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0123 - mae: 0.0852\n",
      "Epoch 20/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0120 - mae: 0.0843\n",
      "Epoch 21/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0121 - mae: 0.0845\n",
      "Epoch 22/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0124 - mae: 0.0860\n",
      "Epoch 23/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0119 - mae: 0.0841\n",
      "Epoch 24/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0117 - mae: 0.0833\n",
      "Epoch 25/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0119 - mae: 0.0840\n",
      "Epoch 26/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0854\n",
      "Epoch 27/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0125 - mae: 0.0864\n",
      "Epoch 28/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0127 - mae: 0.0867\n",
      "Epoch 29/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0127 - mae: 0.0868\n",
      "Epoch 30/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0127 - mae: 0.0867\n",
      "Epoch 31/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0126 - mae: 0.0866\n",
      "Epoch 32/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0126 - mae: 0.0865\n",
      "Epoch 33/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0126 - mae: 0.0864\n",
      "Epoch 34/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0125 - mae: 0.0863\n",
      "Epoch 35/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0125 - mae: 0.0862\n",
      "Epoch 36/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0125 - mae: 0.0860\n",
      "Epoch 37/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0125 - mae: 0.0859\n",
      "Epoch 38/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0124 - mae: 0.0858\n",
      "Epoch 39/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0855\n",
      "Epoch 40/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0854: 1s - loss:\n",
      "Epoch 41/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0853\n",
      "Epoch 42/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0852\n",
      "Epoch 43/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0122 - mae: 0.0851\n",
      "Epoch 44/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0122 - mae: 0.0851\n",
      "Epoch 45/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0852\n",
      "Epoch 46/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0853\n",
      "Epoch 47/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0852\n",
      "Epoch 48/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0851\n",
      "Epoch 49/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0122 - mae: 0.0849\n",
      "Epoch 50/75\n",
      "65341/65341 [==============================] - 98s 2ms/step - loss: 0.0122 - mae: 0.0849\n",
      "Epoch 51/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0121 - mae: 0.0847\n",
      "Epoch 52/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0121 - mae: 0.0846\n",
      "Epoch 53/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0120 - mae: 0.0844\n",
      "Epoch 54/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0120 - mae: 0.0844: 1s - lo - ETA: 0s - loss: 0.0120 - mae: 0.08\n",
      "Epoch 55/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0120 - mae: 0.0844\n",
      "Epoch 56/75\n",
      "65341/65341 [==============================] - 100s 2ms/step - loss: 0.0120 - mae: 0.0844\n",
      "Epoch 57/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0120 - mae: 0.0845\n",
      "Epoch 58/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0120 - mae: 0.0846\n",
      "Epoch 59/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0121 - mae: 0.0849\n",
      "Epoch 60/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0121 - mae: 0.0851\n",
      "Epoch 61/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0122 - mae: 0.0855\n",
      "Epoch 62/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0123 - mae: 0.0855: 1s - loss:\n",
      "Epoch 63/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0117 - mae: 0.0835\n",
      "Epoch 64/75\n",
      "65341/65341 [==============================] - 99s 2ms/step - loss: 0.0117 - mae: 0.0836\n",
      "Epoch 65/75\n",
      "65341/65341 [==============================] - 108s 2ms/step - loss: 0.0116 - mae: 0.0832\n",
      "Epoch 66/75\n",
      "65341/65341 [==============================] - 100s 2ms/step - loss: 0.0116 - mae: 0.0828\n",
      "Epoch 67/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0116 - mae: 0.0828\n",
      "Epoch 68/75\n",
      "65341/65341 [==============================] - 104s 2ms/step - loss: 0.0115 - mae: 0.0828\n",
      "Epoch 69/75\n",
      "65341/65341 [==============================] - 97s 1ms/step - loss: 0.0116 - mae: 0.0830\n",
      "Epoch 70/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0116 - mae: 0.0829\n",
      "Epoch 71/75\n",
      "65341/65341 [==============================] - 96s 1ms/step - loss: 0.0116 - mae: 0.0830\n",
      "Epoch 72/75\n",
      "65341/65341 [==============================] - 95s 1ms/step - loss: 0.0117 - mae: 0.0832\n",
      "Epoch 73/75\n",
      "65341/65341 [==============================] - 99s 2ms/step - loss: 0.0118 - mae: 0.0835\n",
      "Epoch 74/75\n",
      "65341/65341 [==============================] - 93s 1ms/step - loss: 0.0119 - mae: 0.0838\n",
      "Epoch 75/75\n",
      "65341/65341 [==============================] - 92s 1ms/step - loss: 0.0119 - mae: 0.0838: 1s - l\n"
     ]
    }
   ],
   "source": [
    " model = get_model_with(inputs, 12)\n",
    "\n",
    "history = model.fit(inputs, targets, epochs=75, batch_size=1, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_12_75.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
